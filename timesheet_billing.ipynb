{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "import mysql.connector\n",
    "\n",
    "mysql_host = '34.116.84.145'\n",
    "mysql_port = '3306'\n",
    "mysql_user = 'gong-cha'\n",
    "mysql_password = 'HelloGongCha2012'\n",
    "mysql_database = 'gong_cha_redcat_db'\n",
    "\n",
    "# Engine for MySQL\n",
    "mysql_connection_string = f\"mysql+mysqlconnector://{mysql_user}:{mysql_password}@{mysql_host}:{mysql_port}/{mysql_database}\"\n",
    "mysql_engine = create_engine(mysql_connection_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # START OF FUNCTIONS\n",
    "\n",
    "def extract_additional_hr(file, sheet_name):\n",
    "  df = pd.read_excel(file, sheet_name = sheet_name)\n",
    "  df = df.dropna(subset=['Employee ID'])\n",
    "\n",
    "  if df['Employee ID'].dtypes == 'object':\n",
    "    df['Employee ID'] = df['Employee ID'].str[:6]\n",
    "  df['Employee ID'] = df['Employee ID'].astype(int)\n",
    "\n",
    "  if df['Store'].dtypes == float:\n",
    "    df['Store'] = df['Store'].astype(int).astype(str)\n",
    "\n",
    "  df = df.fillna({'Add': 0, 'Add.1': 0,'Add.2': 0,'Add.3': 0,'Add.4': 0,'Add.5': 0,'Personal Leave': 0,'Annual Leave': 0,})\n",
    "  df['2012-11-01'] = df['Add'] + df['Add.1'] + df['Add.2'] + df['Add.3'] + df['Add.4'] + df['Add.5']\n",
    "  df['2013-01-01'] = df['Personal Leave'] + df['Annual Leave']\n",
    "  cols =[0,1,2, df.columns.tolist().index('2012-11-01'),df.columns.tolist().index('2013-01-01')]\n",
    "\n",
    "  df = df.iloc[:, cols]\n",
    "  df = df.dropna(subset=df.columns[:3], how='all')\n",
    "  df = df.melt(id_vars=['Employee ID', 'Store', 'Preferred Name'], value_vars=df.columns[3:], var_name='Date', value_name='Hours')\n",
    "  df = df[df['Hours'] != 0]\n",
    "  return df\n",
    "\n",
    "def extract_rostered_hr(file, sheet_name):\n",
    "  df = pd.read_excel(file, sheet_name = sheet_name)\n",
    "\n",
    "  df = df.dropna(subset=['Employee ID'])\n",
    "\n",
    "  if df['Employee ID'].dtypes == 'object':\n",
    "    df['Employee ID'] = df['Employee ID'].str[:6]\n",
    "  df['Employee ID'] = df['Employee ID'].astype(int)\n",
    "\n",
    "  if df['Store'].dtypes == float:\n",
    "    df['Store'] = df['Store'].astype(int).astype(str)\n",
    "\n",
    "  df = df.iloc[:, :24]\n",
    "  cols = [0,1,2]\n",
    "  for col in range(3, 24, 3):\n",
    "      df[df.columns[col]] = df[df.columns[col+2]]\n",
    "      cols.append(col)\n",
    "  df = df.iloc[:,cols]\n",
    "  df = df.dropna(subset=df.columns[:3], how='all')\n",
    "  df = df.melt(id_vars=['Employee ID', 'Store', 'Preferred Name'], value_vars=df.columns[3:], var_name='Date', value_name='Hours')\n",
    "  df = df[df['Hours'] != 0]\n",
    "  return df\n",
    "\n",
    "def calc_timesheets_n_billings(files):\n",
    "  print('calc')\n",
    "  timesheets = pd.DataFrame()\n",
    "  billings = pd.DataFrame()\n",
    "  rostered_hr = pd.DataFrame()\n",
    "  additional_hr = pd.DataFrame()\n",
    "\n",
    "  for file in files:\n",
    "    timesheet = pd.read_excel(file, sheet_name = 'Timesheet')\n",
    "    billing = pd.read_excel(file, sheet_name = 'Billing')\n",
    "    rostered_hr_w1 = extract_rostered_hr(file, 'Week 1 Roster')\n",
    "    rostered_hr_w2 = extract_rostered_hr(file, 'Week 2 Roster')\n",
    "    additional_hr_w1 = extract_additional_hr(file, 'Week 1 Roster')\n",
    "    additional_hr_w2 = extract_additional_hr(file, 'Week 2 Roster')\n",
    "    employees = pd.read_excel(file, sheet_name = 'Employees')\n",
    "\n",
    "    timesheets = pd.concat([timesheets, timesheet], ignore_index=True)\n",
    "    billings = pd.concat([billings, billing], ignore_index=True)\n",
    "    rostered_hr = pd.concat([rostered_hr, rostered_hr_w1], ignore_index=True)\n",
    "    rostered_hr = pd.concat([rostered_hr, rostered_hr_w2], ignore_index=True)\n",
    "    additional_hr = pd.concat([additional_hr, additional_hr_w1], ignore_index=True)\n",
    "    additional_hr = pd.concat([additional_hr, additional_hr_w2], ignore_index=True)\n",
    "\n",
    "    timesheets = pd.concat([timesheets, timesheet], ignore_index=True)\n",
    "    billings = pd.concat([billings, billing], ignore_index=True)\n",
    "    rostered_hr = pd.concat([rostered_hr, rostered_hr_w1], ignore_index=True)\n",
    "    rostered_hr = pd.concat([rostered_hr, rostered_hr_w2], ignore_index=True)\n",
    "    additional_hr = pd.concat([additional_hr, additional_hr_w1], ignore_index=True)\n",
    "    additional_hr = pd.concat([additional_hr, additional_hr_w2], ignore_index=True)\n",
    "\n",
    "  #Remov  e irrelevant rows\n",
    "  timesheets.dropna(subset = ['Employee ID'], inplace=True)\n",
    "  #Keep the needed columns\n",
    "  timesheets_cols = [1,2,3,7,8,9,10,11,12,13,14,15,16,17,18,19,20]\n",
    "  timesheets = timesheets[timesheets.columns[timesheets_cols]]\n",
    "  timesheets['Update Wage'] = timesheets['Update Wage'].astype(bool)\n",
    "  #Column Aggregations\n",
    "  timesheets_agg_cols = {'First Name':'first','Last Name':'first','Update Wage':'first','Hour Threshold':'first','Company':'first','Ord':'sum','Sat':'sum','Sun':'sum','Pub':'sum','Eve 1':'sum','Eve 2':'sum','No. of Shifts':'sum','Personal Leave':'sum','Annual Leave':'sum','Unpaid Leave':'sum','Total':'sum'}\n",
    "  timesheets = timesheets.groupby('Employee ID', as_index = False).agg(timesheets_agg_cols)\n",
    "  #Calculate Over Threshold\n",
    "  timesheets['Over Threshold'] = timesheets['Total'] - timesheets['Hour Threshold']\n",
    "  timesheets.loc[timesheets[\"Over Threshold\"] <=0, \"Over Threshold\"] = 0\n",
    "  #Keep Over Thresholds to a new df\n",
    "  over_threshold = timesheets[timesheets['Over Threshold']>0]\n",
    "  #Reduce Ord & Total with the excess\n",
    "  timesheets['Ord'] = timesheets['Ord'] - timesheets['Over Threshold']\n",
    "  timesheets['Total'] = timesheets['Total'] - timesheets['Over Threshold']\n",
    "  #Convert 80 & 100 hours to 76 hours\n",
    "  hours_col = ['Ord', 'Sat','Sun','Eve 1','Eve 2','Pub','Personal Leave', 'Annual Leave', 'Unpaid Leave', 'Total']\n",
    "  if(100 in timesheets[\"Hour Threshold\"].values):\n",
    "      timesheets.loc[timesheets[\"Hour Threshold\"] == 100, hours_col] = timesheets[hours_col]/100*76\n",
    "  if(80 in timesheets[\"Hour Threshold\"].values):\n",
    "      timesheets.loc[timesheets[\"Hour Threshold\"] == 80, hours_col] = timesheets[hours_col]/80*76\n",
    "  if any(timesheets[\"Hour Threshold\"] > 1000):\n",
    "  # Find rows where \"Hour Threshold\" is greater than 1000\n",
    "      rows_to_update = timesheets.loc[timesheets[\"Hour Threshold\"] > 1000]\n",
    "      # Perform actions on the rows\n",
    "      for index, row in rows_to_update.iterrows():\n",
    "          threshold = int(row[\"Hour Threshold\"])\n",
    "          base = int(str(threshold)[:2])\n",
    "          conversion = int(str(threshold)[-2:])\n",
    "          # Update multiple columns using .loc\n",
    "          timesheets.loc[index, hours_col] = timesheets.loc[index, hours_col] / conversion * base\n",
    "\n",
    "  #drop Hour Threshold & Over Threshold\n",
    "  timesheets = timesheets.drop(['Hour Threshold','Over Threshold'],axis = 1)\n",
    "\n",
    "  #Remove irrelevant rows\n",
    "  billings.dropna(subset=['Store'],inplace = True)\n",
    "  billings = billings[billings['Total'] > 0]\n",
    "\n",
    "  #Keep the needed columns\n",
    "  billings_cols = [0,1,2,3,4,5,6,7,8,9,10,11]\n",
    "  billings = billings[billings.columns[billings_cols]]\n",
    "  #Column Aggregations\n",
    "  billings_agg_cols = {'Ord':'sum','Sat':'sum','Sun':'sum','Pub':'sum','Eve 1':'sum','Eve 2':'sum','No. of Shifts':'sum','Personal Leave':'sum','Annual Leave':'sum','Unpaid Leave':'sum','Total':'sum'}\n",
    "  billings = billings.groupby('Store', as_index = False).agg(billings_agg_cols)\n",
    "\n",
    "  rostered_hr = pd.merge(rostered_hr, employees[['Employee ID', 'First Name', 'Last Name', 'Company']], how='left', on=['Employee ID'])\n",
    "  rostered_hr_col = [\n",
    "  'Employee ID',\n",
    "  'First Name',\n",
    "  'Last Name',\n",
    "  'Preferred Name',\n",
    "  'Company',\n",
    "  'Store',\n",
    "  'Date',\n",
    "  'Hours'\n",
    "  ]\n",
    "  rostered_hr = rostered_hr[rostered_hr_col]\n",
    "  rostered_hr['Date'] = pd.to_datetime(rostered_hr['Date'])\n",
    "\n",
    "  bonus = rostered_hr.copy()\n",
    "\n",
    "  # Stitch Store ID and drop rows which Store ID are not found\n",
    "  sheet_id = '1rqOeBjA9drmTnjlENvr57RqL5-oxSqe_KGdbdL2MKhM'\n",
    "  sheet_name = 'StoreReference'\n",
    "  url = f'https://docs.google.com/spreadsheets/d/{sheet_id}/gviz/tq?tqx=out:csv&sheet={sheet_name}'\n",
    "  store_ref = pd.read_csv(url)\n",
    "\n",
    "  bonus = pd.merge(bonus, store_ref, on=['Store'], how = 'left')\n",
    "\n",
    "  bonus.dropna(subset=['Store ID'], inplace = True)\n",
    "\n",
    "  # Stitch recid_plo\n",
    "  sheet_id = '1ezyBlKquUhYnFwmIKTR4fghI59ZvGaKL35mKbcdeRy4'\n",
    "  sheet_name = 'Stores'\n",
    "  url = f'https://docs.google.com/spreadsheets/d/{sheet_id}/gviz/tq?tqx=out:csv&sheet={sheet_name}'\n",
    "  store_df_gs = pd.read_csv(url)\n",
    "\n",
    "  bonus = pd.merge(bonus, store_df_gs[['Store ID', 'recid_plo']], on=['Store ID'], how = 'left')\n",
    "  bonus['recid_plo'] = bonus['recid_plo'].astype(int)\n",
    "\n",
    "  # Stich sales based on recid_plo & dates, skip if there is no Date\n",
    "  start = bonus['Date'].min()\n",
    "  end = bonus['Date'].max()\n",
    "\n",
    "  start_str = start.strftime('%Y-%m-%d')\n",
    "  end_str = end.strftime('%Y-%m-%d')\n",
    "\n",
    "  recid_plo_list = bonus['recid_plo'].unique().tolist()\n",
    "  recid_plo_list_str = ', '.join(str(id) for id in recid_plo_list)\n",
    "\n",
    "  tumbler_recid_plu_list = [1059,1060,1061,1062]\n",
    "  gingerbread_recid_plu_list = [485,559,572,573,574,575,1036,1085,1086]\n",
    "  stock_exclusions_list = tumbler_recid_plu_list + gingerbread_recid_plu_list\n",
    "  stock_exclusions_list_str = ', '.join(str(s) for s in stock_exclusions_list)\n",
    "\n",
    "  query = '''\n",
    "  SELECT ts2.recid_plo, ts.itemdate as Date, sum(ts.qty*ts.price) as Sales\n",
    "  FROM tbl_salesitems ts \n",
    "  JOIN tbl_salesheaders ts2 on ts.recid_mixh = ts2.recid\n",
    "  WHERE ts.itemdate >= '{start}' and ts.itemdate <= '{end}' and ts2.recid_plo in ({recid_plo_list}) and ts.recid_plu not in ({stock_exclusions_list})\n",
    "  GROUP BY ts2.recid_plo, ts.itemdate\n",
    "  ORDER BY ts.itemdate ASC, recid_plo ASC\n",
    "  '''.format(start=start_str, end = end_str, recid_plo_list = recid_plo_list_str, stock_exclusions_list = stock_exclusions_list_str)\n",
    "\n",
    "  sales_df = pd.read_sql(query, mysql_engine)\n",
    "  sales_df['Date'] = pd.to_datetime(sales_df['Date'])\n",
    "\n",
    "  bonus = pd.merge(bonus, sales_df[['recid_plo', 'Date', 'Sales']], on=['recid_plo', 'Date'], how = 'left')\n",
    "\n",
    "  # Stitch Target Sales & Bonus Rates\n",
    "  sheet_id = '1rqOeBjA9drmTnjlENvr57RqL5-oxSqe_KGdbdL2MKhM'\n",
    "  sheet_name = 'Targets'\n",
    "  url = f'https://docs.google.com/spreadsheets/d/{sheet_id}/gviz/tq?tqx=out:csv&sheet={sheet_name}'\n",
    "  targets = pd.read_csv(url)\n",
    "  targets['Date'] = pd.to_datetime(targets['Date'])\n",
    "\n",
    "  # Change Bonus Rates to 0, if Target Sales is not met\n",
    "  bonus = pd.merge(bonus, targets[['Store ID', 'Date', 'Target Sales', 'Bonus Rate']], on=['Store ID', 'Date'], how = 'left')\n",
    "  bonus['Bonus Rate'] = bonus['Bonus Rate'].where(bonus['Sales'] >= bonus['Target Sales'], 0)\n",
    "  bonus['Bonus'] = bonus['Bonus Rate']  * bonus['Hours']\n",
    "\n",
    "  # Work out additional_hr\n",
    "  additional_hr = additional_hr.dropna(subset=['Employee ID'])\n",
    "  additional_hr = pd.merge(additional_hr, employees[['Employee ID', 'First Name', 'Last Name', 'Company']], how='left', on=['Employee ID'])\n",
    "  additional_hr_col = [\n",
    "  'Employee ID',\n",
    "  'First Name',\n",
    "  'Last Name',\n",
    "  'Preferred Name',\n",
    "  'Company',\n",
    "  'Store',\n",
    "  'Date',\n",
    "  'Hours'\n",
    "  ]\n",
    "  additional_hr = additional_hr[additional_hr_col]\n",
    "  additional_hr['Date'] = pd.to_datetime(additional_hr['Date'])\n",
    "\n",
    "  # Concat rostered_hr and additional_hr\n",
    "  analysis = pd.concat([rostered_hr, additional_hr])\n",
    "\n",
    "  # Concat Bouns on to Timesheets\n",
    "  bonus_summary = bonus.groupby('Employee ID', as_index = False).agg({'Bonus':'sum'})\n",
    "  timesheets = pd.merge(timesheets, bonus_summary, on=['Employee ID'], how = 'left')\n",
    "  timesheets.fillna({'Bonus':0}, inplace = True)\n",
    "  timesheets.rename(columns={'Bonus':'Bonus $'}, inplace = True)\n",
    "\n",
    "  return timesheets, billings, over_threshold, analysis, bonus\n",
    "\n",
    "\n",
    "# # # END OF FUNCTIONS\n",
    "\n",
    "\n",
    "import io\n",
    "import streamlit as st\n",
    "\n",
    "st.title('Timesheet & Billing')\n",
    "\n",
    "uploaded_files = st.file_uploader(\"Choose Files\", accept_multiple_files = True)\n",
    "\n",
    "# Create an empty container\n",
    "output = st.empty()\n",
    "\n",
    "# if uploaded_files is not None:\n",
    "if len(uploaded_files) > 0:\n",
    "    ts, bl, ot, an, bo = calc_timesheets_n_billings(uploaded_files)\n",
    "\n",
    "    buffer = io.BytesIO()\n",
    "\n",
    "    with pd.ExcelWriter(buffer, engine='xlsxwriter') as writer:\n",
    "    # Write each dataframe to a different worksheet.\n",
    "        ts.to_excel(writer, sheet_name='Timesheet', index = False)\n",
    "        bl.to_excel(writer, sheet_name='Billing', index = False)\n",
    "        ot.to_excel(writer, sheet_name='Over Threshold', index = False)\n",
    "        an.to_excel(writer, sheet_name='Analysis',index = False)\n",
    "        bo.to_excel(writer, sheet_name='Bonus',index = False)\n",
    "\n",
    "    # Close the Pandas Excel writer and output the Excel file to the buffer\n",
    "    writer.close()\n",
    "\n",
    "    st.download_button(\n",
    "        label=\"Download\",\n",
    "        data=buffer,\n",
    "        file_name=\"Timesheet & Billing.xlsx\",\n",
    "        mime=\"application/vnd.ms-excel\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/eddy/Developer/Streamlit/roster-consolidation/files/Waterloo Final Roster 2201-0402.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "/usr/local/lib/python3.11/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "/usr/local/lib/python3.11/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "/usr/local/lib/python3.11/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/eddy/Developer/Streamlit/roster-consolidation/files/Eastwood Final Roster 2201-0402.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "/usr/local/lib/python3.11/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "/usr/local/lib/python3.11/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "/usr/local/lib/python3.11/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/eddy/Developer/Streamlit/roster-consolidation/files/GFP Final Roster 2201-0402.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "/usr/local/lib/python3.11/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "/usr/local/lib/python3.11/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "/usr/local/lib/python3.11/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/eddy/Developer/Streamlit/roster-consolidation/files/Myer Final Roster 2201-0402.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "/usr/local/lib/python3.11/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "/usr/local/lib/python3.11/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "/usr/local/lib/python3.11/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/eddy/Developer/Streamlit/roster-consolidation/files/Wsq Final Roster 2201-0402.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "/usr/local/lib/python3.11/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "/usr/local/lib/python3.11/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "/usr/local/lib/python3.11/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/eddy/Developer/Streamlit/roster-consolidation/files/One Hv Final Roster 2201-0402.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "/usr/local/lib/python3.11/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "/usr/local/lib/python3.11/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "/usr/local/lib/python3.11/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/eddy/Developer/Streamlit/roster-consolidation/files/Qvb Final Roster 2201-0402.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "/usr/local/lib/python3.11/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "/usr/local/lib/python3.11/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "/usr/local/lib/python3.11/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/eddy/Developer/Streamlit/roster-consolidation/files/Mc Final Roster 2201-0402.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "/usr/local/lib/python3.11/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "/usr/local/lib/python3.11/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "/usr/local/lib/python3.11/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/eddy/Developer/Streamlit/roster-consolidation/files/Bwy Final Roster 2201-0402.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "/usr/local/lib/python3.11/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "/usr/local/lib/python3.11/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "/usr/local/lib/python3.11/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/eddy/Developer/Streamlit/roster-consolidation/files/The Star Hot Star Final Roster 2201-0402.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "/usr/local/lib/python3.11/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "/usr/local/lib/python3.11/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "/usr/local/lib/python3.11/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/eddy/Developer/Streamlit/roster-consolidation/files/Gateway Final Roster 2201-0402.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "/usr/local/lib/python3.11/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "/usr/local/lib/python3.11/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "/usr/local/lib/python3.11/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/eddy/Developer/Streamlit/roster-consolidation/files/Hv Final Roster 2201-0402.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "/usr/local/lib/python3.11/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "/usr/local/lib/python3.11/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "/usr/local/lib/python3.11/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/eddy/Developer/Streamlit/roster-consolidation/files/The Star Final Roster 2201-0402.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "/usr/local/lib/python3.11/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "/usr/local/lib/python3.11/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "/usr/local/lib/python3.11/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/eddy/Developer/Streamlit/roster-consolidation/files/Plumpton Marsden Park Rouse Hill Final Roster 2201-0402.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "/usr/local/lib/python3.11/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "/usr/local/lib/python3.11/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "/usr/local/lib/python3.11/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/eddy/Developer/Streamlit/roster-consolidation/files/Ribbon Final Roster 2201-0402.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "/usr/local/lib/python3.11/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "/usr/local/lib/python3.11/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "/usr/local/lib/python3.11/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/eddy/Developer/Streamlit/roster-consolidation/files/Miranda Final Roster 2201-0402.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "/usr/local/lib/python3.11/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "/usr/local/lib/python3.11/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "/usr/local/lib/python3.11/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/eddy/Developer/Streamlit/roster-consolidation/files/Westfield Final Roster 2201-0402.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "/usr/local/lib/python3.11/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "/usr/local/lib/python3.11/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "/usr/local/lib/python3.11/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/eddy/Developer/Streamlit/roster-consolidation/files/501 Final Roster 2201-0402.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "/usr/local/lib/python3.11/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "/usr/local/lib/python3.11/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "/usr/local/lib/python3.11/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/eddy/Developer/Streamlit/roster-consolidation/files/Waterloo Hot Star Final Roster 2201-0402.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "/usr/local/lib/python3.11/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "/usr/local/lib/python3.11/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "/usr/local/lib/python3.11/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import openpyxl\n",
    "\n",
    "# Get absolute path of the current notebook's directory\n",
    "notebook_dir = os.getcwd()  # Get current working directory\n",
    "\n",
    "# Construct the path to the `/files/` folder\n",
    "files_dir = os.path.join(notebook_dir, \"files\")\n",
    "\n",
    "# List files in the directory\n",
    "files_names_dir = os.listdir(files_dir)\n",
    "\n",
    "timesheets = pd.DataFrame()\n",
    "billings = pd.DataFrame()\n",
    "rostered_hr = pd.DataFrame()\n",
    "additional_hr = pd.DataFrame()\n",
    "\n",
    "for filename in files_names_dir:\n",
    "    if filename.endswith(\".xlsx\"):\n",
    "        file = os.path.join(files_dir, filename)\n",
    "        print(file)\n",
    "        timesheet = pd.read_excel(file, sheet_name = 'Timesheet', engine='openpyxl')\n",
    "        billing = pd.read_excel(file, sheet_name = 'Billing', engine='openpyxl')\n",
    "        rostered_hr_w1 = extract_rostered_hr(file, 'Week 1 Roster')\n",
    "        rostered_hr_w2 = extract_rostered_hr(file, 'Week 2 Roster')\n",
    "        additional_hr_w1 = extract_additional_hr(file, 'Week 1 Roster')\n",
    "        additional_hr_w2 = extract_additional_hr(file, 'Week 2 Roster')\n",
    "        employees = pd.read_excel(file, sheet_name = 'Employees')\n",
    "\n",
    "    timesheets = pd.concat([timesheets, timesheet], ignore_index=True)\n",
    "    billings = pd.concat([billings, billing], ignore_index=True)\n",
    "    rostered_hr = pd.concat([rostered_hr, rostered_hr_w1], ignore_index=True)\n",
    "    rostered_hr = pd.concat([rostered_hr, rostered_hr_w2], ignore_index=True)\n",
    "    additional_hr = pd.concat([additional_hr, additional_hr_w1], ignore_index=True)\n",
    "    additional_hr = pd.concat([additional_hr, additional_hr_w2], ignore_index=True)\n",
    "\n",
    "#Remov  e irrelevant rows\n",
    "timesheets.dropna(subset = ['Employee ID'], inplace=True)\n",
    "#Keep the needed columns\n",
    "timesheets_cols = [1,2,3,7,8,9,10,11,12,13,14,15,16,17,18,19,20]\n",
    "timesheets = timesheets[timesheets.columns[timesheets_cols]]\n",
    "timesheets['Update Wage'] = timesheets['Update Wage'].astype(bool)\n",
    "#Column Aggregations\n",
    "timesheets_agg_cols = {'First Name':'first','Last Name':'first','Update Wage':'first','Hour Threshold':'first','Company':'first','Ord':'sum','Sat':'sum','Sun':'sum','Pub':'sum','Eve 1':'sum','Eve 2':'sum','No. of Shifts':'sum','Personal Leave':'sum','Annual Leave':'sum','Unpaid Leave':'sum','Total':'sum'}\n",
    "timesheets = timesheets.groupby('Employee ID', as_index = False).agg(timesheets_agg_cols)\n",
    "#Calculate Over Threshold\n",
    "timesheets['Over Threshold'] = timesheets['Total'] - timesheets['Hour Threshold']\n",
    "timesheets.loc[timesheets[\"Over Threshold\"] <=0, \"Over Threshold\"] = 0\n",
    "#Keep Over Thresholds to a new df\n",
    "over_threshold = timesheets[timesheets['Over Threshold']>0]\n",
    "#Reduce Ord & Total with the excess\n",
    "timesheets['Ord'] = timesheets['Ord'] - timesheets['Over Threshold']\n",
    "timesheets['Total'] = timesheets['Total'] - timesheets['Over Threshold']\n",
    "#Convert 80 & 100 hours to 76 hours\n",
    "hours_col = ['Ord', 'Sat','Sun','Eve 1','Eve 2','Pub','Personal Leave', 'Annual Leave', 'Unpaid Leave', 'Total']\n",
    "if(100 in timesheets[\"Hour Threshold\"].values):\n",
    "    timesheets.loc[timesheets[\"Hour Threshold\"] == 100, hours_col] = timesheets[hours_col]/100*76\n",
    "if(80 in timesheets[\"Hour Threshold\"].values):\n",
    "    timesheets.loc[timesheets[\"Hour Threshold\"] == 80, hours_col] = timesheets[hours_col]/80*76\n",
    "if any(timesheets[\"Hour Threshold\"] > 1000):\n",
    "# Find rows where \"Hour Threshold\" is greater than 1000\n",
    "    rows_to_update = timesheets.loc[timesheets[\"Hour Threshold\"] > 1000]\n",
    "    # Perform actions on the rows\n",
    "    for index, row in rows_to_update.iterrows():\n",
    "        threshold = int(row[\"Hour Threshold\"])\n",
    "        base = int(str(threshold)[:2])\n",
    "        conversion = int(str(threshold)[-2:])\n",
    "        # Update multiple columns using .loc\n",
    "        timesheets.loc[index, hours_col] = timesheets.loc[index, hours_col] / conversion * base\n",
    "\n",
    "#drop Hour Threshold & Over Threshold\n",
    "timesheets = timesheets.drop(['Hour Threshold','Over Threshold'],axis = 1)\n",
    "\n",
    "#Remove irrelevant rows\n",
    "billings.dropna(subset=['Store'],inplace = True)\n",
    "billings = billings[billings['Total'] > 0]\n",
    "\n",
    "#Keep the needed columns\n",
    "billings_cols = [0,1,2,3,4,5,6,7,8,9,10,11]\n",
    "billings = billings[billings.columns[billings_cols]]\n",
    "#Column Aggregations\n",
    "billings_agg_cols = {'Ord':'sum','Sat':'sum','Sun':'sum','Pub':'sum','Eve 1':'sum','Eve 2':'sum','No. of Shifts':'sum','Personal Leave':'sum','Annual Leave':'sum','Unpaid Leave':'sum','Total':'sum'}\n",
    "billings = billings.groupby('Store', as_index = False).agg(billings_agg_cols)\n",
    "\n",
    "rostered_hr = pd.merge(rostered_hr, employees[['Employee ID', 'First Name', 'Last Name', 'Company']], how='left', on=['Employee ID'])\n",
    "rostered_hr_col = [\n",
    "'Employee ID',\n",
    "'First Name',\n",
    "'Last Name',\n",
    "'Preferred Name',\n",
    "'Company',\n",
    "'Store',\n",
    "'Date',\n",
    "'Hours'\n",
    "]\n",
    "rostered_hr = rostered_hr[rostered_hr_col]\n",
    "rostered_hr['Date'] = pd.to_datetime(rostered_hr['Date'])\n",
    "\n",
    "bonus = rostered_hr.copy()\n",
    "\n",
    "# Stitch Store ID and drop rows which Store ID are not found\n",
    "sheet_id = '1rqOeBjA9drmTnjlENvr57RqL5-oxSqe_KGdbdL2MKhM'\n",
    "sheet_name = 'StoreReference'\n",
    "url = f'https://docs.google.com/spreadsheets/d/{sheet_id}/gviz/tq?tqx=out:csv&sheet={sheet_name}'\n",
    "store_ref = pd.read_csv(url)\n",
    "\n",
    "bonus = pd.merge(bonus, store_ref, on=['Store'], how = 'left')\n",
    "\n",
    "bonus.dropna(subset=['Store ID'], inplace = True)\n",
    "\n",
    "# Stitch recid_plo\n",
    "sheet_id = '1ezyBlKquUhYnFwmIKTR4fghI59ZvGaKL35mKbcdeRy4'\n",
    "sheet_name = 'Stores'\n",
    "url = f'https://docs.google.com/spreadsheets/d/{sheet_id}/gviz/tq?tqx=out:csv&sheet={sheet_name}'\n",
    "store_df_gs = pd.read_csv(url)\n",
    "\n",
    "bonus = pd.merge(bonus, store_df_gs[['Store ID', 'recid_plo']], on=['Store ID'], how = 'left')\n",
    "bonus['recid_plo'] = bonus['recid_plo'].astype(int)\n",
    "\n",
    "# Stich sales based on recid_plo & dates, skip if there is no Date\n",
    "start = bonus['Date'].min()\n",
    "end = bonus['Date'].max()\n",
    "\n",
    "start_str = start.strftime('%Y-%m-%d')\n",
    "end_str = end.strftime('%Y-%m-%d')\n",
    "\n",
    "recid_plo_list = bonus['recid_plo'].unique().tolist()\n",
    "recid_plo_list_str = ', '.join(str(id) for id in recid_plo_list)\n",
    "\n",
    "tumbler_recid_plu_list = [1059,1060,1061,1062]\n",
    "gingerbread_recid_plu_list = [485,559,572,573,574,575,1036,1085,1086]\n",
    "stock_exclusions_list = tumbler_recid_plu_list + gingerbread_recid_plu_list\n",
    "stock_exclusions_list_str = ', '.join(str(s) for s in stock_exclusions_list)\n",
    "\n",
    "query = '''\n",
    "SELECT ts2.recid_plo, ts.itemdate as Date, sum(ts.qty*ts.price) as Sales\n",
    "FROM tbl_salesitems ts \n",
    "JOIN tbl_salesheaders ts2 on ts.recid_mixh = ts2.recid\n",
    "WHERE ts.itemdate >= '{start}' and ts.itemdate <= '{end}' and ts2.recid_plo in ({recid_plo_list}) and ts.recid_plu not in ({stock_exclusions_list})\n",
    "GROUP BY ts2.recid_plo, ts.itemdate\n",
    "ORDER BY ts.itemdate ASC, recid_plo ASC\n",
    "'''.format(start=start_str, end = end_str, recid_plo_list = recid_plo_list_str, stock_exclusions_list = stock_exclusions_list_str)\n",
    "\n",
    "sales_df = pd.read_sql(query, mysql_engine)\n",
    "sales_df['Date'] = pd.to_datetime(sales_df['Date'])\n",
    "\n",
    "bonus = pd.merge(bonus, sales_df[['recid_plo', 'Date', 'Sales']], on=['recid_plo', 'Date'], how = 'left')\n",
    "\n",
    "# Stitch Target Sales & Bonus Rates\n",
    "sheet_id = '1rqOeBjA9drmTnjlENvr57RqL5-oxSqe_KGdbdL2MKhM'\n",
    "sheet_name = 'Targets'\n",
    "url = f'https://docs.google.com/spreadsheets/d/{sheet_id}/gviz/tq?tqx=out:csv&sheet={sheet_name}'\n",
    "targets = pd.read_csv(url)\n",
    "targets['Date'] = pd.to_datetime(targets['Date'])\n",
    "\n",
    "# Change Bonus Rates to 0, if Target Sales is not met\n",
    "bonus = pd.merge(bonus, targets[['Store ID', 'Date', 'Target Sales', 'Bonus Rate']], on=['Store ID', 'Date'], how = 'left')\n",
    "bonus['Bonus Rate'] = bonus['Bonus Rate'].where(bonus['Sales'] >= bonus['Target Sales'], 0)\n",
    "bonus['Bonus'] = bonus['Bonus Rate']  * bonus['Hours']\n",
    "\n",
    "# Work out additional_hr\n",
    "additional_hr = additional_hr.dropna(subset=['Employee ID'])\n",
    "additional_hr = pd.merge(additional_hr, employees[['Employee ID', 'First Name', 'Last Name', 'Company']], how='left', on=['Employee ID'])\n",
    "additional_hr_col = [\n",
    "'Employee ID',\n",
    "'First Name',\n",
    "'Last Name',\n",
    "'Preferred Name',\n",
    "'Company',\n",
    "'Store',\n",
    "'Date',\n",
    "'Hours'\n",
    "]\n",
    "additional_hr = additional_hr[additional_hr_col]\n",
    "additional_hr['Date'] = pd.to_datetime(additional_hr['Date'])\n",
    "\n",
    "# Concat rostered_hr and additional_hr\n",
    "analysis = pd.concat([rostered_hr, additional_hr])\n",
    "\n",
    "# Concat Bouns on to Timesheets\n",
    "bonus_summary = bonus.groupby('Employee ID', as_index = False).agg({'Bonus':'sum'})\n",
    "timesheets = pd.merge(timesheets, bonus_summary, on=['Employee ID'], how = 'left')\n",
    "timesheets.fillna({'Bonus':0}, inplace = True)\n",
    "timesheets.rename(columns={'Bonus':'Bonus $'}, inplace = True)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    ", , , , "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Employee ID</th>\n",
       "      <th>First Name</th>\n",
       "      <th>Last Name</th>\n",
       "      <th>Preferred Name</th>\n",
       "      <th>Company</th>\n",
       "      <th>Store</th>\n",
       "      <th>Date</th>\n",
       "      <th>Hours</th>\n",
       "      <th>Store ID</th>\n",
       "      <th>recid_plo</th>\n",
       "      <th>Sales</th>\n",
       "      <th>Target Sales</th>\n",
       "      <th>Bonus Rate</th>\n",
       "      <th>Bonus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10035</td>\n",
       "      <td>Shanzhi</td>\n",
       "      <td>Chen</td>\n",
       "      <td>CHLOE CHEN</td>\n",
       "      <td>GCM</td>\n",
       "      <td>Waterloo</td>\n",
       "      <td>2024-01-22</td>\n",
       "      <td>8.5</td>\n",
       "      <td>S164</td>\n",
       "      <td>154</td>\n",
       "      <td>NaN</td>\n",
       "      <td>724.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10035</td>\n",
       "      <td>Shanzhi</td>\n",
       "      <td>Chen</td>\n",
       "      <td>CHLOE CHEN</td>\n",
       "      <td>GCM</td>\n",
       "      <td>Waterloo</td>\n",
       "      <td>2024-01-22</td>\n",
       "      <td>8.5</td>\n",
       "      <td>S164</td>\n",
       "      <td>154</td>\n",
       "      <td>NaN</td>\n",
       "      <td>784.39</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10052</td>\n",
       "      <td>Yeyu</td>\n",
       "      <td>Deng</td>\n",
       "      <td>DEREK DENG</td>\n",
       "      <td>GCM</td>\n",
       "      <td>Waterloo</td>\n",
       "      <td>2024-01-22</td>\n",
       "      <td>6.0</td>\n",
       "      <td>S164</td>\n",
       "      <td>154</td>\n",
       "      <td>NaN</td>\n",
       "      <td>724.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10052</td>\n",
       "      <td>Yeyu</td>\n",
       "      <td>Deng</td>\n",
       "      <td>DEREK DENG</td>\n",
       "      <td>GCM</td>\n",
       "      <td>Waterloo</td>\n",
       "      <td>2024-01-22</td>\n",
       "      <td>6.0</td>\n",
       "      <td>S164</td>\n",
       "      <td>154</td>\n",
       "      <td>NaN</td>\n",
       "      <td>784.39</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10299</td>\n",
       "      <td>YUTANG</td>\n",
       "      <td>HUANG</td>\n",
       "      <td>RYAN HUANG</td>\n",
       "      <td>GCM</td>\n",
       "      <td>Waterloo</td>\n",
       "      <td>2024-01-23</td>\n",
       "      <td>7.5</td>\n",
       "      <td>S164</td>\n",
       "      <td>154</td>\n",
       "      <td>NaN</td>\n",
       "      <td>978.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1803</th>\n",
       "      <td>10343</td>\n",
       "      <td>Theresa</td>\n",
       "      <td>Chow</td>\n",
       "      <td>Theresa chow</td>\n",
       "      <td>SS</td>\n",
       "      <td>501</td>\n",
       "      <td>2024-02-04</td>\n",
       "      <td>6.5</td>\n",
       "      <td>S001</td>\n",
       "      <td>124</td>\n",
       "      <td>5592.42</td>\n",
       "      <td>8213.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1804</th>\n",
       "      <td>10054</td>\n",
       "      <td>Yiran</td>\n",
       "      <td>Zhang</td>\n",
       "      <td>Eos zhang</td>\n",
       "      <td>SS</td>\n",
       "      <td>501</td>\n",
       "      <td>2024-02-04</td>\n",
       "      <td>7.5</td>\n",
       "      <td>S001</td>\n",
       "      <td>124</td>\n",
       "      <td>5592.42</td>\n",
       "      <td>7581.97</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1805</th>\n",
       "      <td>10054</td>\n",
       "      <td>Yiran</td>\n",
       "      <td>Zhang</td>\n",
       "      <td>Eos zhang</td>\n",
       "      <td>SS</td>\n",
       "      <td>501</td>\n",
       "      <td>2024-02-04</td>\n",
       "      <td>7.5</td>\n",
       "      <td>S001</td>\n",
       "      <td>124</td>\n",
       "      <td>5592.42</td>\n",
       "      <td>8213.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1806</th>\n",
       "      <td>10334</td>\n",
       "      <td>Huy Tien</td>\n",
       "      <td>Phan</td>\n",
       "      <td>Pat phan</td>\n",
       "      <td>SS</td>\n",
       "      <td>501</td>\n",
       "      <td>2024-02-04</td>\n",
       "      <td>7.5</td>\n",
       "      <td>S001</td>\n",
       "      <td>124</td>\n",
       "      <td>5592.42</td>\n",
       "      <td>7581.97</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1807</th>\n",
       "      <td>10334</td>\n",
       "      <td>Huy Tien</td>\n",
       "      <td>Phan</td>\n",
       "      <td>Pat phan</td>\n",
       "      <td>SS</td>\n",
       "      <td>501</td>\n",
       "      <td>2024-02-04</td>\n",
       "      <td>7.5</td>\n",
       "      <td>S001</td>\n",
       "      <td>124</td>\n",
       "      <td>5592.42</td>\n",
       "      <td>8213.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1808 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Employee ID First Name Last Name Preferred Name Company     Store  \\\n",
       "0           10035    Shanzhi      Chen     CHLOE CHEN     GCM  Waterloo   \n",
       "1           10035    Shanzhi      Chen     CHLOE CHEN     GCM  Waterloo   \n",
       "2           10052       Yeyu      Deng     DEREK DENG     GCM  Waterloo   \n",
       "3           10052       Yeyu      Deng     DEREK DENG     GCM  Waterloo   \n",
       "4           10299     YUTANG     HUANG     RYAN HUANG     GCM  Waterloo   \n",
       "...           ...        ...       ...            ...     ...       ...   \n",
       "1803        10343    Theresa      Chow   Theresa chow      SS       501   \n",
       "1804        10054      Yiran     Zhang      Eos zhang      SS       501   \n",
       "1805        10054      Yiran     Zhang      Eos zhang      SS       501   \n",
       "1806        10334   Huy Tien      Phan       Pat phan      SS       501   \n",
       "1807        10334   Huy Tien      Phan       Pat phan      SS       501   \n",
       "\n",
       "           Date  Hours Store ID  recid_plo    Sales  Target Sales  Bonus Rate  \\\n",
       "0    2024-01-22    8.5     S164        154      NaN        724.06         0.0   \n",
       "1    2024-01-22    8.5     S164        154      NaN        784.39         0.0   \n",
       "2    2024-01-22    6.0     S164        154      NaN        724.06         0.0   \n",
       "3    2024-01-22    6.0     S164        154      NaN        784.39         0.0   \n",
       "4    2024-01-23    7.5     S164        154      NaN        978.01         0.0   \n",
       "...         ...    ...      ...        ...      ...           ...         ...   \n",
       "1803 2024-02-04    6.5     S001        124  5592.42       8213.80         0.0   \n",
       "1804 2024-02-04    7.5     S001        124  5592.42       7581.97         0.0   \n",
       "1805 2024-02-04    7.5     S001        124  5592.42       8213.80         0.0   \n",
       "1806 2024-02-04    7.5     S001        124  5592.42       7581.97         0.0   \n",
       "1807 2024-02-04    7.5     S001        124  5592.42       8213.80         0.0   \n",
       "\n",
       "      Bonus  \n",
       "0       0.0  \n",
       "1       0.0  \n",
       "2       0.0  \n",
       "3       0.0  \n",
       "4       0.0  \n",
       "...     ...  \n",
       "1803    0.0  \n",
       "1804    0.0  \n",
       "1805    0.0  \n",
       "1806    0.0  \n",
       "1807    0.0  \n",
       "\n",
       "[1808 rows x 14 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bonus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Employee ID</th>\n",
       "      <th>First Name</th>\n",
       "      <th>Last Name</th>\n",
       "      <th>Preferred Name</th>\n",
       "      <th>Company</th>\n",
       "      <th>Store</th>\n",
       "      <th>Date</th>\n",
       "      <th>Hours</th>\n",
       "      <th>Store ID</th>\n",
       "      <th>recid_plo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10035</td>\n",
       "      <td>Shanzhi</td>\n",
       "      <td>Chen</td>\n",
       "      <td>CHLOE CHEN</td>\n",
       "      <td>GCM</td>\n",
       "      <td>Waterloo</td>\n",
       "      <td>2024-01-22</td>\n",
       "      <td>8.5</td>\n",
       "      <td>S164</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10052</td>\n",
       "      <td>Yeyu</td>\n",
       "      <td>Deng</td>\n",
       "      <td>DEREK DENG</td>\n",
       "      <td>GCM</td>\n",
       "      <td>Waterloo</td>\n",
       "      <td>2024-01-22</td>\n",
       "      <td>6.0</td>\n",
       "      <td>S164</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10299</td>\n",
       "      <td>YUTANG</td>\n",
       "      <td>HUANG</td>\n",
       "      <td>RYAN HUANG</td>\n",
       "      <td>GCM</td>\n",
       "      <td>Waterloo</td>\n",
       "      <td>2024-01-23</td>\n",
       "      <td>7.5</td>\n",
       "      <td>S164</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10052</td>\n",
       "      <td>Yeyu</td>\n",
       "      <td>Deng</td>\n",
       "      <td>DEREK DENG</td>\n",
       "      <td>GCM</td>\n",
       "      <td>Waterloo</td>\n",
       "      <td>2024-01-23</td>\n",
       "      <td>7.0</td>\n",
       "      <td>S164</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10052</td>\n",
       "      <td>Yeyu</td>\n",
       "      <td>Deng</td>\n",
       "      <td>DEREK DENG</td>\n",
       "      <td>GCM</td>\n",
       "      <td>Waterloo</td>\n",
       "      <td>2024-01-24</td>\n",
       "      <td>14.5</td>\n",
       "      <td>S164</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>917</th>\n",
       "      <td>10276</td>\n",
       "      <td>Cana</td>\n",
       "      <td>Fukuda</td>\n",
       "      <td>Cana fukuda</td>\n",
       "      <td>GCM</td>\n",
       "      <td>501</td>\n",
       "      <td>2024-02-04</td>\n",
       "      <td>9.0</td>\n",
       "      <td>S001</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>918</th>\n",
       "      <td>10303</td>\n",
       "      <td>Trong Van</td>\n",
       "      <td>Le</td>\n",
       "      <td>Van le</td>\n",
       "      <td>HL</td>\n",
       "      <td>501</td>\n",
       "      <td>2024-02-04</td>\n",
       "      <td>5.0</td>\n",
       "      <td>S001</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>919</th>\n",
       "      <td>10343</td>\n",
       "      <td>Theresa</td>\n",
       "      <td>Chow</td>\n",
       "      <td>Theresa chow</td>\n",
       "      <td>SS</td>\n",
       "      <td>501</td>\n",
       "      <td>2024-02-04</td>\n",
       "      <td>6.5</td>\n",
       "      <td>S001</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>920</th>\n",
       "      <td>10054</td>\n",
       "      <td>Yiran</td>\n",
       "      <td>Zhang</td>\n",
       "      <td>Eos zhang</td>\n",
       "      <td>SS</td>\n",
       "      <td>501</td>\n",
       "      <td>2024-02-04</td>\n",
       "      <td>7.5</td>\n",
       "      <td>S001</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>921</th>\n",
       "      <td>10334</td>\n",
       "      <td>Huy Tien</td>\n",
       "      <td>Phan</td>\n",
       "      <td>Pat phan</td>\n",
       "      <td>SS</td>\n",
       "      <td>501</td>\n",
       "      <td>2024-02-04</td>\n",
       "      <td>7.5</td>\n",
       "      <td>S001</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>922 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Employee ID First Name Last Name Preferred Name Company     Store  \\\n",
       "0          10035    Shanzhi      Chen     CHLOE CHEN     GCM  Waterloo   \n",
       "1          10052       Yeyu      Deng     DEREK DENG     GCM  Waterloo   \n",
       "2          10299     YUTANG     HUANG     RYAN HUANG     GCM  Waterloo   \n",
       "3          10052       Yeyu      Deng     DEREK DENG     GCM  Waterloo   \n",
       "4          10052       Yeyu      Deng     DEREK DENG     GCM  Waterloo   \n",
       "..           ...        ...       ...            ...     ...       ...   \n",
       "917        10276       Cana    Fukuda    Cana fukuda     GCM       501   \n",
       "918        10303  Trong Van        Le         Van le      HL       501   \n",
       "919        10343    Theresa      Chow   Theresa chow      SS       501   \n",
       "920        10054      Yiran     Zhang      Eos zhang      SS       501   \n",
       "921        10334   Huy Tien      Phan       Pat phan      SS       501   \n",
       "\n",
       "          Date  Hours Store ID  recid_plo  \n",
       "0   2024-01-22    8.5     S164        154  \n",
       "1   2024-01-22    6.0     S164        154  \n",
       "2   2024-01-23    7.5     S164        154  \n",
       "3   2024-01-23    7.0     S164        154  \n",
       "4   2024-01-24   14.5     S164        154  \n",
       "..         ...    ...      ...        ...  \n",
       "917 2024-02-04    9.0     S001        124  \n",
       "918 2024-02-04    5.0     S001        124  \n",
       "919 2024-02-04    6.5     S001        124  \n",
       "920 2024-02-04    7.5     S001        124  \n",
       "921 2024-02-04    7.5     S001        124  \n",
       "\n",
       "[922 rows x 10 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Employee ID</th>\n",
       "      <th>First Name</th>\n",
       "      <th>Last Name</th>\n",
       "      <th>Preferred Name</th>\n",
       "      <th>Company</th>\n",
       "      <th>Store</th>\n",
       "      <th>Date</th>\n",
       "      <th>Hours</th>\n",
       "      <th>Store ID</th>\n",
       "      <th>recid_plo</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10035</td>\n",
       "      <td>Shanzhi</td>\n",
       "      <td>Chen</td>\n",
       "      <td>CHLOE CHEN</td>\n",
       "      <td>GCM</td>\n",
       "      <td>Waterloo</td>\n",
       "      <td>2024-01-22</td>\n",
       "      <td>8.5</td>\n",
       "      <td>S164</td>\n",
       "      <td>154</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10052</td>\n",
       "      <td>Yeyu</td>\n",
       "      <td>Deng</td>\n",
       "      <td>DEREK DENG</td>\n",
       "      <td>GCM</td>\n",
       "      <td>Waterloo</td>\n",
       "      <td>2024-01-22</td>\n",
       "      <td>6.0</td>\n",
       "      <td>S164</td>\n",
       "      <td>154</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10299</td>\n",
       "      <td>YUTANG</td>\n",
       "      <td>HUANG</td>\n",
       "      <td>RYAN HUANG</td>\n",
       "      <td>GCM</td>\n",
       "      <td>Waterloo</td>\n",
       "      <td>2024-01-23</td>\n",
       "      <td>7.5</td>\n",
       "      <td>S164</td>\n",
       "      <td>154</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10052</td>\n",
       "      <td>Yeyu</td>\n",
       "      <td>Deng</td>\n",
       "      <td>DEREK DENG</td>\n",
       "      <td>GCM</td>\n",
       "      <td>Waterloo</td>\n",
       "      <td>2024-01-23</td>\n",
       "      <td>7.0</td>\n",
       "      <td>S164</td>\n",
       "      <td>154</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10052</td>\n",
       "      <td>Yeyu</td>\n",
       "      <td>Deng</td>\n",
       "      <td>DEREK DENG</td>\n",
       "      <td>GCM</td>\n",
       "      <td>Waterloo</td>\n",
       "      <td>2024-01-24</td>\n",
       "      <td>14.5</td>\n",
       "      <td>S164</td>\n",
       "      <td>154</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>917</th>\n",
       "      <td>10276</td>\n",
       "      <td>Cana</td>\n",
       "      <td>Fukuda</td>\n",
       "      <td>Cana fukuda</td>\n",
       "      <td>GCM</td>\n",
       "      <td>501</td>\n",
       "      <td>2024-02-04</td>\n",
       "      <td>9.0</td>\n",
       "      <td>S001</td>\n",
       "      <td>124</td>\n",
       "      <td>5592.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>918</th>\n",
       "      <td>10303</td>\n",
       "      <td>Trong Van</td>\n",
       "      <td>Le</td>\n",
       "      <td>Van le</td>\n",
       "      <td>HL</td>\n",
       "      <td>501</td>\n",
       "      <td>2024-02-04</td>\n",
       "      <td>5.0</td>\n",
       "      <td>S001</td>\n",
       "      <td>124</td>\n",
       "      <td>5592.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>919</th>\n",
       "      <td>10343</td>\n",
       "      <td>Theresa</td>\n",
       "      <td>Chow</td>\n",
       "      <td>Theresa chow</td>\n",
       "      <td>SS</td>\n",
       "      <td>501</td>\n",
       "      <td>2024-02-04</td>\n",
       "      <td>6.5</td>\n",
       "      <td>S001</td>\n",
       "      <td>124</td>\n",
       "      <td>5592.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>920</th>\n",
       "      <td>10054</td>\n",
       "      <td>Yiran</td>\n",
       "      <td>Zhang</td>\n",
       "      <td>Eos zhang</td>\n",
       "      <td>SS</td>\n",
       "      <td>501</td>\n",
       "      <td>2024-02-04</td>\n",
       "      <td>7.5</td>\n",
       "      <td>S001</td>\n",
       "      <td>124</td>\n",
       "      <td>5592.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>921</th>\n",
       "      <td>10334</td>\n",
       "      <td>Huy Tien</td>\n",
       "      <td>Phan</td>\n",
       "      <td>Pat phan</td>\n",
       "      <td>SS</td>\n",
       "      <td>501</td>\n",
       "      <td>2024-02-04</td>\n",
       "      <td>7.5</td>\n",
       "      <td>S001</td>\n",
       "      <td>124</td>\n",
       "      <td>5592.42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>922 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Employee ID First Name Last Name Preferred Name Company     Store  \\\n",
       "0          10035    Shanzhi      Chen     CHLOE CHEN     GCM  Waterloo   \n",
       "1          10052       Yeyu      Deng     DEREK DENG     GCM  Waterloo   \n",
       "2          10299     YUTANG     HUANG     RYAN HUANG     GCM  Waterloo   \n",
       "3          10052       Yeyu      Deng     DEREK DENG     GCM  Waterloo   \n",
       "4          10052       Yeyu      Deng     DEREK DENG     GCM  Waterloo   \n",
       "..           ...        ...       ...            ...     ...       ...   \n",
       "917        10276       Cana    Fukuda    Cana fukuda     GCM       501   \n",
       "918        10303  Trong Van        Le         Van le      HL       501   \n",
       "919        10343    Theresa      Chow   Theresa chow      SS       501   \n",
       "920        10054      Yiran     Zhang      Eos zhang      SS       501   \n",
       "921        10334   Huy Tien      Phan       Pat phan      SS       501   \n",
       "\n",
       "          Date  Hours Store ID  recid_plo    Sales  \n",
       "0   2024-01-22    8.5     S164        154      NaN  \n",
       "1   2024-01-22    6.0     S164        154      NaN  \n",
       "2   2024-01-23    7.5     S164        154      NaN  \n",
       "3   2024-01-23    7.0     S164        154      NaN  \n",
       "4   2024-01-24   14.5     S164        154      NaN  \n",
       "..         ...    ...      ...        ...      ...  \n",
       "917 2024-02-04    9.0     S001        124  5592.42  \n",
       "918 2024-02-04    5.0     S001        124  5592.42  \n",
       "919 2024-02-04    6.5     S001        124  5592.42  \n",
       "920 2024-02-04    7.5     S001        124  5592.42  \n",
       "921 2024-02-04    7.5     S001        124  5592.42  \n",
       "\n",
       "[922 rows x 11 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bonus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calc_timesheets_n_billings(files):\n",
    "  print('calc')\n",
    "  timesheets = pd.DataFrame()\n",
    "  billings = pd.DataFrame()\n",
    "  rostered_hr = pd.DataFrame()\n",
    "  additional_hr = pd.DataFrame()\n",
    "\n",
    "  for file in files:\n",
    "    # time.sleep(1)\n",
    "    timesheet = pd.read_excel(file, sheet_name = 'Timesheet')\n",
    "    billing = pd.read_excel(file, sheet_name = 'Billing')\n",
    "    rostered_hr_w1 = extract_rostered_hr(file, 'Week 1 Roster')\n",
    "    rostered_hr_w2 = extract_rostered_hr(file, 'Week 2 Roster')\n",
    "    additional_hr_w1 = extract_additional_hr(file, 'Week 1 Roster')\n",
    "    additional_hr_w2 = extract_additional_hr(file, 'Week 2 Roster')\n",
    "    employees = pd.read_excel(file, sheet_name = 'Employees')\n",
    "\n",
    "    timesheets = pd.concat([timesheets, timesheet], ignore_index=True)\n",
    "    billings = pd.concat([billings, billing], ignore_index=True)\n",
    "    rostered_hr = pd.concat([rostered_hr, rostered_hr_w1], ignore_index=True)\n",
    "    rostered_hr = pd.concat([rostered_hr, rostered_hr_w2], ignore_index=True)\n",
    "    additional_hr = pd.concat([additional_hr, additional_hr_w1], ignore_index=True)\n",
    "    additional_hr = pd.concat([additional_hr, additional_hr_w2], ignore_index=True)\n",
    "\n",
    "  #Remove irrelevant rows\n",
    "  timesheets.dropna(subset = ['Employee ID'], inplace=True)\n",
    "  #Keep the needed columns\n",
    "  timesheets_cols = [1,2,3,7,8,9,10,11,12,13,14,15,16,17,18,19,20]\n",
    "  timesheets = timesheets[timesheets.columns[timesheets_cols]]\n",
    "  timesheets['Update Wage'] = timesheets['Update Wage'].astype(bool)\n",
    "  #Column Aggregations\n",
    "  timesheets_agg_cols = {'First Name':'first','Last Name':'first','Update Wage':'first','Hour Threshold':'first','Company':'first','Ord':'sum','Sat':'sum','Sun':'sum','Pub':'sum','Eve 1':'sum','Eve 2':'sum','No. of Shifts':'sum','Personal Leave':'sum','Annual Leave':'sum','Unpaid Leave':'sum','Total':'sum'}\n",
    "  timesheets = timesheets.groupby('Employee ID', as_index = False).agg(timesheets_agg_cols)\n",
    "  #Calculate Over Threshold\n",
    "  timesheets['Over Threshold'] = timesheets['Total'] - timesheets['Hour Threshold']\n",
    "  timesheets.loc[timesheets[\"Over Threshold\"] <=0, \"Over Threshold\"] = 0\n",
    "  #Keep Over Thresholds to a new df\n",
    "  over_threshold = timesheets[timesheets['Over Threshold']>0]\n",
    "  #Reduce Ord & Total with the excess\n",
    "  timesheets['Ord'] = timesheets['Ord'] - timesheets['Over Threshold']\n",
    "  timesheets['Total'] = timesheets['Total'] - timesheets['Over Threshold']\n",
    "  #Convert 80 & 100 hours to 76 hours\n",
    "  hours_col = ['Ord', 'Sat','Sun','Eve 1','Eve 2','Pub','Personal Leave', 'Annual Leave', 'Unpaid Leave', 'Total']\n",
    "  if(100 in timesheets[\"Hour Threshold\"].values):\n",
    "    timesheets.loc[timesheets[\"Hour Threshold\"] == 100, hours_col] = timesheets[hours_col]/100*76\n",
    "  if(80 in timesheets[\"Hour Threshold\"].values):\n",
    "    timesheets.loc[timesheets[\"Hour Threshold\"] == 80, hours_col] = timesheets[hours_col]/80*76\n",
    "  if any(timesheets[\"Hour Threshold\"] > 1000):\n",
    "    # Find rows where \"Hour Threshold\" is greater than 1000\n",
    "    rows_to_update = timesheets.loc[timesheets[\"Hour Threshold\"] > 1000]\n",
    "    # Perform actions on the rows\n",
    "    for index, row in rows_to_update.iterrows():\n",
    "      threshold = int(row[\"Hour Threshold\"])\n",
    "      base = int(str(threshold)[:2])\n",
    "      # print('before conversion')\n",
    "      conversion = int(str(threshold)[-2:])\n",
    "      # print('after conversion')\n",
    "      # Update multiple columns using .loc\n",
    "      timesheets.loc[index, hours_col] = timesheets.loc[index, hours_col] / conversion * base\n",
    "\n",
    "  #drop Hour Threshold & Over Threshold\n",
    "  timesheets = timesheets.drop(['Hour Threshold','Over Threshold'],axis = 1)\n",
    "\n",
    "  #Remove irrelevant rows\n",
    "  billings.dropna(subset=['Store'],inplace = True)\n",
    "  billings = billings[billings['Total'] > 0]\n",
    "\n",
    "  #Keep the needed columns\n",
    "  billings_cols = [0,1,2,3,4,5,6,7,8,9,10,11]\n",
    "  billings = billings[billings.columns[billings_cols]]\n",
    "  #Column Aggregations\n",
    "  billings_agg_cols = {'Ord':'sum','Sat':'sum','Sun':'sum','Pub':'sum','Eve 1':'sum','Eve 2':'sum','No. of Shifts':'sum','Personal Leave':'sum','Annual Leave':'sum','Unpaid Leave':'sum','Total':'sum'}\n",
    "  billings = billings.groupby('Store', as_index = False).agg(billings_agg_cols)\n",
    "\n",
    "  rostered_hr = pd.merge(rostered_hr, employees[['Employee ID', 'First Name', 'Last Name', 'Company']], how='left', on=['Employee ID'])\n",
    "  rostered_hr_col = [\n",
    "    'Employee ID',\n",
    "    'First Name',\n",
    "    'Last Name',\n",
    "    'Preferred Name',\n",
    "    'Company',\n",
    "    'Store',\n",
    "    'Date',\n",
    "    'Hours'\n",
    "    ]\n",
    "  rostered_hr = rostered_hr[rostered_hr_col]\n",
    "  rostered_hr['Date'] = pd.to_datetime(rostered_hr['Date'])\n",
    "\n",
    "  bonus = rostered_hr.copy()\n",
    "\n",
    "  # Stitch Store ID and drop rows which Store ID are not found\n",
    "  sheet_id = '1rqOeBjA9drmTnjlENvr57RqL5-oxSqe_KGdbdL2MKhM'\n",
    "  sheet_name = 'StoreReference'\n",
    "  url = f'https://docs.google.com/spreadsheets/d/{sheet_id}/gviz/tq?tqx=out:csv&sheet={sheet_name}'\n",
    "  store_ref = pd.read_csv(url)\n",
    "\n",
    "  bonus = pd.merge(bonus, store_ref, on=['Store'], how = 'left')\n",
    "\n",
    "  bonus.dropna(subset=['Store ID'], inplace = True)\n",
    "\n",
    "  # Stitch shop_id\n",
    "  sheet_id = '1ezyBlKquUhYnFwmIKTR4fghI59ZvGaKL35mKbcdeRy4'\n",
    "  sheet_name = 'Stores'\n",
    "  url = f'https://docs.google.com/spreadsheets/d/{sheet_id}/gviz/tq?tqx=out:csv&sheet={sheet_name}'\n",
    "  store_df_gs = pd.read_csv(url)\n",
    "\n",
    "  bonus = pd.merge(bonus, store_df_gs[['Store ID', 'shop_id']], on=['Store ID'], how = 'left')\n",
    "  bonus['shop_id'] = bonus['shop_id'].astype(int)\n",
    "\n",
    "\n",
    "  # Stich sales based on shop_id & dates, skip if there is no Date\n",
    "  start = bonus['Date'].min()\n",
    "  end = bonus['Date'].max()\n",
    "\n",
    "  start_str = start.strftime('%Y-%m-%d')\n",
    "  end_str = (end+timedelta(days=1)).strftime('%Y-%m-%d')\n",
    "  shop_id_list = bonus['shop_id'].unique().tolist()\n",
    "  shop_id_list_str = ', '.join(str(id) for id in shop_id_list)\n",
    "  stock_exclusions_list = [266,267,268,269,270,272,256,255,254]\n",
    "  stock_exclusions_list_str = ', '.join(str(s) for s in stock_exclusions_list)\n",
    "\n",
    "  query = '''\n",
    "  SELECT\n",
    "    d.shop_id, Date(d.docket_date) AS Date, SUM(dl.quantity * dl.sell_inc) as Sales\n",
    "  FROM\n",
    "    DocketLine dl\n",
    "  JOIN\n",
    "    Docket d on dl.docket_id  = d.docket_id \n",
    "  WHERE \n",
    "    d.docket_date >='{start}' and d.docket_date < '{end}' and d.shop_id in ({shop_id_list}) and d.`transaction`  = 'SA' and dl.stock_id not in ({stock_exclusions_list})\n",
    "  GROUP BY \n",
    "    d.shop_id, Date(d.docket_date)\n",
    "  '''.format(start=start_str, end = end_str, shop_id_list = shop_id_list_str, stock_exclusions_list = stock_exclusions_list_str)\n",
    "  sales_df = pd.read_sql(con=Gong_cha_MySQL_engine.connect(), sql=sql_text(query))\n",
    "  sales_df['Date'] = pd.to_datetime(sales_df['Date'])\n",
    "\n",
    "  bonus = pd.merge(bonus, sales_df[['shop_id', 'Date', 'Sales']], on=['shop_id', 'Date'], how = 'left')\n",
    "\n",
    "  # Stitch Target Sales & Bonus Rates\n",
    "  sheet_id = '1rqOeBjA9drmTnjlENvr57RqL5-oxSqe_KGdbdL2MKhM'\n",
    "  sheet_name = 'Targets'\n",
    "  url = f'https://docs.google.com/spreadsheets/d/{sheet_id}/gviz/tq?tqx=out:csv&sheet={sheet_name}'\n",
    "  targets = pd.read_csv(url)\n",
    "  targets['Date'] = pd.to_datetime(targets['Date'])\n",
    "\n",
    "  # Change Bonus Rates to 0, if Target Sales is not met\n",
    "  bonus = pd.merge(bonus, targets[['Store ID', 'Date', 'Target Sales', 'Bonus Rate']], on=['Store ID', 'Date'], how = 'left')\n",
    "  bonus['Bonus Rate'] = bonus['Bonus Rate'].where(bonus['Sales'] >= bonus['Target Sales'], 0)\n",
    "  bonus['Bonus'] = bonus['Bonus Rate']  * bonus['Hours']\n",
    "\n",
    "  # Work out additional_hr\n",
    "  additional_hr = additional_hr.dropna(subset=['Employee ID'])\n",
    "  additional_hr = pd.merge(additional_hr, employees[['Employee ID', 'First Name', 'Last Name', 'Company']], how='left', on=['Employee ID'])\n",
    "  additional_hr_col = [\n",
    "    'Employee ID',\n",
    "    'First Name',\n",
    "    'Last Name',\n",
    "    'Preferred Name',\n",
    "    'Company',\n",
    "    'Store',\n",
    "    'Date',\n",
    "    'Hours'\n",
    "  ]\n",
    "  additional_hr = additional_hr[additional_hr_col]\n",
    "  additional_hr['Date'] = pd.to_datetime(additional_hr['Date'])\n",
    "\n",
    "  # Concat rostered_hr and additional_hr\n",
    "  analysis = pd.concat([rostered_hr, additional_hr])\n",
    "\n",
    "  # Concat Bouns on to Timesheets\n",
    "  bonus_summary = bonus.groupby('Employee ID', as_index = False).agg({'Bonus':'sum'})\n",
    "  timesheets = pd.merge(timesheets, bonus_summary, on=['Employee ID'], how = 'left')\n",
    "  timesheets.fillna({'Bonus':0}, inplace = True)\n",
    "  timesheets.rename(columns={'Bonus':'Bonus $'}, inplace = True)\n",
    "\n",
    "  return timesheets, billings, over_threshold, analysis, bonus\n",
    "\n",
    "# # # END OF FUNCTIONS\n",
    "\n",
    "\n",
    "import io\n",
    "import streamlit as st\n",
    "\n",
    "st.title('Timesheet & Billing')\n",
    "\n",
    "uploaded_files = st.file_uploader(\"Choose Files\", accept_multiple_files = True)\n",
    "\n",
    "# Create an empty container\n",
    "output = st.empty()\n",
    "\n",
    "# if uploaded_files is not None:\n",
    "if len(uploaded_files) > 0:\n",
    "    ts, bl, ot, an, bo = calc_timesheets_n_billings(uploaded_files)\n",
    "\n",
    "    buffer = io.BytesIO()\n",
    "\n",
    "    with pd.ExcelWriter(buffer, engine='xlsxwriter') as writer:\n",
    "    # Write each dataframe to a different worksheet.\n",
    "        ts.to_excel(writer, sheet_name='Timesheet', index = False)\n",
    "        bl.to_excel(writer, sheet_name='Billing', index = False)\n",
    "        ot.to_excel(writer, sheet_name='Over Threshold', index = False)\n",
    "        an.to_excel(writer, sheet_name='Analysis',index = False)\n",
    "        bo.to_excel(writer, sheet_name='Bonus',index = False)\n",
    "\n",
    "    # Close the Pandas Excel writer and output the Excel file to the buffer\n",
    "    writer.close()\n",
    "\n",
    "    st.download_button(\n",
    "        label=\"Download\",\n",
    "        data=buffer,\n",
    "        file_name=\"Timesheet & Billing.xlsx\",\n",
    "        mime=\"application/vnd.ms-excel\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
