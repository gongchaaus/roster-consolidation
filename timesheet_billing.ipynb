{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3y/sylb4fpd4y19tc1y_nfdd_jw0000gn/T/ipykernel_98881/3170424087.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "import mysql.connector\n",
    "\n",
    "mysql_host = '34.116.84.145'\n",
    "mysql_port = '3306'\n",
    "mysql_user = 'gong-cha'\n",
    "mysql_password = 'HelloGongCha2012'\n",
    "mysql_database = 'gong_cha_redcat_db'\n",
    "\n",
    "# Engine for MySQL\n",
    "mysql_connection_string = f\"mysql+mysqlconnector://{mysql_user}:{mysql_password}@{mysql_host}:{mysql_port}/{mysql_database}\"\n",
    "mysql_engine = create_engine(mysql_connection_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # START OF FUNCTIONS\n",
    "\n",
    "def extract_additional_hr(file, sheet_name):\n",
    "  df = pd.read_excel(file, sheet_name = sheet_name)\n",
    "  df = df.dropna(subset=['Employee ID'])\n",
    "\n",
    "  if df['Employee ID'].dtypes == 'object':\n",
    "    df['Employee ID'] = df['Employee ID'].str[:6]\n",
    "  df['Employee ID'] = df['Employee ID'].astype(int)\n",
    "\n",
    "  if df['Store'].dtypes == float:\n",
    "    df['Store'] = df['Store'].astype(int).astype(str)\n",
    "\n",
    "  df = df.fillna({'Add': 0, 'Add.1': 0,'Add.2': 0,'Add.3': 0,'Add.4': 0,'Add.5': 0,'Personal Leave': 0,'Annual Leave': 0,})\n",
    "  df['2012-11-01'] = df['Add'] + df['Add.1'] + df['Add.2'] + df['Add.3'] + df['Add.4'] + df['Add.5']\n",
    "  df['2013-01-01'] = df['Personal Leave'] + df['Annual Leave']\n",
    "  cols =[0,1,2, df.columns.tolist().index('2012-11-01'),df.columns.tolist().index('2013-01-01')]\n",
    "\n",
    "  df = df.iloc[:, cols]\n",
    "  df = df.dropna(subset=df.columns[:3], how='all')\n",
    "  df = df.melt(id_vars=['Employee ID', 'Store', 'Preferred Name'], value_vars=df.columns[3:], var_name='Date', value_name='Hours')\n",
    "  df = df[df['Hours'] != 0]\n",
    "  return df\n",
    "\n",
    "def extract_rostered_hr(file, sheet_name):\n",
    "  df = pd.read_excel(file, sheet_name = sheet_name)\n",
    "\n",
    "  df = df.dropna(subset=['Employee ID'])\n",
    "\n",
    "  if df['Employee ID'].dtypes == 'object':\n",
    "    df['Employee ID'] = df['Employee ID'].str[:6]\n",
    "  df['Employee ID'] = df['Employee ID'].astype(int)\n",
    "\n",
    "  if df['Store'].dtypes == float:\n",
    "    df['Store'] = df['Store'].astype(int).astype(str)\n",
    "\n",
    "  df = df.iloc[:, :24]\n",
    "  cols = [0,1,2]\n",
    "  for col in range(3, 24, 3):\n",
    "      df[df.columns[col]] = df[df.columns[col+2]]\n",
    "      cols.append(col)\n",
    "  df = df.iloc[:,cols]\n",
    "  df = df.dropna(subset=df.columns[:3], how='all')\n",
    "  df = df.melt(id_vars=['Employee ID', 'Store', 'Preferred Name'], value_vars=df.columns[3:], var_name='Date', value_name='Hours')\n",
    "  df = df[df['Hours'] != 0]\n",
    "  return df\n",
    "\n",
    "def calc_timesheets_n_billings(files):\n",
    "  print('calc')\n",
    "  timesheets = pd.DataFrame()\n",
    "  billings = pd.DataFrame()\n",
    "  rostered_hr = pd.DataFrame()\n",
    "  additional_hr = pd.DataFrame()\n",
    "\n",
    "  for file in files:\n",
    "    timesheet = pd.read_excel(file, sheet_name = 'Timesheet')\n",
    "    billing = pd.read_excel(file, sheet_name = 'Billing')\n",
    "    rostered_hr_w1 = extract_rostered_hr(file, 'Week 1 Roster')\n",
    "    rostered_hr_w2 = extract_rostered_hr(file, 'Week 2 Roster')\n",
    "    additional_hr_w1 = extract_additional_hr(file, 'Week 1 Roster')\n",
    "    additional_hr_w2 = extract_additional_hr(file, 'Week 2 Roster')\n",
    "    employees = pd.read_excel(file, sheet_name = 'Employees')\n",
    "\n",
    "    timesheets = pd.concat([timesheets, timesheet], ignore_index=True)\n",
    "    billings = pd.concat([billings, billing], ignore_index=True)\n",
    "    rostered_hr = pd.concat([rostered_hr, rostered_hr_w1], ignore_index=True)\n",
    "    rostered_hr = pd.concat([rostered_hr, rostered_hr_w2], ignore_index=True)\n",
    "    additional_hr = pd.concat([additional_hr, additional_hr_w1], ignore_index=True)\n",
    "    additional_hr = pd.concat([additional_hr, additional_hr_w2], ignore_index=True)\n",
    "\n",
    "  #Remov  e irrelevant rows\n",
    "  timesheets.dropna(subset = ['Employee ID'], inplace=True)\n",
    "  #Keep the needed columns\n",
    "  timesheets_cols = [1,2,3,7,8,9,10,11,12,13,14,15,16,17,18,19,20]\n",
    "  timesheets = timesheets[timesheets.columns[timesheets_cols]]\n",
    "  timesheets['Update Wage'] = timesheets['Update Wage'].astype(bool)\n",
    "  #Column Aggregations\n",
    "  timesheets_agg_cols = {'First Name':'first','Last Name':'first','Update Wage':'first','Hour Threshold':'first','Company':'first','Ord':'sum','Sat':'sum','Sun':'sum','Pub':'sum','Eve 1':'sum','Eve 2':'sum','No. of Shifts':'sum','Personal Leave':'sum','Annual Leave':'sum','Unpaid Leave':'sum','Total':'sum'}\n",
    "  timesheets = timesheets.groupby('Employee ID', as_index = False).agg(timesheets_agg_cols)\n",
    "  #Calculate Over Threshold\n",
    "  timesheets['Over Threshold'] = timesheets['Total'] - timesheets['Hour Threshold']\n",
    "  timesheets.loc[timesheets[\"Over Threshold\"] <=0, \"Over Threshold\"] = 0\n",
    "  #Keep Over Thresholds to a new df\n",
    "  over_threshold = timesheets[timesheets['Over Threshold']>0]\n",
    "  #Reduce Ord & Total with the excess\n",
    "  timesheets['Ord'] = timesheets['Ord'] - timesheets['Over Threshold']\n",
    "  timesheets['Total'] = timesheets['Total'] - timesheets['Over Threshold']\n",
    "  #Convert 80 & 100 hours to 76 hours\n",
    "  hours_col = ['Ord', 'Sat','Sun','Eve 1','Eve 2','Pub','Personal Leave', 'Annual Leave', 'Unpaid Leave', 'Total']\n",
    "  if(100 in timesheets[\"Hour Threshold\"].values):\n",
    "      timesheets.loc[timesheets[\"Hour Threshold\"] == 100, hours_col] = timesheets[hours_col]/100*76\n",
    "  if(80 in timesheets[\"Hour Threshold\"].values):\n",
    "      timesheets.loc[timesheets[\"Hour Threshold\"] == 80, hours_col] = timesheets[hours_col]/80*76\n",
    "  if any(timesheets[\"Hour Threshold\"] > 1000):\n",
    "  # Find rows where \"Hour Threshold\" is greater than 1000\n",
    "      rows_to_update = timesheets.loc[timesheets[\"Hour Threshold\"] > 1000]\n",
    "      # Perform actions on the rows\n",
    "      for index, row in rows_to_update.iterrows():\n",
    "          threshold = int(row[\"Hour Threshold\"])\n",
    "          base = int(str(threshold)[:2])\n",
    "          conversion = int(str(threshold)[-2:])\n",
    "          # Update multiple columns using .loc\n",
    "          timesheets.loc[index, hours_col] = timesheets.loc[index, hours_col] / conversion * base\n",
    "\n",
    "  #drop Hour Threshold & Over Threshold\n",
    "  timesheets = timesheets.drop(['Hour Threshold','Over Threshold'],axis = 1)\n",
    "\n",
    "  #Remove irrelevant rows\n",
    "  billings.dropna(subset=['Store'],inplace = True)\n",
    "  billings = billings[billings['Total'] > 0]\n",
    "\n",
    "  #Keep the needed columns\n",
    "  billings_cols = [0,1,2,3,4,5,6,7,8,9,10,11]\n",
    "  billings = billings[billings.columns[billings_cols]]\n",
    "  #Column Aggregations\n",
    "  billings_agg_cols = {'Ord':'sum','Sat':'sum','Sun':'sum','Pub':'sum','Eve 1':'sum','Eve 2':'sum','No. of Shifts':'sum','Personal Leave':'sum','Annual Leave':'sum','Unpaid Leave':'sum','Total':'sum'}\n",
    "  billings = billings.groupby('Store', as_index = False).agg(billings_agg_cols)\n",
    "\n",
    "  rostered_hr = pd.merge(rostered_hr, employees[['Employee ID', 'First Name', 'Last Name', 'Company']], how='left', on=['Employee ID'])\n",
    "  rostered_hr_col = [\n",
    "  'Employee ID',\n",
    "  'First Name',\n",
    "  'Last Name',\n",
    "  'Preferred Name',\n",
    "  'Company',\n",
    "  'Store',\n",
    "  'Date',\n",
    "  'Hours'\n",
    "  ]\n",
    "  rostered_hr = rostered_hr[rostered_hr_col]\n",
    "  rostered_hr['Date'] = pd.to_datetime(rostered_hr['Date'])\n",
    "\n",
    "  bonus = rostered_hr.copy()\n",
    "\n",
    "  # Stitch Store ID and drop rows which Store ID are not found\n",
    "  sheet_id = '1rqOeBjA9drmTnjlENvr57RqL5-oxSqe_KGdbdL2MKhM'\n",
    "  sheet_name = 'StoreReference'\n",
    "  url = f'https://docs.google.com/spreadsheets/d/{sheet_id}/gviz/tq?tqx=out:csv&sheet={sheet_name}'\n",
    "  store_ref = pd.read_csv(url)\n",
    "\n",
    "  bonus = pd.merge(bonus, store_ref, on=['Store'], how = 'left')\n",
    "\n",
    "  bonus.dropna(subset=['Store ID'], inplace = True)\n",
    "\n",
    "  # Stitch recid_plo\n",
    "  sheet_id = '1aVcnah9Cp_PUvFiXgd2XRmBpLhumCqHUaqROaLcpYfc'\n",
    "  sheet_name = 'store_id_ref'\n",
    "  url = f'https://docs.google.com/spreadsheets/d/{sheet_id}/gviz/tq?tqx=out:csv&sheet={sheet_name}'\n",
    "  store_id_ref_crm = pd.read_csv(url)\n",
    "  store_id_ref_crm = store_id_ref_crm.rename(columns={'store_id' : 'Store ID'})\n",
    "  bonus = pd.merge(bonus, store_id_ref_crm[['Store ID', 'recid_plo']], on=['Store ID'], how = 'left')\n",
    "  bonus['recid_plo'] = bonus['recid_plo'].astype(int)\n",
    "\n",
    "  # Stich sales based on recid_plo & dates, skip if there is no Date\n",
    "  start = bonus['Date'].min()\n",
    "  end = bonus['Date'].max()\n",
    "\n",
    "  start_str = start.strftime('%Y-%m-%d')\n",
    "  end_str = end.strftime('%Y-%m-%d')\n",
    "\n",
    "  recid_plo_list = bonus['recid_plo'].unique().tolist()\n",
    "  recid_plo_list_str = ', '.join(str(id) for id in recid_plo_list)\n",
    "\n",
    "  sheet_id = '1peA8effpeSTk3duIjxF46V-PrDD8tv3fubTCDEpD940'\n",
    "  sheet_name = 'ops_bonus_exclusion'\n",
    "  url = f'https://docs.google.com/spreadsheets/d/{sheet_id}/gviz/tq?tqx=out:csv&sheet={sheet_name}'\n",
    "  exclusion_df = pd.read_csv(url)\n",
    "  excluded_recid_plu = exclusion_df['recid_plu'].drop_duplicates()\n",
    "\n",
    "  excluded_recid_plu_str = ', '.join(str(s) for s in excluded_recid_plu)\n",
    "\n",
    "  query = '''\n",
    "  SELECT ts2.recid_plo, ts.itemdate as Date, sum(ts.qty*ts.price) as Sales\n",
    "  FROM tbl_salesitems ts \n",
    "  JOIN tbl_salesheaders ts2 on ts.recid_mixh = ts2.recid\n",
    "  WHERE ts.itemdate >= '{start}' and ts.itemdate <= '{end}' and ts2.recid_plo in ({recid_plo_list}) and ts.recid_plu not in ({excluded_recid_plu})\n",
    "  GROUP BY ts2.recid_plo, ts.itemdate\n",
    "  ORDER BY ts.itemdate ASC, recid_plo ASC\n",
    "  '''.format(start=start_str, end = end_str, recid_plo_list = recid_plo_list_str, excluded_recid_plu = excluded_recid_plu_str)\n",
    "\n",
    "  sales_df = pd.read_sql(query, mysql_engine)\n",
    "  sales_df['Date'] = pd.to_datetime(sales_df['Date'])\n",
    "\n",
    "  bonus = pd.merge(bonus, sales_df[['recid_plo', 'Date', 'Sales']], on=['recid_plo', 'Date'], how = 'left')\n",
    "\n",
    "  # Stitch Target Sales & Bonus Rates\n",
    "  sheet_id = '1rqOeBjA9drmTnjlENvr57RqL5-oxSqe_KGdbdL2MKhM'\n",
    "  sheet_name = 'Targets'\n",
    "  url = f'https://docs.google.com/spreadsheets/d/{sheet_id}/gviz/tq?tqx=out:csv&sheet={sheet_name}'\n",
    "  targets = pd.read_csv(url)\n",
    "  targets['Date'] = pd.to_datetime(targets['Date'])\n",
    "\n",
    "  # Change Bonus Rates to 0, if Target Sales is not met\n",
    "  bonus = pd.merge(bonus, targets[['Store ID', 'Date', 'Target Sales', 'Bonus Rate']], on=['Store ID', 'Date'], how = 'left')\n",
    "  bonus['Bonus Rate'] = bonus['Bonus Rate'].where(bonus['Sales'] >= bonus['Target Sales'], 0)\n",
    "  bonus['Bonus'] = bonus['Bonus Rate']  * bonus['Hours']\n",
    "\n",
    "  # Work out additional_hr\n",
    "  additional_hr = additional_hr.dropna(subset=['Employee ID'])\n",
    "  additional_hr = pd.merge(additional_hr, employees[['Employee ID', 'First Name', 'Last Name', 'Company']], how='left', on=['Employee ID'])\n",
    "  additional_hr_col = [\n",
    "  'Employee ID',\n",
    "  'First Name',\n",
    "  'Last Name',\n",
    "  'Preferred Name',\n",
    "  'Company',\n",
    "  'Store',\n",
    "  'Date',\n",
    "  'Hours'\n",
    "  ]\n",
    "  additional_hr = additional_hr[additional_hr_col]\n",
    "  additional_hr['Date'] = pd.to_datetime(additional_hr['Date'])\n",
    "\n",
    "  # Concat rostered_hr and additional_hr\n",
    "  analysis = pd.concat([rostered_hr, additional_hr])\n",
    "\n",
    "  # Concat Bouns on to Timesheets\n",
    "  bonus_summary = bonus.groupby('Employee ID', as_index = False).agg({'Bonus':'sum'})\n",
    "  timesheets = pd.merge(timesheets, bonus_summary, on=['Employee ID'], how = 'left')\n",
    "  timesheets.fillna({'Bonus':0}, inplace = True)\n",
    "  timesheets.rename(columns={'Bonus':'Bonus $'}, inplace = True)\n",
    "\n",
    "  return timesheets, billings, over_threshold, analysis, bonus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # # END OF FUNCTIONS\n",
    "\n",
    "\n",
    "import io\n",
    "import streamlit as st\n",
    "\n",
    "st.title('Timesheet & Billing')\n",
    "\n",
    "uploaded_files = st.file_uploader(\"Choose Files\", accept_multiple_files = True)\n",
    "\n",
    "# Create an empty container\n",
    "output = st.empty()\n",
    "\n",
    "# if uploaded_files is not None:\n",
    "if len(uploaded_files) > 0:\n",
    "    ts, bl, ot, an, bo = calc_timesheets_n_billings(uploaded_files)\n",
    "\n",
    "    buffer = io.BytesIO()\n",
    "\n",
    "    with pd.ExcelWriter(buffer, engine='xlsxwriter') as writer:\n",
    "    # Write each dataframe to a different worksheet.\n",
    "        ts.to_excel(writer, sheet_name='Timesheet', index = False)\n",
    "        bl.to_excel(writer, sheet_name='Billing', index = False)\n",
    "        ot.to_excel(writer, sheet_name='Over Threshold', index = False)\n",
    "        an.to_excel(writer, sheet_name='Analysis',index = False)\n",
    "        bo.to_excel(writer, sheet_name='Bonus',index = False)\n",
    "\n",
    "    # Close the Pandas Excel writer and output the Excel file to the buffer\n",
    "    writer.close()\n",
    "\n",
    "    st.download_button(\n",
    "        label=\"Download\",\n",
    "        data=buffer,\n",
    "        file_name=\"Timesheet & Billing.xlsx\",\n",
    "        mime=\"application/vnd.ms-excel\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Employee ID</th>\n",
       "      <th>First Name</th>\n",
       "      <th>Last Name</th>\n",
       "      <th>Preferred Name</th>\n",
       "      <th>Company</th>\n",
       "      <th>Store</th>\n",
       "      <th>Date</th>\n",
       "      <th>Hours</th>\n",
       "      <th>Store ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10040</td>\n",
       "      <td>Tran Thu Hang</td>\n",
       "      <td>Vu</td>\n",
       "      <td>Zoe Vu</td>\n",
       "      <td>GCM</td>\n",
       "      <td>MetCentre</td>\n",
       "      <td>2024-08-05</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>S181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10003</td>\n",
       "      <td>Ching Yi</td>\n",
       "      <td>Huang</td>\n",
       "      <td>Amilli Huang</td>\n",
       "      <td>GCM</td>\n",
       "      <td>MetCentre</td>\n",
       "      <td>2024-08-05</td>\n",
       "      <td>6.250000</td>\n",
       "      <td>S181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10090</td>\n",
       "      <td>Hsin-Yi</td>\n",
       "      <td>CHIANG</td>\n",
       "      <td>Ava chiang</td>\n",
       "      <td>HL</td>\n",
       "      <td>MetCentre</td>\n",
       "      <td>2024-08-06</td>\n",
       "      <td>3.750000</td>\n",
       "      <td>S181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10040</td>\n",
       "      <td>Tran Thu Hang</td>\n",
       "      <td>Vu</td>\n",
       "      <td>Zoe Vu</td>\n",
       "      <td>GCM</td>\n",
       "      <td>MetCentre</td>\n",
       "      <td>2024-08-06</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>S181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10382</td>\n",
       "      <td>Vi Viet Hoang</td>\n",
       "      <td>Ngo</td>\n",
       "      <td>Henry Ngo</td>\n",
       "      <td>SS</td>\n",
       "      <td>MetCentre</td>\n",
       "      <td>2024-08-06</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>S181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10306</td>\n",
       "      <td>Thuy An</td>\n",
       "      <td>Pham</td>\n",
       "      <td>Annie Pham</td>\n",
       "      <td>GCM</td>\n",
       "      <td>MetCentre</td>\n",
       "      <td>2024-08-06</td>\n",
       "      <td>5.166667</td>\n",
       "      <td>S181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10090</td>\n",
       "      <td>Hsin-Yi</td>\n",
       "      <td>CHIANG</td>\n",
       "      <td>Ava chiang</td>\n",
       "      <td>HL</td>\n",
       "      <td>MetCentre</td>\n",
       "      <td>2024-08-07</td>\n",
       "      <td>9.366667</td>\n",
       "      <td>S181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10280</td>\n",
       "      <td>Luoshi</td>\n",
       "      <td>Wu</td>\n",
       "      <td>Stella Wu</td>\n",
       "      <td>GCM</td>\n",
       "      <td>MetCentre</td>\n",
       "      <td>2024-08-07</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>S181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10250</td>\n",
       "      <td>Amy</td>\n",
       "      <td>Hou</td>\n",
       "      <td>Amy Hou</td>\n",
       "      <td>GCM</td>\n",
       "      <td>MetCentre</td>\n",
       "      <td>2024-08-07</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>S181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10160</td>\n",
       "      <td>Pulin</td>\n",
       "      <td>Pan</td>\n",
       "      <td>Lexi Pan</td>\n",
       "      <td>GCM</td>\n",
       "      <td>MetCentre</td>\n",
       "      <td>2024-08-07</td>\n",
       "      <td>6.700000</td>\n",
       "      <td>S181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10090</td>\n",
       "      <td>Hsin-Yi</td>\n",
       "      <td>CHIANG</td>\n",
       "      <td>Ava chiang</td>\n",
       "      <td>HL</td>\n",
       "      <td>MetCentre</td>\n",
       "      <td>2024-08-08</td>\n",
       "      <td>6.150000</td>\n",
       "      <td>S181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10334</td>\n",
       "      <td>Huy Tien</td>\n",
       "      <td>Phan</td>\n",
       "      <td>Pat phan</td>\n",
       "      <td>SS</td>\n",
       "      <td>MetCentre</td>\n",
       "      <td>2024-08-08</td>\n",
       "      <td>7.350000</td>\n",
       "      <td>S181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10090</td>\n",
       "      <td>Hsin-Yi</td>\n",
       "      <td>CHIANG</td>\n",
       "      <td>Ava chiang</td>\n",
       "      <td>HL</td>\n",
       "      <td>MetCentre</td>\n",
       "      <td>2024-08-09</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>S181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>10334</td>\n",
       "      <td>Huy Tien</td>\n",
       "      <td>Phan</td>\n",
       "      <td>Pat phan</td>\n",
       "      <td>SS</td>\n",
       "      <td>MetCentre</td>\n",
       "      <td>2024-08-09</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>S181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>10160</td>\n",
       "      <td>Pulin</td>\n",
       "      <td>Pan</td>\n",
       "      <td>Lexi Pan</td>\n",
       "      <td>GCM</td>\n",
       "      <td>MetCentre</td>\n",
       "      <td>2024-08-12</td>\n",
       "      <td>6.783333</td>\n",
       "      <td>S181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>10284</td>\n",
       "      <td>Kim Ngoc Ngo</td>\n",
       "      <td>Bui</td>\n",
       "      <td>Mari Bui</td>\n",
       "      <td>HL</td>\n",
       "      <td>MetCentre</td>\n",
       "      <td>2024-08-12</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>S181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>10040</td>\n",
       "      <td>Tran Thu Hang</td>\n",
       "      <td>Vu</td>\n",
       "      <td>Zoe Vu</td>\n",
       "      <td>GCM</td>\n",
       "      <td>MetCentre</td>\n",
       "      <td>2024-08-13</td>\n",
       "      <td>5.966667</td>\n",
       "      <td>S181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>10382</td>\n",
       "      <td>Vi Viet Hoang</td>\n",
       "      <td>Ngo</td>\n",
       "      <td>Henry Ngo</td>\n",
       "      <td>SS</td>\n",
       "      <td>MetCentre</td>\n",
       "      <td>2024-08-13</td>\n",
       "      <td>6.600000</td>\n",
       "      <td>S181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>10090</td>\n",
       "      <td>Hsin-Yi</td>\n",
       "      <td>CHIANG</td>\n",
       "      <td>Ava chiang</td>\n",
       "      <td>HL</td>\n",
       "      <td>MetCentre</td>\n",
       "      <td>2024-08-14</td>\n",
       "      <td>6.383333</td>\n",
       "      <td>S181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>10040</td>\n",
       "      <td>Tran Thu Hang</td>\n",
       "      <td>Vu</td>\n",
       "      <td>Zoe Vu</td>\n",
       "      <td>GCM</td>\n",
       "      <td>MetCentre</td>\n",
       "      <td>2024-08-14</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>S181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>10090</td>\n",
       "      <td>Hsin-Yi</td>\n",
       "      <td>CHIANG</td>\n",
       "      <td>Ava chiang</td>\n",
       "      <td>HL</td>\n",
       "      <td>MetCentre</td>\n",
       "      <td>2024-08-15</td>\n",
       "      <td>9.150000</td>\n",
       "      <td>S181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>10334</td>\n",
       "      <td>Huy Tien</td>\n",
       "      <td>Phan</td>\n",
       "      <td>Pat phan</td>\n",
       "      <td>SS</td>\n",
       "      <td>MetCentre</td>\n",
       "      <td>2024-08-15</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>S181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>10334</td>\n",
       "      <td>Huy Tien</td>\n",
       "      <td>Phan</td>\n",
       "      <td>Pat phan</td>\n",
       "      <td>SS</td>\n",
       "      <td>MetCentre</td>\n",
       "      <td>2024-08-16</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>S181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>10031</td>\n",
       "      <td>Qinyi</td>\n",
       "      <td>ZHOU</td>\n",
       "      <td>Cordelia Zhou</td>\n",
       "      <td>GCM</td>\n",
       "      <td>MetCentre</td>\n",
       "      <td>2024-08-16</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>S181</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Employee ID     First Name Last Name Preferred Name Company      Store  \\\n",
       "0         10040  Tran Thu Hang        Vu         Zoe Vu     GCM  MetCentre   \n",
       "1         10003       Ching Yi     Huang   Amilli Huang     GCM  MetCentre   \n",
       "2         10090        Hsin-Yi    CHIANG     Ava chiang      HL  MetCentre   \n",
       "3         10040  Tran Thu Hang        Vu         Zoe Vu     GCM  MetCentre   \n",
       "4         10382  Vi Viet Hoang       Ngo      Henry Ngo      SS  MetCentre   \n",
       "5         10306        Thuy An      Pham     Annie Pham     GCM  MetCentre   \n",
       "6         10090        Hsin-Yi    CHIANG     Ava chiang      HL  MetCentre   \n",
       "7         10280         Luoshi        Wu      Stella Wu     GCM  MetCentre   \n",
       "8         10250            Amy       Hou        Amy Hou     GCM  MetCentre   \n",
       "9         10160          Pulin       Pan       Lexi Pan     GCM  MetCentre   \n",
       "10        10090        Hsin-Yi    CHIANG     Ava chiang      HL  MetCentre   \n",
       "11        10334       Huy Tien      Phan       Pat phan      SS  MetCentre   \n",
       "12        10090        Hsin-Yi    CHIANG     Ava chiang      HL  MetCentre   \n",
       "13        10334       Huy Tien      Phan       Pat phan      SS  MetCentre   \n",
       "14        10160          Pulin       Pan       Lexi Pan     GCM  MetCentre   \n",
       "15        10284   Kim Ngoc Ngo       Bui       Mari Bui      HL  MetCentre   \n",
       "16        10040  Tran Thu Hang        Vu         Zoe Vu     GCM  MetCentre   \n",
       "17        10382  Vi Viet Hoang       Ngo      Henry Ngo      SS  MetCentre   \n",
       "18        10090        Hsin-Yi    CHIANG     Ava chiang      HL  MetCentre   \n",
       "19        10040  Tran Thu Hang        Vu         Zoe Vu     GCM  MetCentre   \n",
       "20        10090        Hsin-Yi    CHIANG     Ava chiang      HL  MetCentre   \n",
       "21        10334       Huy Tien      Phan       Pat phan      SS  MetCentre   \n",
       "22        10334       Huy Tien      Phan       Pat phan      SS  MetCentre   \n",
       "23        10031          Qinyi      ZHOU  Cordelia Zhou     GCM  MetCentre   \n",
       "\n",
       "         Date     Hours Store ID  \n",
       "0  2024-08-05  7.500000     S181  \n",
       "1  2024-08-05  6.250000     S181  \n",
       "2  2024-08-06  3.750000     S181  \n",
       "3  2024-08-06  7.500000     S181  \n",
       "4  2024-08-06  7.500000     S181  \n",
       "5  2024-08-06  5.166667     S181  \n",
       "6  2024-08-07  9.366667     S181  \n",
       "7  2024-08-07  7.500000     S181  \n",
       "8  2024-08-07  5.500000     S181  \n",
       "9  2024-08-07  6.700000     S181  \n",
       "10 2024-08-08  6.150000     S181  \n",
       "11 2024-08-08  7.350000     S181  \n",
       "12 2024-08-09  5.500000     S181  \n",
       "13 2024-08-09  6.500000     S181  \n",
       "14 2024-08-12  6.783333     S181  \n",
       "15 2024-08-12  6.500000     S181  \n",
       "16 2024-08-13  5.966667     S181  \n",
       "17 2024-08-13  6.600000     S181  \n",
       "18 2024-08-14  6.383333     S181  \n",
       "19 2024-08-14  7.500000     S181  \n",
       "20 2024-08-15  9.150000     S181  \n",
       "21 2024-08-15  5.000000     S181  \n",
       "22 2024-08-16  6.500000     S181  \n",
       "23 2024-08-16  6.200000     S181  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bonus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/eddy/Developer/Python/roster-consolidation/files/MetCentre Final Roster 0508- 1808 copy.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eddy/.pyenv/versions/3.12.4/envs/default/lib/python3.12/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "/Users/eddy/.pyenv/versions/3.12.4/envs/default/lib/python3.12/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "/Users/eddy/.pyenv/versions/3.12.4/envs/default/lib/python3.12/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "/Users/eddy/.pyenv/versions/3.12.4/envs/default/lib/python3.12/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import openpyxl\n",
    "\n",
    "# Get absolute path of the current notebook's directory\n",
    "notebook_dir = os.getcwd()  # Get current working directory\n",
    "\n",
    "# Construct the path to the `/files/` folder\n",
    "files_dir = os.path.join(notebook_dir, \"files\")\n",
    "\n",
    "# List files in the directory\n",
    "files_names_dir = os.listdir(files_dir)\n",
    "\n",
    "timesheets = pd.DataFrame()\n",
    "billings = pd.DataFrame()\n",
    "rostered_hr = pd.DataFrame()\n",
    "additional_hr = pd.DataFrame()\n",
    "\n",
    "for filename in files_names_dir:\n",
    "    if filename.endswith(\".xlsx\"):\n",
    "        file = os.path.join(files_dir, filename)\n",
    "        print(file)\n",
    "        timesheet = pd.read_excel(file, sheet_name = 'Timesheet', engine='openpyxl')\n",
    "        billing = pd.read_excel(file, sheet_name = 'Billing', engine='openpyxl')\n",
    "        rostered_hr_w1 = extract_rostered_hr(file, 'Week 1 Roster')\n",
    "        rostered_hr_w2 = extract_rostered_hr(file, 'Week 2 Roster')\n",
    "        additional_hr_w1 = extract_additional_hr(file, 'Week 1 Roster')\n",
    "        additional_hr_w2 = extract_additional_hr(file, 'Week 2 Roster')\n",
    "        employees = pd.read_excel(file, sheet_name = 'Employees')\n",
    "\n",
    "        timesheets = pd.concat([timesheets, timesheet], ignore_index=True)\n",
    "        billings = pd.concat([billings, billing], ignore_index=True)\n",
    "        rostered_hr = pd.concat([rostered_hr, rostered_hr_w1], ignore_index=True)\n",
    "        rostered_hr = pd.concat([rostered_hr, rostered_hr_w2], ignore_index=True)\n",
    "        additional_hr = pd.concat([additional_hr, additional_hr_w1], ignore_index=True)\n",
    "        additional_hr = pd.concat([additional_hr, additional_hr_w2], ignore_index=True)\n",
    "\n",
    "#Remov  e irrelevant rows\n",
    "timesheets.dropna(subset = ['Employee ID'], inplace=True)\n",
    "#Keep the needed columns\n",
    "timesheets_cols = [1,2,3,7,8,9,10,11,12,13,14,15,16,17,18,19,20]\n",
    "timesheets = timesheets[timesheets.columns[timesheets_cols]]\n",
    "timesheets['Update Wage'] = timesheets['Update Wage'].astype(bool)\n",
    "#Column Aggregations\n",
    "timesheets_agg_cols = {'First Name':'first','Last Name':'first','Update Wage':'first','Hour Threshold':'first','Company':'first','Ord':'sum','Sat':'sum','Sun':'sum','Pub':'sum','Eve 1':'sum','Eve 2':'sum','No. of Shifts':'sum','Personal Leave':'sum','Annual Leave':'sum','Unpaid Leave':'sum','Total':'sum'}\n",
    "timesheets = timesheets.groupby('Employee ID', as_index = False).agg(timesheets_agg_cols)\n",
    "#Calculate Over Threshold\n",
    "timesheets['Over Threshold'] = timesheets['Total'] - timesheets['Hour Threshold']\n",
    "timesheets.loc[timesheets[\"Over Threshold\"] <=0, \"Over Threshold\"] = 0\n",
    "#Keep Over Thresholds to a new df\n",
    "over_threshold = timesheets[timesheets['Over Threshold']>0]\n",
    "#Reduce Ord & Total with the excess\n",
    "timesheets['Ord'] = timesheets['Ord'] - timesheets['Over Threshold']\n",
    "timesheets['Total'] = timesheets['Total'] - timesheets['Over Threshold']\n",
    "#Convert 80 & 100 hours to 76 hours\n",
    "hours_col = ['Ord', 'Sat','Sun','Eve 1','Eve 2','Pub','Personal Leave', 'Annual Leave', 'Unpaid Leave', 'Total']\n",
    "if(100 in timesheets[\"Hour Threshold\"].values):\n",
    "    timesheets.loc[timesheets[\"Hour Threshold\"] == 100, hours_col] = timesheets[hours_col]/100*76\n",
    "if(80 in timesheets[\"Hour Threshold\"].values):\n",
    "    timesheets.loc[timesheets[\"Hour Threshold\"] == 80, hours_col] = timesheets[hours_col]/80*76\n",
    "if any(timesheets[\"Hour Threshold\"] > 1000):\n",
    "# Find rows where \"Hour Threshold\" is greater than 1000\n",
    "    rows_to_update = timesheets.loc[timesheets[\"Hour Threshold\"] > 1000]\n",
    "    # Perform actions on the rows\n",
    "    for index, row in rows_to_update.iterrows():\n",
    "        threshold = int(row[\"Hour Threshold\"])\n",
    "        base = int(str(threshold)[:2])\n",
    "        conversion = int(str(threshold)[-2:])\n",
    "        # Update multiple columns using .loc\n",
    "        timesheets.loc[index, hours_col] = timesheets.loc[index, hours_col] / conversion * base\n",
    "\n",
    "#drop Hour Threshold & Over Threshold\n",
    "timesheets = timesheets.drop(['Hour Threshold','Over Threshold'],axis = 1)\n",
    "\n",
    "#Remove irrelevant rows\n",
    "billings.dropna(subset=['Store'],inplace = True)\n",
    "billings = billings[billings['Total'] > 0]\n",
    "\n",
    "#Keep the needed columns\n",
    "billings_cols = [0,1,2,3,4,5,6,7,8,9,10,11]\n",
    "billings = billings[billings.columns[billings_cols]]\n",
    "#Column Aggregations\n",
    "billings_agg_cols = {'Ord':'sum','Sat':'sum','Sun':'sum','Pub':'sum','Eve 1':'sum','Eve 2':'sum','No. of Shifts':'sum','Personal Leave':'sum','Annual Leave':'sum','Unpaid Leave':'sum','Total':'sum'}\n",
    "billings = billings.groupby('Store', as_index = False).agg(billings_agg_cols)\n",
    "\n",
    "rostered_hr = pd.merge(rostered_hr, employees[['Employee ID', 'First Name', 'Last Name', 'Company']], how='left', on=['Employee ID'])\n",
    "rostered_hr_col = [\n",
    "'Employee ID',\n",
    "'First Name',\n",
    "'Last Name',\n",
    "'Preferred Name',\n",
    "'Company',\n",
    "'Store',\n",
    "'Date',\n",
    "'Hours'\n",
    "]\n",
    "rostered_hr = rostered_hr[rostered_hr_col]\n",
    "rostered_hr['Date'] = pd.to_datetime(rostered_hr['Date'])\n",
    "\n",
    "bonus = rostered_hr.copy()\n",
    "\n",
    "# Stitch Store ID and drop rows which Store ID are not found\n",
    "sheet_id = '1rqOeBjA9drmTnjlENvr57RqL5-oxSqe_KGdbdL2MKhM'\n",
    "sheet_name = 'StoreReference'\n",
    "url = f'https://docs.google.com/spreadsheets/d/{sheet_id}/gviz/tq?tqx=out:csv&sheet={sheet_name}'\n",
    "store_ref = pd.read_csv(url)\n",
    "\n",
    "bonus = pd.merge(bonus, store_ref, on=['Store'], how = 'left')\n",
    "\n",
    "bonus.dropna(subset=['Store ID'], inplace = True)\n",
    "\n",
    "# Stitch recid_plo\n",
    "sheet_id = '1aVcnah9Cp_PUvFiXgd2XRmBpLhumCqHUaqROaLcpYfc'\n",
    "sheet_name = 'store_id_ref'\n",
    "url = f'https://docs.google.com/spreadsheets/d/{sheet_id}/gviz/tq?tqx=out:csv&sheet={sheet_name}'\n",
    "store_id_ref_crm = pd.read_csv(url)\n",
    "store_id_ref_crm = store_id_ref_crm.rename(columns={'store_id' : 'Store ID'})\n",
    "bonus = pd.merge(bonus, store_id_ref_crm[['Store ID', 'recid_plo']], on=['Store ID'], how = 'left')\n",
    "bonus['recid_plo'] = bonus['recid_plo'].astype(int)\n",
    "\n",
    "# Stich sales based on recid_plo & dates, skip if there is no Date\n",
    "start = bonus['Date'].min()\n",
    "end = bonus['Date'].max()\n",
    "\n",
    "start_str = start.strftime('%Y-%m-%d')\n",
    "end_str = end.strftime('%Y-%m-%d')\n",
    "\n",
    "recid_plo_list = bonus['recid_plo'].unique().tolist()\n",
    "recid_plo_list_str = ', '.join(str(id) for id in recid_plo_list)\n",
    "\n",
    "tumbler_recid_plu_list = [1059,1060,1061,1062]\n",
    "gingerbread_recid_plu_list = [485,559,572,573,574,575,1036,1085,1086]\n",
    "stock_exclusions_list = tumbler_recid_plu_list + gingerbread_recid_plu_list\n",
    "stock_exclusions_list_str = ', '.join(str(s) for s in stock_exclusions_list)\n",
    "\n",
    "query = '''\n",
    "SELECT ts2.recid_plo, ts.itemdate as Date, sum(ts.qty*ts.price) as Sales\n",
    "FROM tbl_salesitems ts \n",
    "JOIN tbl_salesheaders ts2 on ts.recid_mixh = ts2.recid\n",
    "WHERE ts.itemdate >= '{start}' and ts.itemdate <= '{end}' and ts2.recid_plo in ({recid_plo_list}) and ts.recid_plu not in ({stock_exclusions_list})\n",
    "GROUP BY ts2.recid_plo, ts.itemdate\n",
    "ORDER BY ts.itemdate ASC, recid_plo ASC\n",
    "'''.format(start=start_str, end = end_str, recid_plo_list = recid_plo_list_str, stock_exclusions_list = stock_exclusions_list_str)\n",
    "\n",
    "sales_df = pd.read_sql(query, mysql_engine)\n",
    "sales_df['Date'] = pd.to_datetime(sales_df['Date'])\n",
    "\n",
    "bonus = pd.merge(bonus, sales_df[['recid_plo', 'Date', 'Sales']], on=['recid_plo', 'Date'], how = 'left')\n",
    "\n",
    "# Stitch Target Sales & Bonus Rates\n",
    "sheet_id = '1rqOeBjA9drmTnjlENvr57RqL5-oxSqe_KGdbdL2MKhM'\n",
    "sheet_name = 'Targets'\n",
    "url = f'https://docs.google.com/spreadsheets/d/{sheet_id}/gviz/tq?tqx=out:csv&sheet={sheet_name}'\n",
    "targets = pd.read_csv(url)\n",
    "targets['Date'] = pd.to_datetime(targets['Date'])\n",
    "\n",
    "# Change Bonus Rates to 0, if Target Sales is not met\n",
    "bonus = pd.merge(bonus, targets[['Store ID', 'Date', 'Target Sales', 'Bonus Rate']], on=['Store ID', 'Date'], how = 'left')\n",
    "bonus['Bonus Rate'] = bonus['Bonus Rate'].where(bonus['Sales'] >= bonus['Target Sales'], 0)\n",
    "bonus['Bonus'] = bonus['Bonus Rate']  * bonus['Hours']\n",
    "\n",
    "# Work out additional_hr\n",
    "additional_hr = additional_hr.dropna(subset=['Employee ID'])\n",
    "additional_hr = pd.merge(additional_hr, employees[['Employee ID', 'First Name', 'Last Name', 'Company']], how='left', on=['Employee ID'])\n",
    "additional_hr_col = [\n",
    "'Employee ID',\n",
    "'First Name',\n",
    "'Last Name',\n",
    "'Preferred Name',\n",
    "'Company',\n",
    "'Store',\n",
    "'Date',\n",
    "'Hours'\n",
    "]\n",
    "additional_hr = additional_hr[additional_hr_col]\n",
    "additional_hr['Date'] = pd.to_datetime(additional_hr['Date'])\n",
    "\n",
    "# Concat rostered_hr and additional_hr\n",
    "analysis = pd.concat([rostered_hr, additional_hr])\n",
    "\n",
    "# Concat Bouns on to Timesheets\n",
    "bonus_summary = bonus.groupby('Employee ID', as_index = False).agg({'Bonus':'sum'})\n",
    "timesheets = pd.merge(timesheets, bonus_summary, on=['Employee ID'], how = 'left')\n",
    "timesheets.fillna({'Bonus':0}, inplace = True)\n",
    "timesheets.rename(columns={'Bonus':'Bonus $'}, inplace = True)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Employee ID</th>\n",
       "      <th>First Name</th>\n",
       "      <th>Last Name</th>\n",
       "      <th>Preferred Name</th>\n",
       "      <th>Company</th>\n",
       "      <th>Store</th>\n",
       "      <th>Date</th>\n",
       "      <th>Hours</th>\n",
       "      <th>Store ID</th>\n",
       "      <th>recid_plo</th>\n",
       "      <th>Sales</th>\n",
       "      <th>Target Sales</th>\n",
       "      <th>Bonus Rate</th>\n",
       "      <th>Bonus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10040</td>\n",
       "      <td>Tran Thu Hang</td>\n",
       "      <td>Vu</td>\n",
       "      <td>Zoe Vu</td>\n",
       "      <td>GCM</td>\n",
       "      <td>MetCentre</td>\n",
       "      <td>2024-08-05</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>S181</td>\n",
       "      <td>198</td>\n",
       "      <td>676.10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10003</td>\n",
       "      <td>Ching Yi</td>\n",
       "      <td>Huang</td>\n",
       "      <td>Amilli Huang</td>\n",
       "      <td>GCM</td>\n",
       "      <td>MetCentre</td>\n",
       "      <td>2024-08-05</td>\n",
       "      <td>6.250000</td>\n",
       "      <td>S181</td>\n",
       "      <td>198</td>\n",
       "      <td>676.10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10090</td>\n",
       "      <td>Hsin-Yi</td>\n",
       "      <td>CHIANG</td>\n",
       "      <td>Ava chiang</td>\n",
       "      <td>HL</td>\n",
       "      <td>MetCentre</td>\n",
       "      <td>2024-08-06</td>\n",
       "      <td>3.750000</td>\n",
       "      <td>S181</td>\n",
       "      <td>198</td>\n",
       "      <td>2545.37</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10040</td>\n",
       "      <td>Tran Thu Hang</td>\n",
       "      <td>Vu</td>\n",
       "      <td>Zoe Vu</td>\n",
       "      <td>GCM</td>\n",
       "      <td>MetCentre</td>\n",
       "      <td>2024-08-06</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>S181</td>\n",
       "      <td>198</td>\n",
       "      <td>2545.37</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10382</td>\n",
       "      <td>Vi Viet Hoang</td>\n",
       "      <td>Ngo</td>\n",
       "      <td>Henry Ngo</td>\n",
       "      <td>SS</td>\n",
       "      <td>MetCentre</td>\n",
       "      <td>2024-08-06</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>S181</td>\n",
       "      <td>198</td>\n",
       "      <td>2545.37</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10306</td>\n",
       "      <td>Thuy An</td>\n",
       "      <td>Pham</td>\n",
       "      <td>Annie Pham</td>\n",
       "      <td>GCM</td>\n",
       "      <td>MetCentre</td>\n",
       "      <td>2024-08-06</td>\n",
       "      <td>5.166667</td>\n",
       "      <td>S181</td>\n",
       "      <td>198</td>\n",
       "      <td>2545.37</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10090</td>\n",
       "      <td>Hsin-Yi</td>\n",
       "      <td>CHIANG</td>\n",
       "      <td>Ava chiang</td>\n",
       "      <td>HL</td>\n",
       "      <td>MetCentre</td>\n",
       "      <td>2024-08-07</td>\n",
       "      <td>9.366667</td>\n",
       "      <td>S181</td>\n",
       "      <td>198</td>\n",
       "      <td>3258.05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10280</td>\n",
       "      <td>Luoshi</td>\n",
       "      <td>Wu</td>\n",
       "      <td>Stella Wu</td>\n",
       "      <td>GCM</td>\n",
       "      <td>MetCentre</td>\n",
       "      <td>2024-08-07</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>S181</td>\n",
       "      <td>198</td>\n",
       "      <td>3258.05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10250</td>\n",
       "      <td>Amy</td>\n",
       "      <td>Hou</td>\n",
       "      <td>Amy Hou</td>\n",
       "      <td>GCM</td>\n",
       "      <td>MetCentre</td>\n",
       "      <td>2024-08-07</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>S181</td>\n",
       "      <td>198</td>\n",
       "      <td>3258.05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10160</td>\n",
       "      <td>Pulin</td>\n",
       "      <td>Pan</td>\n",
       "      <td>Lexi Pan</td>\n",
       "      <td>GCM</td>\n",
       "      <td>MetCentre</td>\n",
       "      <td>2024-08-07</td>\n",
       "      <td>6.700000</td>\n",
       "      <td>S181</td>\n",
       "      <td>198</td>\n",
       "      <td>3258.05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10090</td>\n",
       "      <td>Hsin-Yi</td>\n",
       "      <td>CHIANG</td>\n",
       "      <td>Ava chiang</td>\n",
       "      <td>HL</td>\n",
       "      <td>MetCentre</td>\n",
       "      <td>2024-08-08</td>\n",
       "      <td>6.150000</td>\n",
       "      <td>S181</td>\n",
       "      <td>198</td>\n",
       "      <td>1592.44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10334</td>\n",
       "      <td>Huy Tien</td>\n",
       "      <td>Phan</td>\n",
       "      <td>Pat phan</td>\n",
       "      <td>SS</td>\n",
       "      <td>MetCentre</td>\n",
       "      <td>2024-08-08</td>\n",
       "      <td>7.350000</td>\n",
       "      <td>S181</td>\n",
       "      <td>198</td>\n",
       "      <td>1592.44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10090</td>\n",
       "      <td>Hsin-Yi</td>\n",
       "      <td>CHIANG</td>\n",
       "      <td>Ava chiang</td>\n",
       "      <td>HL</td>\n",
       "      <td>MetCentre</td>\n",
       "      <td>2024-08-09</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>S181</td>\n",
       "      <td>198</td>\n",
       "      <td>1223.73</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>10334</td>\n",
       "      <td>Huy Tien</td>\n",
       "      <td>Phan</td>\n",
       "      <td>Pat phan</td>\n",
       "      <td>SS</td>\n",
       "      <td>MetCentre</td>\n",
       "      <td>2024-08-09</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>S181</td>\n",
       "      <td>198</td>\n",
       "      <td>1223.73</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>10160</td>\n",
       "      <td>Pulin</td>\n",
       "      <td>Pan</td>\n",
       "      <td>Lexi Pan</td>\n",
       "      <td>GCM</td>\n",
       "      <td>MetCentre</td>\n",
       "      <td>2024-08-12</td>\n",
       "      <td>6.783333</td>\n",
       "      <td>S181</td>\n",
       "      <td>198</td>\n",
       "      <td>1130.63</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>10284</td>\n",
       "      <td>Kim Ngoc Ngo</td>\n",
       "      <td>Bui</td>\n",
       "      <td>Mari Bui</td>\n",
       "      <td>HL</td>\n",
       "      <td>MetCentre</td>\n",
       "      <td>2024-08-12</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>S181</td>\n",
       "      <td>198</td>\n",
       "      <td>1130.63</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>10040</td>\n",
       "      <td>Tran Thu Hang</td>\n",
       "      <td>Vu</td>\n",
       "      <td>Zoe Vu</td>\n",
       "      <td>GCM</td>\n",
       "      <td>MetCentre</td>\n",
       "      <td>2024-08-13</td>\n",
       "      <td>5.966667</td>\n",
       "      <td>S181</td>\n",
       "      <td>198</td>\n",
       "      <td>1480.70</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>10382</td>\n",
       "      <td>Vi Viet Hoang</td>\n",
       "      <td>Ngo</td>\n",
       "      <td>Henry Ngo</td>\n",
       "      <td>SS</td>\n",
       "      <td>MetCentre</td>\n",
       "      <td>2024-08-13</td>\n",
       "      <td>6.600000</td>\n",
       "      <td>S181</td>\n",
       "      <td>198</td>\n",
       "      <td>1480.70</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>10090</td>\n",
       "      <td>Hsin-Yi</td>\n",
       "      <td>CHIANG</td>\n",
       "      <td>Ava chiang</td>\n",
       "      <td>HL</td>\n",
       "      <td>MetCentre</td>\n",
       "      <td>2024-08-14</td>\n",
       "      <td>6.383333</td>\n",
       "      <td>S181</td>\n",
       "      <td>198</td>\n",
       "      <td>1480.84</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>10040</td>\n",
       "      <td>Tran Thu Hang</td>\n",
       "      <td>Vu</td>\n",
       "      <td>Zoe Vu</td>\n",
       "      <td>GCM</td>\n",
       "      <td>MetCentre</td>\n",
       "      <td>2024-08-14</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>S181</td>\n",
       "      <td>198</td>\n",
       "      <td>1480.84</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>10090</td>\n",
       "      <td>Hsin-Yi</td>\n",
       "      <td>CHIANG</td>\n",
       "      <td>Ava chiang</td>\n",
       "      <td>HL</td>\n",
       "      <td>MetCentre</td>\n",
       "      <td>2024-08-15</td>\n",
       "      <td>9.150000</td>\n",
       "      <td>S181</td>\n",
       "      <td>198</td>\n",
       "      <td>1776.94</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>10334</td>\n",
       "      <td>Huy Tien</td>\n",
       "      <td>Phan</td>\n",
       "      <td>Pat phan</td>\n",
       "      <td>SS</td>\n",
       "      <td>MetCentre</td>\n",
       "      <td>2024-08-15</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>S181</td>\n",
       "      <td>198</td>\n",
       "      <td>1776.94</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>10334</td>\n",
       "      <td>Huy Tien</td>\n",
       "      <td>Phan</td>\n",
       "      <td>Pat phan</td>\n",
       "      <td>SS</td>\n",
       "      <td>MetCentre</td>\n",
       "      <td>2024-08-16</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>S181</td>\n",
       "      <td>198</td>\n",
       "      <td>1325.21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>10031</td>\n",
       "      <td>Qinyi</td>\n",
       "      <td>ZHOU</td>\n",
       "      <td>Cordelia Zhou</td>\n",
       "      <td>GCM</td>\n",
       "      <td>MetCentre</td>\n",
       "      <td>2024-08-16</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>S181</td>\n",
       "      <td>198</td>\n",
       "      <td>1325.21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Employee ID     First Name Last Name Preferred Name Company      Store  \\\n",
       "0         10040  Tran Thu Hang        Vu         Zoe Vu     GCM  MetCentre   \n",
       "1         10003       Ching Yi     Huang   Amilli Huang     GCM  MetCentre   \n",
       "2         10090        Hsin-Yi    CHIANG     Ava chiang      HL  MetCentre   \n",
       "3         10040  Tran Thu Hang        Vu         Zoe Vu     GCM  MetCentre   \n",
       "4         10382  Vi Viet Hoang       Ngo      Henry Ngo      SS  MetCentre   \n",
       "5         10306        Thuy An      Pham     Annie Pham     GCM  MetCentre   \n",
       "6         10090        Hsin-Yi    CHIANG     Ava chiang      HL  MetCentre   \n",
       "7         10280         Luoshi        Wu      Stella Wu     GCM  MetCentre   \n",
       "8         10250            Amy       Hou        Amy Hou     GCM  MetCentre   \n",
       "9         10160          Pulin       Pan       Lexi Pan     GCM  MetCentre   \n",
       "10        10090        Hsin-Yi    CHIANG     Ava chiang      HL  MetCentre   \n",
       "11        10334       Huy Tien      Phan       Pat phan      SS  MetCentre   \n",
       "12        10090        Hsin-Yi    CHIANG     Ava chiang      HL  MetCentre   \n",
       "13        10334       Huy Tien      Phan       Pat phan      SS  MetCentre   \n",
       "14        10160          Pulin       Pan       Lexi Pan     GCM  MetCentre   \n",
       "15        10284   Kim Ngoc Ngo       Bui       Mari Bui      HL  MetCentre   \n",
       "16        10040  Tran Thu Hang        Vu         Zoe Vu     GCM  MetCentre   \n",
       "17        10382  Vi Viet Hoang       Ngo      Henry Ngo      SS  MetCentre   \n",
       "18        10090        Hsin-Yi    CHIANG     Ava chiang      HL  MetCentre   \n",
       "19        10040  Tran Thu Hang        Vu         Zoe Vu     GCM  MetCentre   \n",
       "20        10090        Hsin-Yi    CHIANG     Ava chiang      HL  MetCentre   \n",
       "21        10334       Huy Tien      Phan       Pat phan      SS  MetCentre   \n",
       "22        10334       Huy Tien      Phan       Pat phan      SS  MetCentre   \n",
       "23        10031          Qinyi      ZHOU  Cordelia Zhou     GCM  MetCentre   \n",
       "\n",
       "         Date     Hours Store ID  recid_plo    Sales  Target Sales  \\\n",
       "0  2024-08-05  7.500000     S181        198   676.10           NaN   \n",
       "1  2024-08-05  6.250000     S181        198   676.10           NaN   \n",
       "2  2024-08-06  3.750000     S181        198  2545.37           NaN   \n",
       "3  2024-08-06  7.500000     S181        198  2545.37           NaN   \n",
       "4  2024-08-06  7.500000     S181        198  2545.37           NaN   \n",
       "5  2024-08-06  5.166667     S181        198  2545.37           NaN   \n",
       "6  2024-08-07  9.366667     S181        198  3258.05           NaN   \n",
       "7  2024-08-07  7.500000     S181        198  3258.05           NaN   \n",
       "8  2024-08-07  5.500000     S181        198  3258.05           NaN   \n",
       "9  2024-08-07  6.700000     S181        198  3258.05           NaN   \n",
       "10 2024-08-08  6.150000     S181        198  1592.44           NaN   \n",
       "11 2024-08-08  7.350000     S181        198  1592.44           NaN   \n",
       "12 2024-08-09  5.500000     S181        198  1223.73           NaN   \n",
       "13 2024-08-09  6.500000     S181        198  1223.73           NaN   \n",
       "14 2024-08-12  6.783333     S181        198  1130.63           NaN   \n",
       "15 2024-08-12  6.500000     S181        198  1130.63           NaN   \n",
       "16 2024-08-13  5.966667     S181        198  1480.70           NaN   \n",
       "17 2024-08-13  6.600000     S181        198  1480.70           NaN   \n",
       "18 2024-08-14  6.383333     S181        198  1480.84           NaN   \n",
       "19 2024-08-14  7.500000     S181        198  1480.84           NaN   \n",
       "20 2024-08-15  9.150000     S181        198  1776.94           NaN   \n",
       "21 2024-08-15  5.000000     S181        198  1776.94           NaN   \n",
       "22 2024-08-16  6.500000     S181        198  1325.21           NaN   \n",
       "23 2024-08-16  6.200000     S181        198  1325.21           NaN   \n",
       "\n",
       "    Bonus Rate  Bonus  \n",
       "0          0.0    0.0  \n",
       "1          0.0    0.0  \n",
       "2          0.0    0.0  \n",
       "3          0.0    0.0  \n",
       "4          0.0    0.0  \n",
       "5          0.0    0.0  \n",
       "6          0.0    0.0  \n",
       "7          0.0    0.0  \n",
       "8          0.0    0.0  \n",
       "9          0.0    0.0  \n",
       "10         0.0    0.0  \n",
       "11         0.0    0.0  \n",
       "12         0.0    0.0  \n",
       "13         0.0    0.0  \n",
       "14         0.0    0.0  \n",
       "15         0.0    0.0  \n",
       "16         0.0    0.0  \n",
       "17         0.0    0.0  \n",
       "18         0.0    0.0  \n",
       "19         0.0    0.0  \n",
       "20         0.0    0.0  \n",
       "21         0.0    0.0  \n",
       "22         0.0    0.0  \n",
       "23         0.0    0.0  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bonus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Employee ID</th>\n",
       "      <th>First Name</th>\n",
       "      <th>Last Name</th>\n",
       "      <th>Preferred Name</th>\n",
       "      <th>Company</th>\n",
       "      <th>Store</th>\n",
       "      <th>Date</th>\n",
       "      <th>Hours</th>\n",
       "      <th>Store ID</th>\n",
       "      <th>recid_plo</th>\n",
       "      <th>Sales</th>\n",
       "      <th>Target Sales</th>\n",
       "      <th>Bonus Rate</th>\n",
       "      <th>Bonus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10035</td>\n",
       "      <td>Shanzhi</td>\n",
       "      <td>Chen</td>\n",
       "      <td>CHLOE CHEN</td>\n",
       "      <td>GCM</td>\n",
       "      <td>Waterloo</td>\n",
       "      <td>2024-01-22</td>\n",
       "      <td>8.5</td>\n",
       "      <td>S164</td>\n",
       "      <td>154</td>\n",
       "      <td>NaN</td>\n",
       "      <td>724.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10035</td>\n",
       "      <td>Shanzhi</td>\n",
       "      <td>Chen</td>\n",
       "      <td>CHLOE CHEN</td>\n",
       "      <td>GCM</td>\n",
       "      <td>Waterloo</td>\n",
       "      <td>2024-01-22</td>\n",
       "      <td>8.5</td>\n",
       "      <td>S164</td>\n",
       "      <td>154</td>\n",
       "      <td>NaN</td>\n",
       "      <td>784.39</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10052</td>\n",
       "      <td>Yeyu</td>\n",
       "      <td>Deng</td>\n",
       "      <td>DEREK DENG</td>\n",
       "      <td>GCM</td>\n",
       "      <td>Waterloo</td>\n",
       "      <td>2024-01-22</td>\n",
       "      <td>6.0</td>\n",
       "      <td>S164</td>\n",
       "      <td>154</td>\n",
       "      <td>NaN</td>\n",
       "      <td>724.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10052</td>\n",
       "      <td>Yeyu</td>\n",
       "      <td>Deng</td>\n",
       "      <td>DEREK DENG</td>\n",
       "      <td>GCM</td>\n",
       "      <td>Waterloo</td>\n",
       "      <td>2024-01-22</td>\n",
       "      <td>6.0</td>\n",
       "      <td>S164</td>\n",
       "      <td>154</td>\n",
       "      <td>NaN</td>\n",
       "      <td>784.39</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10299</td>\n",
       "      <td>YUTANG</td>\n",
       "      <td>HUANG</td>\n",
       "      <td>RYAN HUANG</td>\n",
       "      <td>GCM</td>\n",
       "      <td>Waterloo</td>\n",
       "      <td>2024-01-23</td>\n",
       "      <td>7.5</td>\n",
       "      <td>S164</td>\n",
       "      <td>154</td>\n",
       "      <td>NaN</td>\n",
       "      <td>978.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1803</th>\n",
       "      <td>10343</td>\n",
       "      <td>Theresa</td>\n",
       "      <td>Chow</td>\n",
       "      <td>Theresa chow</td>\n",
       "      <td>SS</td>\n",
       "      <td>501</td>\n",
       "      <td>2024-02-04</td>\n",
       "      <td>6.5</td>\n",
       "      <td>S001</td>\n",
       "      <td>124</td>\n",
       "      <td>5592.42</td>\n",
       "      <td>8213.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1804</th>\n",
       "      <td>10054</td>\n",
       "      <td>Yiran</td>\n",
       "      <td>Zhang</td>\n",
       "      <td>Eos zhang</td>\n",
       "      <td>SS</td>\n",
       "      <td>501</td>\n",
       "      <td>2024-02-04</td>\n",
       "      <td>7.5</td>\n",
       "      <td>S001</td>\n",
       "      <td>124</td>\n",
       "      <td>5592.42</td>\n",
       "      <td>7581.97</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1805</th>\n",
       "      <td>10054</td>\n",
       "      <td>Yiran</td>\n",
       "      <td>Zhang</td>\n",
       "      <td>Eos zhang</td>\n",
       "      <td>SS</td>\n",
       "      <td>501</td>\n",
       "      <td>2024-02-04</td>\n",
       "      <td>7.5</td>\n",
       "      <td>S001</td>\n",
       "      <td>124</td>\n",
       "      <td>5592.42</td>\n",
       "      <td>8213.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1806</th>\n",
       "      <td>10334</td>\n",
       "      <td>Huy Tien</td>\n",
       "      <td>Phan</td>\n",
       "      <td>Pat phan</td>\n",
       "      <td>SS</td>\n",
       "      <td>501</td>\n",
       "      <td>2024-02-04</td>\n",
       "      <td>7.5</td>\n",
       "      <td>S001</td>\n",
       "      <td>124</td>\n",
       "      <td>5592.42</td>\n",
       "      <td>7581.97</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1807</th>\n",
       "      <td>10334</td>\n",
       "      <td>Huy Tien</td>\n",
       "      <td>Phan</td>\n",
       "      <td>Pat phan</td>\n",
       "      <td>SS</td>\n",
       "      <td>501</td>\n",
       "      <td>2024-02-04</td>\n",
       "      <td>7.5</td>\n",
       "      <td>S001</td>\n",
       "      <td>124</td>\n",
       "      <td>5592.42</td>\n",
       "      <td>8213.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1808 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Employee ID First Name Last Name Preferred Name Company     Store  \\\n",
       "0           10035    Shanzhi      Chen     CHLOE CHEN     GCM  Waterloo   \n",
       "1           10035    Shanzhi      Chen     CHLOE CHEN     GCM  Waterloo   \n",
       "2           10052       Yeyu      Deng     DEREK DENG     GCM  Waterloo   \n",
       "3           10052       Yeyu      Deng     DEREK DENG     GCM  Waterloo   \n",
       "4           10299     YUTANG     HUANG     RYAN HUANG     GCM  Waterloo   \n",
       "...           ...        ...       ...            ...     ...       ...   \n",
       "1803        10343    Theresa      Chow   Theresa chow      SS       501   \n",
       "1804        10054      Yiran     Zhang      Eos zhang      SS       501   \n",
       "1805        10054      Yiran     Zhang      Eos zhang      SS       501   \n",
       "1806        10334   Huy Tien      Phan       Pat phan      SS       501   \n",
       "1807        10334   Huy Tien      Phan       Pat phan      SS       501   \n",
       "\n",
       "           Date  Hours Store ID  recid_plo    Sales  Target Sales  Bonus Rate  \\\n",
       "0    2024-01-22    8.5     S164        154      NaN        724.06         0.0   \n",
       "1    2024-01-22    8.5     S164        154      NaN        784.39         0.0   \n",
       "2    2024-01-22    6.0     S164        154      NaN        724.06         0.0   \n",
       "3    2024-01-22    6.0     S164        154      NaN        784.39         0.0   \n",
       "4    2024-01-23    7.5     S164        154      NaN        978.01         0.0   \n",
       "...         ...    ...      ...        ...      ...           ...         ...   \n",
       "1803 2024-02-04    6.5     S001        124  5592.42       8213.80         0.0   \n",
       "1804 2024-02-04    7.5     S001        124  5592.42       7581.97         0.0   \n",
       "1805 2024-02-04    7.5     S001        124  5592.42       8213.80         0.0   \n",
       "1806 2024-02-04    7.5     S001        124  5592.42       7581.97         0.0   \n",
       "1807 2024-02-04    7.5     S001        124  5592.42       8213.80         0.0   \n",
       "\n",
       "      Bonus  \n",
       "0       0.0  \n",
       "1       0.0  \n",
       "2       0.0  \n",
       "3       0.0  \n",
       "4       0.0  \n",
       "...     ...  \n",
       "1803    0.0  \n",
       "1804    0.0  \n",
       "1805    0.0  \n",
       "1806    0.0  \n",
       "1807    0.0  \n",
       "\n",
       "[1808 rows x 14 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bonus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Employee ID</th>\n",
       "      <th>First Name</th>\n",
       "      <th>Last Name</th>\n",
       "      <th>Preferred Name</th>\n",
       "      <th>Company</th>\n",
       "      <th>Store</th>\n",
       "      <th>Date</th>\n",
       "      <th>Hours</th>\n",
       "      <th>Store ID</th>\n",
       "      <th>recid_plo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10035</td>\n",
       "      <td>Shanzhi</td>\n",
       "      <td>Chen</td>\n",
       "      <td>CHLOE CHEN</td>\n",
       "      <td>GCM</td>\n",
       "      <td>Waterloo</td>\n",
       "      <td>2024-01-22</td>\n",
       "      <td>8.5</td>\n",
       "      <td>S164</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10052</td>\n",
       "      <td>Yeyu</td>\n",
       "      <td>Deng</td>\n",
       "      <td>DEREK DENG</td>\n",
       "      <td>GCM</td>\n",
       "      <td>Waterloo</td>\n",
       "      <td>2024-01-22</td>\n",
       "      <td>6.0</td>\n",
       "      <td>S164</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10299</td>\n",
       "      <td>YUTANG</td>\n",
       "      <td>HUANG</td>\n",
       "      <td>RYAN HUANG</td>\n",
       "      <td>GCM</td>\n",
       "      <td>Waterloo</td>\n",
       "      <td>2024-01-23</td>\n",
       "      <td>7.5</td>\n",
       "      <td>S164</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10052</td>\n",
       "      <td>Yeyu</td>\n",
       "      <td>Deng</td>\n",
       "      <td>DEREK DENG</td>\n",
       "      <td>GCM</td>\n",
       "      <td>Waterloo</td>\n",
       "      <td>2024-01-23</td>\n",
       "      <td>7.0</td>\n",
       "      <td>S164</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10052</td>\n",
       "      <td>Yeyu</td>\n",
       "      <td>Deng</td>\n",
       "      <td>DEREK DENG</td>\n",
       "      <td>GCM</td>\n",
       "      <td>Waterloo</td>\n",
       "      <td>2024-01-24</td>\n",
       "      <td>14.5</td>\n",
       "      <td>S164</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>917</th>\n",
       "      <td>10276</td>\n",
       "      <td>Cana</td>\n",
       "      <td>Fukuda</td>\n",
       "      <td>Cana fukuda</td>\n",
       "      <td>GCM</td>\n",
       "      <td>501</td>\n",
       "      <td>2024-02-04</td>\n",
       "      <td>9.0</td>\n",
       "      <td>S001</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>918</th>\n",
       "      <td>10303</td>\n",
       "      <td>Trong Van</td>\n",
       "      <td>Le</td>\n",
       "      <td>Van le</td>\n",
       "      <td>HL</td>\n",
       "      <td>501</td>\n",
       "      <td>2024-02-04</td>\n",
       "      <td>5.0</td>\n",
       "      <td>S001</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>919</th>\n",
       "      <td>10343</td>\n",
       "      <td>Theresa</td>\n",
       "      <td>Chow</td>\n",
       "      <td>Theresa chow</td>\n",
       "      <td>SS</td>\n",
       "      <td>501</td>\n",
       "      <td>2024-02-04</td>\n",
       "      <td>6.5</td>\n",
       "      <td>S001</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>920</th>\n",
       "      <td>10054</td>\n",
       "      <td>Yiran</td>\n",
       "      <td>Zhang</td>\n",
       "      <td>Eos zhang</td>\n",
       "      <td>SS</td>\n",
       "      <td>501</td>\n",
       "      <td>2024-02-04</td>\n",
       "      <td>7.5</td>\n",
       "      <td>S001</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>921</th>\n",
       "      <td>10334</td>\n",
       "      <td>Huy Tien</td>\n",
       "      <td>Phan</td>\n",
       "      <td>Pat phan</td>\n",
       "      <td>SS</td>\n",
       "      <td>501</td>\n",
       "      <td>2024-02-04</td>\n",
       "      <td>7.5</td>\n",
       "      <td>S001</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>922 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Employee ID First Name Last Name Preferred Name Company     Store  \\\n",
       "0          10035    Shanzhi      Chen     CHLOE CHEN     GCM  Waterloo   \n",
       "1          10052       Yeyu      Deng     DEREK DENG     GCM  Waterloo   \n",
       "2          10299     YUTANG     HUANG     RYAN HUANG     GCM  Waterloo   \n",
       "3          10052       Yeyu      Deng     DEREK DENG     GCM  Waterloo   \n",
       "4          10052       Yeyu      Deng     DEREK DENG     GCM  Waterloo   \n",
       "..           ...        ...       ...            ...     ...       ...   \n",
       "917        10276       Cana    Fukuda    Cana fukuda     GCM       501   \n",
       "918        10303  Trong Van        Le         Van le      HL       501   \n",
       "919        10343    Theresa      Chow   Theresa chow      SS       501   \n",
       "920        10054      Yiran     Zhang      Eos zhang      SS       501   \n",
       "921        10334   Huy Tien      Phan       Pat phan      SS       501   \n",
       "\n",
       "          Date  Hours Store ID  recid_plo  \n",
       "0   2024-01-22    8.5     S164        154  \n",
       "1   2024-01-22    6.0     S164        154  \n",
       "2   2024-01-23    7.5     S164        154  \n",
       "3   2024-01-23    7.0     S164        154  \n",
       "4   2024-01-24   14.5     S164        154  \n",
       "..         ...    ...      ...        ...  \n",
       "917 2024-02-04    9.0     S001        124  \n",
       "918 2024-02-04    5.0     S001        124  \n",
       "919 2024-02-04    6.5     S001        124  \n",
       "920 2024-02-04    7.5     S001        124  \n",
       "921 2024-02-04    7.5     S001        124  \n",
       "\n",
       "[922 rows x 10 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Employee ID</th>\n",
       "      <th>First Name</th>\n",
       "      <th>Last Name</th>\n",
       "      <th>Preferred Name</th>\n",
       "      <th>Company</th>\n",
       "      <th>Store</th>\n",
       "      <th>Date</th>\n",
       "      <th>Hours</th>\n",
       "      <th>Store ID</th>\n",
       "      <th>recid_plo</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10035</td>\n",
       "      <td>Shanzhi</td>\n",
       "      <td>Chen</td>\n",
       "      <td>CHLOE CHEN</td>\n",
       "      <td>GCM</td>\n",
       "      <td>Waterloo</td>\n",
       "      <td>2024-01-22</td>\n",
       "      <td>8.5</td>\n",
       "      <td>S164</td>\n",
       "      <td>154</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10052</td>\n",
       "      <td>Yeyu</td>\n",
       "      <td>Deng</td>\n",
       "      <td>DEREK DENG</td>\n",
       "      <td>GCM</td>\n",
       "      <td>Waterloo</td>\n",
       "      <td>2024-01-22</td>\n",
       "      <td>6.0</td>\n",
       "      <td>S164</td>\n",
       "      <td>154</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10299</td>\n",
       "      <td>YUTANG</td>\n",
       "      <td>HUANG</td>\n",
       "      <td>RYAN HUANG</td>\n",
       "      <td>GCM</td>\n",
       "      <td>Waterloo</td>\n",
       "      <td>2024-01-23</td>\n",
       "      <td>7.5</td>\n",
       "      <td>S164</td>\n",
       "      <td>154</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10052</td>\n",
       "      <td>Yeyu</td>\n",
       "      <td>Deng</td>\n",
       "      <td>DEREK DENG</td>\n",
       "      <td>GCM</td>\n",
       "      <td>Waterloo</td>\n",
       "      <td>2024-01-23</td>\n",
       "      <td>7.0</td>\n",
       "      <td>S164</td>\n",
       "      <td>154</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10052</td>\n",
       "      <td>Yeyu</td>\n",
       "      <td>Deng</td>\n",
       "      <td>DEREK DENG</td>\n",
       "      <td>GCM</td>\n",
       "      <td>Waterloo</td>\n",
       "      <td>2024-01-24</td>\n",
       "      <td>14.5</td>\n",
       "      <td>S164</td>\n",
       "      <td>154</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>917</th>\n",
       "      <td>10276</td>\n",
       "      <td>Cana</td>\n",
       "      <td>Fukuda</td>\n",
       "      <td>Cana fukuda</td>\n",
       "      <td>GCM</td>\n",
       "      <td>501</td>\n",
       "      <td>2024-02-04</td>\n",
       "      <td>9.0</td>\n",
       "      <td>S001</td>\n",
       "      <td>124</td>\n",
       "      <td>5592.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>918</th>\n",
       "      <td>10303</td>\n",
       "      <td>Trong Van</td>\n",
       "      <td>Le</td>\n",
       "      <td>Van le</td>\n",
       "      <td>HL</td>\n",
       "      <td>501</td>\n",
       "      <td>2024-02-04</td>\n",
       "      <td>5.0</td>\n",
       "      <td>S001</td>\n",
       "      <td>124</td>\n",
       "      <td>5592.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>919</th>\n",
       "      <td>10343</td>\n",
       "      <td>Theresa</td>\n",
       "      <td>Chow</td>\n",
       "      <td>Theresa chow</td>\n",
       "      <td>SS</td>\n",
       "      <td>501</td>\n",
       "      <td>2024-02-04</td>\n",
       "      <td>6.5</td>\n",
       "      <td>S001</td>\n",
       "      <td>124</td>\n",
       "      <td>5592.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>920</th>\n",
       "      <td>10054</td>\n",
       "      <td>Yiran</td>\n",
       "      <td>Zhang</td>\n",
       "      <td>Eos zhang</td>\n",
       "      <td>SS</td>\n",
       "      <td>501</td>\n",
       "      <td>2024-02-04</td>\n",
       "      <td>7.5</td>\n",
       "      <td>S001</td>\n",
       "      <td>124</td>\n",
       "      <td>5592.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>921</th>\n",
       "      <td>10334</td>\n",
       "      <td>Huy Tien</td>\n",
       "      <td>Phan</td>\n",
       "      <td>Pat phan</td>\n",
       "      <td>SS</td>\n",
       "      <td>501</td>\n",
       "      <td>2024-02-04</td>\n",
       "      <td>7.5</td>\n",
       "      <td>S001</td>\n",
       "      <td>124</td>\n",
       "      <td>5592.42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>922 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Employee ID First Name Last Name Preferred Name Company     Store  \\\n",
       "0          10035    Shanzhi      Chen     CHLOE CHEN     GCM  Waterloo   \n",
       "1          10052       Yeyu      Deng     DEREK DENG     GCM  Waterloo   \n",
       "2          10299     YUTANG     HUANG     RYAN HUANG     GCM  Waterloo   \n",
       "3          10052       Yeyu      Deng     DEREK DENG     GCM  Waterloo   \n",
       "4          10052       Yeyu      Deng     DEREK DENG     GCM  Waterloo   \n",
       "..           ...        ...       ...            ...     ...       ...   \n",
       "917        10276       Cana    Fukuda    Cana fukuda     GCM       501   \n",
       "918        10303  Trong Van        Le         Van le      HL       501   \n",
       "919        10343    Theresa      Chow   Theresa chow      SS       501   \n",
       "920        10054      Yiran     Zhang      Eos zhang      SS       501   \n",
       "921        10334   Huy Tien      Phan       Pat phan      SS       501   \n",
       "\n",
       "          Date  Hours Store ID  recid_plo    Sales  \n",
       "0   2024-01-22    8.5     S164        154      NaN  \n",
       "1   2024-01-22    6.0     S164        154      NaN  \n",
       "2   2024-01-23    7.5     S164        154      NaN  \n",
       "3   2024-01-23    7.0     S164        154      NaN  \n",
       "4   2024-01-24   14.5     S164        154      NaN  \n",
       "..         ...    ...      ...        ...      ...  \n",
       "917 2024-02-04    9.0     S001        124  5592.42  \n",
       "918 2024-02-04    5.0     S001        124  5592.42  \n",
       "919 2024-02-04    6.5     S001        124  5592.42  \n",
       "920 2024-02-04    7.5     S001        124  5592.42  \n",
       "921 2024-02-04    7.5     S001        124  5592.42  \n",
       "\n",
       "[922 rows x 11 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bonus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calc_timesheets_n_billings(files):\n",
    "  print('calc')\n",
    "  timesheets = pd.DataFrame()\n",
    "  billings = pd.DataFrame()\n",
    "  rostered_hr = pd.DataFrame()\n",
    "  additional_hr = pd.DataFrame()\n",
    "\n",
    "  for file in files:\n",
    "    # time.sleep(1)\n",
    "    timesheet = pd.read_excel(file, sheet_name = 'Timesheet')\n",
    "    billing = pd.read_excel(file, sheet_name = 'Billing')\n",
    "    rostered_hr_w1 = extract_rostered_hr(file, 'Week 1 Roster')\n",
    "    rostered_hr_w2 = extract_rostered_hr(file, 'Week 2 Roster')\n",
    "    additional_hr_w1 = extract_additional_hr(file, 'Week 1 Roster')\n",
    "    additional_hr_w2 = extract_additional_hr(file, 'Week 2 Roster')\n",
    "    employees = pd.read_excel(file, sheet_name = 'Employees')\n",
    "\n",
    "    timesheets = pd.concat([timesheets, timesheet], ignore_index=True)\n",
    "    billings = pd.concat([billings, billing], ignore_index=True)\n",
    "    rostered_hr = pd.concat([rostered_hr, rostered_hr_w1], ignore_index=True)\n",
    "    rostered_hr = pd.concat([rostered_hr, rostered_hr_w2], ignore_index=True)\n",
    "    additional_hr = pd.concat([additional_hr, additional_hr_w1], ignore_index=True)\n",
    "    additional_hr = pd.concat([additional_hr, additional_hr_w2], ignore_index=True)\n",
    "\n",
    "  #Remove irrelevant rows\n",
    "  timesheets.dropna(subset = ['Employee ID'], inplace=True)\n",
    "  #Keep the needed columns\n",
    "  timesheets_cols = [1,2,3,7,8,9,10,11,12,13,14,15,16,17,18,19,20]\n",
    "  timesheets = timesheets[timesheets.columns[timesheets_cols]]\n",
    "  timesheets['Update Wage'] = timesheets['Update Wage'].astype(bool)\n",
    "  #Column Aggregations\n",
    "  timesheets_agg_cols = {'First Name':'first','Last Name':'first','Update Wage':'first','Hour Threshold':'first','Company':'first','Ord':'sum','Sat':'sum','Sun':'sum','Pub':'sum','Eve 1':'sum','Eve 2':'sum','No. of Shifts':'sum','Personal Leave':'sum','Annual Leave':'sum','Unpaid Leave':'sum','Total':'sum'}\n",
    "  timesheets = timesheets.groupby('Employee ID', as_index = False).agg(timesheets_agg_cols)\n",
    "  #Calculate Over Threshold\n",
    "  timesheets['Over Threshold'] = timesheets['Total'] - timesheets['Hour Threshold']\n",
    "  timesheets.loc[timesheets[\"Over Threshold\"] <=0, \"Over Threshold\"] = 0\n",
    "  #Keep Over Thresholds to a new df\n",
    "  over_threshold = timesheets[timesheets['Over Threshold']>0]\n",
    "  #Reduce Ord & Total with the excess\n",
    "  timesheets['Ord'] = timesheets['Ord'] - timesheets['Over Threshold']\n",
    "  timesheets['Total'] = timesheets['Total'] - timesheets['Over Threshold']\n",
    "  #Convert 80 & 100 hours to 76 hours\n",
    "  hours_col = ['Ord', 'Sat','Sun','Eve 1','Eve 2','Pub','Personal Leave', 'Annual Leave', 'Unpaid Leave', 'Total']\n",
    "  if(100 in timesheets[\"Hour Threshold\"].values):\n",
    "    timesheets.loc[timesheets[\"Hour Threshold\"] == 100, hours_col] = timesheets[hours_col]/100*76\n",
    "  if(80 in timesheets[\"Hour Threshold\"].values):\n",
    "    timesheets.loc[timesheets[\"Hour Threshold\"] == 80, hours_col] = timesheets[hours_col]/80*76\n",
    "  if any(timesheets[\"Hour Threshold\"] > 1000):\n",
    "    # Find rows where \"Hour Threshold\" is greater than 1000\n",
    "    rows_to_update = timesheets.loc[timesheets[\"Hour Threshold\"] > 1000]\n",
    "    # Perform actions on the rows\n",
    "    for index, row in rows_to_update.iterrows():\n",
    "      threshold = int(row[\"Hour Threshold\"])\n",
    "      base = int(str(threshold)[:2])\n",
    "      # print('before conversion')\n",
    "      conversion = int(str(threshold)[-2:])\n",
    "      # print('after conversion')\n",
    "      # Update multiple columns using .loc\n",
    "      timesheets.loc[index, hours_col] = timesheets.loc[index, hours_col] / conversion * base\n",
    "\n",
    "  #drop Hour Threshold & Over Threshold\n",
    "  timesheets = timesheets.drop(['Hour Threshold','Over Threshold'],axis = 1)\n",
    "\n",
    "  #Remove irrelevant rows\n",
    "  billings.dropna(subset=['Store'],inplace = True)\n",
    "  billings = billings[billings['Total'] > 0]\n",
    "\n",
    "  #Keep the needed columns\n",
    "  billings_cols = [0,1,2,3,4,5,6,7,8,9,10,11]\n",
    "  billings = billings[billings.columns[billings_cols]]\n",
    "  #Column Aggregations\n",
    "  billings_agg_cols = {'Ord':'sum','Sat':'sum','Sun':'sum','Pub':'sum','Eve 1':'sum','Eve 2':'sum','No. of Shifts':'sum','Personal Leave':'sum','Annual Leave':'sum','Unpaid Leave':'sum','Total':'sum'}\n",
    "  billings = billings.groupby('Store', as_index = False).agg(billings_agg_cols)\n",
    "\n",
    "  rostered_hr = pd.merge(rostered_hr, employees[['Employee ID', 'First Name', 'Last Name', 'Company']], how='left', on=['Employee ID'])\n",
    "  rostered_hr_col = [\n",
    "    'Employee ID',\n",
    "    'First Name',\n",
    "    'Last Name',\n",
    "    'Preferred Name',\n",
    "    'Company',\n",
    "    'Store',\n",
    "    'Date',\n",
    "    'Hours'\n",
    "    ]\n",
    "  rostered_hr = rostered_hr[rostered_hr_col]\n",
    "  rostered_hr['Date'] = pd.to_datetime(rostered_hr['Date'])\n",
    "\n",
    "  bonus = rostered_hr.copy()\n",
    "\n",
    "  # Stitch Store ID and drop rows which Store ID are not found\n",
    "  sheet_id = '1rqOeBjA9drmTnjlENvr57RqL5-oxSqe_KGdbdL2MKhM'\n",
    "  sheet_name = 'StoreReference'\n",
    "  url = f'https://docs.google.com/spreadsheets/d/{sheet_id}/gviz/tq?tqx=out:csv&sheet={sheet_name}'\n",
    "  store_ref = pd.read_csv(url)\n",
    "\n",
    "  bonus = pd.merge(bonus, store_ref, on=['Store'], how = 'left')\n",
    "\n",
    "  bonus.dropna(subset=['Store ID'], inplace = True)\n",
    "\n",
    "  # Stitch shop_id\n",
    "  sheet_id = '1ezyBlKquUhYnFwmIKTR4fghI59ZvGaKL35mKbcdeRy4'\n",
    "  sheet_name = 'Stores'\n",
    "  url = f'https://docs.google.com/spreadsheets/d/{sheet_id}/gviz/tq?tqx=out:csv&sheet={sheet_name}'\n",
    "  store_df_gs = pd.read_csv(url)\n",
    "\n",
    "  bonus = pd.merge(bonus, store_df_gs[['Store ID', 'shop_id']], on=['Store ID'], how = 'left')\n",
    "  bonus['shop_id'] = bonus['shop_id'].astype(int)\n",
    "\n",
    "\n",
    "  # Stich sales based on shop_id & dates, skip if there is no Date\n",
    "  start = bonus['Date'].min()\n",
    "  end = bonus['Date'].max()\n",
    "\n",
    "  start_str = start.strftime('%Y-%m-%d')\n",
    "  end_str = (end+timedelta(days=1)).strftime('%Y-%m-%d')\n",
    "  shop_id_list = bonus['shop_id'].unique().tolist()\n",
    "  shop_id_list_str = ', '.join(str(id) for id in shop_id_list)\n",
    "  stock_exclusions_list = [266,267,268,269,270,272,256,255,254]\n",
    "  stock_exclusions_list_str = ', '.join(str(s) for s in stock_exclusions_list)\n",
    "\n",
    "  query = '''\n",
    "  SELECT\n",
    "    d.shop_id, Date(d.docket_date) AS Date, SUM(dl.quantity * dl.sell_inc) as Sales\n",
    "  FROM\n",
    "    DocketLine dl\n",
    "  JOIN\n",
    "    Docket d on dl.docket_id  = d.docket_id \n",
    "  WHERE \n",
    "    d.docket_date >='{start}' and d.docket_date < '{end}' and d.shop_id in ({shop_id_list}) and d.`transaction`  = 'SA' and dl.stock_id not in ({stock_exclusions_list})\n",
    "  GROUP BY \n",
    "    d.shop_id, Date(d.docket_date)\n",
    "  '''.format(start=start_str, end = end_str, shop_id_list = shop_id_list_str, stock_exclusions_list = stock_exclusions_list_str)\n",
    "  sales_df = pd.read_sql(con=Gong_cha_MySQL_engine.connect(), sql=sql_text(query))\n",
    "  sales_df['Date'] = pd.to_datetime(sales_df['Date'])\n",
    "\n",
    "  bonus = pd.merge(bonus, sales_df[['shop_id', 'Date', 'Sales']], on=['shop_id', 'Date'], how = 'left')\n",
    "\n",
    "  # Stitch Target Sales & Bonus Rates\n",
    "  sheet_id = '1rqOeBjA9drmTnjlENvr57RqL5-oxSqe_KGdbdL2MKhM'\n",
    "  sheet_name = 'Targets'\n",
    "  url = f'https://docs.google.com/spreadsheets/d/{sheet_id}/gviz/tq?tqx=out:csv&sheet={sheet_name}'\n",
    "  targets = pd.read_csv(url)\n",
    "  targets['Date'] = pd.to_datetime(targets['Date'])\n",
    "\n",
    "  # Change Bonus Rates to 0, if Target Sales is not met\n",
    "  bonus = pd.merge(bonus, targets[['Store ID', 'Date', 'Target Sales', 'Bonus Rate']], on=['Store ID', 'Date'], how = 'left')\n",
    "  bonus['Bonus Rate'] = bonus['Bonus Rate'].where(bonus['Sales'] >= bonus['Target Sales'], 0)\n",
    "  bonus['Bonus'] = bonus['Bonus Rate']  * bonus['Hours']\n",
    "\n",
    "  # Work out additional_hr\n",
    "  additional_hr = additional_hr.dropna(subset=['Employee ID'])\n",
    "  additional_hr = pd.merge(additional_hr, employees[['Employee ID', 'First Name', 'Last Name', 'Company']], how='left', on=['Employee ID'])\n",
    "  additional_hr_col = [\n",
    "    'Employee ID',\n",
    "    'First Name',\n",
    "    'Last Name',\n",
    "    'Preferred Name',\n",
    "    'Company',\n",
    "    'Store',\n",
    "    'Date',\n",
    "    'Hours'\n",
    "  ]\n",
    "  additional_hr = additional_hr[additional_hr_col]\n",
    "  additional_hr['Date'] = pd.to_datetime(additional_hr['Date'])\n",
    "\n",
    "  # Concat rostered_hr and additional_hr\n",
    "  analysis = pd.concat([rostered_hr, additional_hr])\n",
    "\n",
    "  # Concat Bouns on to Timesheets\n",
    "  bonus_summary = bonus.groupby('Employee ID', as_index = False).agg({'Bonus':'sum'})\n",
    "  timesheets = pd.merge(timesheets, bonus_summary, on=['Employee ID'], how = 'left')\n",
    "  timesheets.fillna({'Bonus':0}, inplace = True)\n",
    "  timesheets.rename(columns={'Bonus':'Bonus $'}, inplace = True)\n",
    "\n",
    "  return timesheets, billings, over_threshold, analysis, bonus\n",
    "\n",
    "# # # END OF FUNCTIONS\n",
    "\n",
    "\n",
    "import io\n",
    "import streamlit as st\n",
    "\n",
    "st.title('Timesheet & Billing')\n",
    "\n",
    "uploaded_files = st.file_uploader(\"Choose Files\", accept_multiple_files = True)\n",
    "\n",
    "# Create an empty container\n",
    "output = st.empty()\n",
    "\n",
    "# if uploaded_files is not None:\n",
    "if len(uploaded_files) > 0:\n",
    "    ts, bl, ot, an, bo = calc_timesheets_n_billings(uploaded_files)\n",
    "\n",
    "    buffer = io.BytesIO()\n",
    "\n",
    "    with pd.ExcelWriter(buffer, engine='xlsxwriter') as writer:\n",
    "    # Write each dataframe to a different worksheet.\n",
    "        ts.to_excel(writer, sheet_name='Timesheet', index = False)\n",
    "        bl.to_excel(writer, sheet_name='Billing', index = False)\n",
    "        ot.to_excel(writer, sheet_name='Over Threshold', index = False)\n",
    "        an.to_excel(writer, sheet_name='Analysis',index = False)\n",
    "        bo.to_excel(writer, sheet_name='Bonus',index = False)\n",
    "\n",
    "    # Close the Pandas Excel writer and output the Excel file to the buffer\n",
    "    writer.close()\n",
    "\n",
    "    st.download_button(\n",
    "        label=\"Download\",\n",
    "        data=buffer,\n",
    "        file_name=\"Timesheet & Billing.xlsx\",\n",
    "        mime=\"application/vnd.ms-excel\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
