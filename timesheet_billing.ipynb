{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qw/dzbm6krn4k1gwl2301yj90f40000gn/T/ipykernel_27169/3170424087.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "import mysql.connector\n",
    "\n",
    "mysql_host = '34.116.84.145'\n",
    "mysql_port = '3306'\n",
    "mysql_user = 'gong-cha'\n",
    "mysql_password = 'HelloGongCha2012'\n",
    "mysql_database = 'gong_cha_redcat_db'\n",
    "\n",
    "# Engine for MySQL\n",
    "mysql_connection_string = f\"mysql+mysqlconnector://{mysql_user}:{mysql_password}@{mysql_host}:{mysql_port}/{mysql_database}\"\n",
    "mysql_engine = create_engine(mysql_connection_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'streamlit'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 234\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[39m# # # END OF FUNCTIONS\u001b[39;00m\n\u001b[1;32m    233\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mio\u001b[39;00m\n\u001b[0;32m--> 234\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mstreamlit\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mst\u001b[39;00m\n\u001b[1;32m    236\u001b[0m st\u001b[39m.\u001b[39mtitle(\u001b[39m'\u001b[39m\u001b[39mTimesheet & Billing\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    238\u001b[0m uploaded_files \u001b[39m=\u001b[39m st\u001b[39m.\u001b[39mfile_uploader(\u001b[39m\"\u001b[39m\u001b[39mChoose Files\u001b[39m\u001b[39m\"\u001b[39m, accept_multiple_files \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'streamlit'"
     ]
    }
   ],
   "source": [
    "# # # START OF FUNCTIONS\n",
    "\n",
    "def extract_additional_hr(file, sheet_name):\n",
    "  df = pd.read_excel(file, sheet_name = sheet_name)\n",
    "  df = df.dropna(subset=['Employee ID'])\n",
    "\n",
    "  if df['Employee ID'].dtypes == 'object':\n",
    "    df['Employee ID'] = df['Employee ID'].str[:6]\n",
    "  df['Employee ID'] = df['Employee ID'].astype(int)\n",
    "\n",
    "  if df['Store'].dtypes == float:\n",
    "    df['Store'] = df['Store'].astype(int).astype(str)\n",
    "\n",
    "  df = df.fillna({'Add': 0, 'Add.1': 0,'Add.2': 0,'Add.3': 0,'Add.4': 0,'Add.5': 0,'Personal Leave': 0,'Annual Leave': 0,})\n",
    "  df['2012-11-01'] = df['Add'] + df['Add.1'] + df['Add.2'] + df['Add.3'] + df['Add.4'] + df['Add.5']\n",
    "  df['2013-01-01'] = df['Personal Leave'] + df['Annual Leave']\n",
    "  cols =[0,1,2, df.columns.tolist().index('2012-11-01'),df.columns.tolist().index('2013-01-01')]\n",
    "\n",
    "  df = df.iloc[:, cols]\n",
    "  df = df.dropna(subset=df.columns[:3], how='all')\n",
    "  df = df.melt(id_vars=['Employee ID', 'Store', 'Preferred Name'], value_vars=df.columns[3:], var_name='Date', value_name='Hours')\n",
    "  df = df[df['Hours'] != 0]\n",
    "  return df\n",
    "\n",
    "def extract_rostered_hr(file, sheet_name):\n",
    "  df = pd.read_excel(file, sheet_name = sheet_name)\n",
    "\n",
    "  df = df.dropna(subset=['Employee ID'])\n",
    "\n",
    "  if df['Employee ID'].dtypes == 'object':\n",
    "    df['Employee ID'] = df['Employee ID'].str[:6]\n",
    "  df['Employee ID'] = df['Employee ID'].astype(int)\n",
    "\n",
    "  if df['Store'].dtypes == float:\n",
    "    df['Store'] = df['Store'].astype(int).astype(str)\n",
    "\n",
    "  df = df.iloc[:, :24]\n",
    "  cols = [0,1,2]\n",
    "  for col in range(3, 24, 3):\n",
    "      df[df.columns[col]] = df[df.columns[col+2]]\n",
    "      cols.append(col)\n",
    "  df = df.iloc[:,cols]\n",
    "  df = df.dropna(subset=df.columns[:3], how='all')\n",
    "  df = df.melt(id_vars=['Employee ID', 'Store', 'Preferred Name'], value_vars=df.columns[3:], var_name='Date', value_name='Hours')\n",
    "  df = df[df['Hours'] != 0]\n",
    "  return df\n",
    "\n",
    "def calc_timesheets_n_billings(files):\n",
    "  print('calc')\n",
    "  timesheets = pd.DataFrame()\n",
    "  billings = pd.DataFrame()\n",
    "  rostered_hr = pd.DataFrame()\n",
    "  additional_hr = pd.DataFrame()\n",
    "\n",
    "  for file in files:\n",
    "    timesheet = pd.read_excel(file, sheet_name = 'Timesheet')\n",
    "    billing = pd.read_excel(file, sheet_name = 'Billing')\n",
    "    rostered_hr_w1 = extract_rostered_hr(file, 'Week 1 Roster')\n",
    "    rostered_hr_w2 = extract_rostered_hr(file, 'Week 2 Roster')\n",
    "    additional_hr_w1 = extract_additional_hr(file, 'Week 1 Roster')\n",
    "    additional_hr_w2 = extract_additional_hr(file, 'Week 2 Roster')\n",
    "    employees = pd.read_excel(file, sheet_name = 'Employees')\n",
    "\n",
    "    timesheets = pd.concat([timesheets, timesheet], ignore_index=True)\n",
    "    billings = pd.concat([billings, billing], ignore_index=True)\n",
    "    rostered_hr = pd.concat([rostered_hr, rostered_hr_w1], ignore_index=True)\n",
    "    rostered_hr = pd.concat([rostered_hr, rostered_hr_w2], ignore_index=True)\n",
    "    additional_hr = pd.concat([additional_hr, additional_hr_w1], ignore_index=True)\n",
    "    additional_hr = pd.concat([additional_hr, additional_hr_w2], ignore_index=True)\n",
    "\n",
    "  #Remov  e irrelevant rows\n",
    "  timesheets.dropna(subset = ['Employee ID'], inplace=True)\n",
    "  #Keep the needed columns\n",
    "  timesheets_cols = [1,2,3,7,8,9,10,11,12,13,14,15,16,17,18,19,20]\n",
    "  timesheets = timesheets[timesheets.columns[timesheets_cols]]\n",
    "  timesheets['Update Wage'] = timesheets['Update Wage'].astype(bool)\n",
    "  #Column Aggregations\n",
    "  timesheets_agg_cols = {'First Name':'first','Last Name':'first','Update Wage':'first','Hour Threshold':'first','Company':'first','Ord':'sum','Sat':'sum','Sun':'sum','Pub':'sum','Eve 1':'sum','Eve 2':'sum','No. of Shifts':'sum','Personal Leave':'sum','Annual Leave':'sum','Unpaid Leave':'sum','Total':'sum'}\n",
    "  timesheets = timesheets.groupby('Employee ID', as_index = False).agg(timesheets_agg_cols)\n",
    "  #Calculate Over Threshold\n",
    "  timesheets['Over Threshold'] = timesheets['Total'] - timesheets['Hour Threshold']\n",
    "  timesheets.loc[timesheets[\"Over Threshold\"] <=0, \"Over Threshold\"] = 0\n",
    "  #Keep Over Thresholds to a new df\n",
    "  over_threshold = timesheets[timesheets['Over Threshold']>0]\n",
    "  #Reduce Ord & Total with the excess\n",
    "  timesheets['Ord'] = timesheets['Ord'] - timesheets['Over Threshold']\n",
    "  timesheets['Total'] = timesheets['Total'] - timesheets['Over Threshold']\n",
    "  #Convert 80 & 100 hours to 76 hours\n",
    "  hours_col = ['Ord', 'Sat','Sun','Eve 1','Eve 2','Pub','Personal Leave', 'Annual Leave', 'Unpaid Leave', 'Total']\n",
    "  if(100 in timesheets[\"Hour Threshold\"].values):\n",
    "      timesheets.loc[timesheets[\"Hour Threshold\"] == 100, hours_col] = timesheets[hours_col]/100*76\n",
    "  if(80 in timesheets[\"Hour Threshold\"].values):\n",
    "      timesheets.loc[timesheets[\"Hour Threshold\"] == 80, hours_col] = timesheets[hours_col]/80*76\n",
    "  if any(timesheets[\"Hour Threshold\"] > 1000):\n",
    "  # Find rows where \"Hour Threshold\" is greater than 1000\n",
    "      rows_to_update = timesheets.loc[timesheets[\"Hour Threshold\"] > 1000]\n",
    "      # Perform actions on the rows\n",
    "      for index, row in rows_to_update.iterrows():\n",
    "          threshold = int(row[\"Hour Threshold\"])\n",
    "          base = int(str(threshold)[:2])\n",
    "          conversion = int(str(threshold)[-2:])\n",
    "          # Update multiple columns using .loc\n",
    "          timesheets.loc[index, hours_col] = timesheets.loc[index, hours_col] / conversion * base\n",
    "\n",
    "  #drop Hour Threshold & Over Threshold\n",
    "  timesheets = timesheets.drop(['Hour Threshold','Over Threshold'],axis = 1)\n",
    "\n",
    "  #Remove irrelevant rows\n",
    "  billings.dropna(subset=['Store'],inplace = True)\n",
    "  billings = billings[billings['Total'] > 0]\n",
    "\n",
    "  #Keep the needed columns\n",
    "  billings_cols = [0,1,2,3,4,5,6,7,8,9,10,11]\n",
    "  billings = billings[billings.columns[billings_cols]]\n",
    "  #Column Aggregations\n",
    "  billings_agg_cols = {'Ord':'sum','Sat':'sum','Sun':'sum','Pub':'sum','Eve 1':'sum','Eve 2':'sum','No. of Shifts':'sum','Personal Leave':'sum','Annual Leave':'sum','Unpaid Leave':'sum','Total':'sum'}\n",
    "  billings = billings.groupby('Store', as_index = False).agg(billings_agg_cols)\n",
    "\n",
    "  rostered_hr = pd.merge(rostered_hr, employees[['Employee ID', 'First Name', 'Last Name', 'Company']], how='left', on=['Employee ID'])\n",
    "  rostered_hr_col = [\n",
    "  'Employee ID',\n",
    "  'First Name',\n",
    "  'Last Name',\n",
    "  'Preferred Name',\n",
    "  'Company',\n",
    "  'Store',\n",
    "  'Date',\n",
    "  'Hours'\n",
    "  ]\n",
    "  rostered_hr = rostered_hr[rostered_hr_col]\n",
    "  rostered_hr['Date'] = pd.to_datetime(rostered_hr['Date'])\n",
    "\n",
    "  bonus = rostered_hr.copy()\n",
    "\n",
    "  # Stitch Store ID and drop rows which Store ID are not found\n",
    "  sheet_id = '1rqOeBjA9drmTnjlENvr57RqL5-oxSqe_KGdbdL2MKhM'\n",
    "  sheet_name = 'StoreReference'\n",
    "  url = f'https://docs.google.com/spreadsheets/d/{sheet_id}/gviz/tq?tqx=out:csv&sheet={sheet_name}'\n",
    "  store_ref = pd.read_csv(url)\n",
    "\n",
    "  bonus = pd.merge(bonus, store_ref, on=['Store'], how = 'left')\n",
    "\n",
    "  bonus.dropna(subset=['Store ID'], inplace = True)\n",
    "\n",
    "  # Stitch recid_plo\n",
    "  sheet_id = '1ezyBlKquUhYnFwmIKTR4fghI59ZvGaKL35mKbcdeRy4'\n",
    "  sheet_name = 'Stores'\n",
    "  url = f'https://docs.google.com/spreadsheets/d/{sheet_id}/gviz/tq?tqx=out:csv&sheet={sheet_name}'\n",
    "  store_df_gs = pd.read_csv(url)\n",
    "\n",
    "  bonus = pd.merge(bonus, store_df_gs[['Store ID', 'recid_plo']], on=['Store ID'], how = 'left')\n",
    "  bonus['recid_plo'] = bonus['recid_plo'].astype(int)\n",
    "\n",
    "  # Stich sales based on recid_plo & dates, skip if there is no Date\n",
    "  start = bonus['Date'].min()\n",
    "  end = bonus['Date'].max()\n",
    "\n",
    "  start_str = start.strftime('%Y-%m-%d')\n",
    "  end_str = end.strftime('%Y-%m-%d')\n",
    "\n",
    "  recid_plo_list = bonus['recid_plo'].unique().tolist()\n",
    "  recid_plo_list_str = ', '.join(str(id) for id in recid_plo_list)\n",
    "\n",
    "  sheet_id = '1peA8effpeSTk3duIjxF46V-PrDD8tv3fubTCDEpD940'\n",
    "  sheet_name = 'ops_bonus_exclusion'\n",
    "  url = f'https://docs.google.com/spreadsheets/d/{sheet_id}/gviz/tq?tqx=out:csv&sheet={sheet_name}'\n",
    "  exclusion_df = pd.read_csv(url)\n",
    "  excluded_recid_plu = exclusion_df['recid_plu'].drop_duplicates()\n",
    "\n",
    "  excluded_recid_plu_str = ', '.join(str(s) for s in excluded_recid_plu)\n",
    "  excluded_recid_plu_str\n",
    "\n",
    "  query = '''\n",
    "  SELECT ts2.recid_plo, ts.itemdate as Date, sum(ts.qty*ts.price) as Sales\n",
    "  FROM tbl_salesitems ts \n",
    "  JOIN tbl_salesheaders ts2 on ts.recid_mixh = ts2.recid\n",
    "  WHERE ts.itemdate >= '{start}' and ts.itemdate <= '{end}' and ts2.recid_plo in ({recid_plo_list}) and ts.recid_plu not in ({excluded_recid_plu})\n",
    "  GROUP BY ts2.recid_plo, ts.itemdate\n",
    "  ORDER BY ts.itemdate ASC, recid_plo ASC\n",
    "  '''.format(start=start_str, end = end_str, recid_plo_list = recid_plo_list_str, excluded_recid_plu = excluded_recid_plu_str)\n",
    "\n",
    "  sales_df = pd.read_sql(query, mysql_engine)\n",
    "  sales_df['Date'] = pd.to_datetime(sales_df['Date'])\n",
    "\n",
    "  bonus = pd.merge(bonus, sales_df[['recid_plo', 'Date', 'Sales']], on=['recid_plo', 'Date'], how = 'left')\n",
    "\n",
    "  # Stitch Target Sales & Bonus Rates\n",
    "  sheet_id = '1rqOeBjA9drmTnjlENvr57RqL5-oxSqe_KGdbdL2MKhM'\n",
    "  sheet_name = 'Targets'\n",
    "  url = f'https://docs.google.com/spreadsheets/d/{sheet_id}/gviz/tq?tqx=out:csv&sheet={sheet_name}'\n",
    "  targets = pd.read_csv(url)\n",
    "  targets['Date'] = pd.to_datetime(targets['Date'])\n",
    "\n",
    "  # Change Bonus Rates to 0, if Target Sales is not met\n",
    "  bonus = pd.merge(bonus, targets[['Store ID', 'Date', 'Target Sales', 'Bonus Rate']], on=['Store ID', 'Date'], how = 'left')\n",
    "  bonus['Bonus Rate'] = bonus['Bonus Rate'].where(bonus['Sales'] >= bonus['Target Sales'], 0)\n",
    "  bonus['Bonus'] = bonus['Bonus Rate']  * bonus['Hours']\n",
    "\n",
    "  # Work out additional_hr\n",
    "  additional_hr = additional_hr.dropna(subset=['Employee ID'])\n",
    "  additional_hr = pd.merge(additional_hr, employees[['Employee ID', 'First Name', 'Last Name', 'Company']], how='left', on=['Employee ID'])\n",
    "  additional_hr_col = [\n",
    "  'Employee ID',\n",
    "  'First Name',\n",
    "  'Last Name',\n",
    "  'Preferred Name',\n",
    "  'Company',\n",
    "  'Store',\n",
    "  'Date',\n",
    "  'Hours'\n",
    "  ]\n",
    "  additional_hr = additional_hr[additional_hr_col]\n",
    "  additional_hr['Date'] = pd.to_datetime(additional_hr['Date'])\n",
    "\n",
    "  # Concat rostered_hr and additional_hr\n",
    "  analysis = pd.concat([rostered_hr, additional_hr])\n",
    "\n",
    "  # Concat Bouns on to Timesheets\n",
    "  bonus_summary = bonus.groupby('Employee ID', as_index = False).agg({'Bonus':'sum'})\n",
    "  timesheets = pd.merge(timesheets, bonus_summary, on=['Employee ID'], how = 'left')\n",
    "  timesheets.fillna({'Bonus':0}, inplace = True)\n",
    "  timesheets.rename(columns={'Bonus':'Bonus $'}, inplace = True)\n",
    "\n",
    "  return timesheets, billings, over_threshold, analysis, bonus\n",
    "\n",
    "\n",
    "# # # END OF FUNCTIONS\n",
    "\n",
    "\n",
    "import io\n",
    "import streamlit as st\n",
    "\n",
    "st.title('Timesheet & Billing')\n",
    "\n",
    "uploaded_files = st.file_uploader(\"Choose Files\", accept_multiple_files = True)\n",
    "\n",
    "# Create an empty container\n",
    "output = st.empty()\n",
    "\n",
    "# if uploaded_files is not None:\n",
    "if len(uploaded_files) > 0:\n",
    "    ts, bl, ot, an, bo = calc_timesheets_n_billings(uploaded_files)\n",
    "\n",
    "    buffer = io.BytesIO()\n",
    "\n",
    "    with pd.ExcelWriter(buffer, engine='xlsxwriter') as writer:\n",
    "    # Write each dataframe to a different worksheet.\n",
    "        ts.to_excel(writer, sheet_name='Timesheet', index = False)\n",
    "        bl.to_excel(writer, sheet_name='Billing', index = False)\n",
    "        ot.to_excel(writer, sheet_name='Over Threshold', index = False)\n",
    "        an.to_excel(writer, sheet_name='Analysis',index = False)\n",
    "        bo.to_excel(writer, sheet_name='Bonus',index = False)\n",
    "\n",
    "    # Close the Pandas Excel writer and output the Excel file to the buffer\n",
    "    writer.close()\n",
    "\n",
    "    st.download_button(\n",
    "        label=\"Download\",\n",
    "        data=buffer,\n",
    "        file_name=\"Timesheet & Billing.xlsx\",\n",
    "        mime=\"application/vnd.ms-excel\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'-2, 21, 568, 861, 570, 1024, 569, 1023, 845, 846, 847, 848, 1059, 1060, 1061, 1062, 485, 559, 572, 573, 574, 575, 892, 1036, 1085, 1086, 1133, 1135, 1136'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tumbler_recid_plu_list = [1059,1060,1061,1062]\n",
    "gingerbread_recid_plu_list = [485,559,572,573,574,575,1036,1085,1086]\n",
    "stock_exclusions_list = tumbler_recid_plu_list + gingerbread_recid_plu_list\n",
    "stock_exclusions_list_str = ', '.join(str(s) for s in stock_exclusions_list)\n",
    "\n",
    "\n",
    "\n",
    "sheet_id = '1peA8effpeSTk3duIjxF46V-PrDD8tv3fubTCDEpD940'\n",
    "sheet_name = 'ops_bonus_exclusion'\n",
    "url = f'https://docs.google.com/spreadsheets/d/{sheet_id}/gviz/tq?tqx=out:csv&sheet={sheet_name}'\n",
    "exclusion_df = pd.read_csv(url)\n",
    "excluded_recid_plu = exclusion_df['recid_plu'].drop_duplicates()\n",
    "\n",
    "excluded_recid_plu_str = ', '.join(str(s) for s in excluded_recid_plu)\n",
    "excluded_recid_plu_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1059, 1060, 1061, 1062, 485, 559, 572, 573, 574, 575, 1036, 1085, 1086'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_exclusions_list_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/eddy/Developer/Streamlit/gongchaaus/roster-consolidation/files/501 Final Roster 0502-1802.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "/opt/homebrew/lib/python3.11/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "/opt/homebrew/lib/python3.11/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "/opt/homebrew/lib/python3.11/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import openpyxl\n",
    "\n",
    "# Get absolute path of the current notebook's directory\n",
    "notebook_dir = os.getcwd()  # Get current working directory\n",
    "\n",
    "# Construct the path to the `/files/` folder\n",
    "files_dir = os.path.join(notebook_dir, \"files\")\n",
    "\n",
    "# List files in the directory\n",
    "files_names_dir = os.listdir(files_dir)\n",
    "\n",
    "timesheets = pd.DataFrame()\n",
    "billings = pd.DataFrame()\n",
    "rostered_hr = pd.DataFrame()\n",
    "additional_hr = pd.DataFrame()\n",
    "\n",
    "for filename in files_names_dir:\n",
    "    if filename.endswith(\".xlsx\"):\n",
    "        file = os.path.join(files_dir, filename)\n",
    "        print(file)\n",
    "        timesheet = pd.read_excel(file, sheet_name = 'Timesheet', engine='openpyxl')\n",
    "        billing = pd.read_excel(file, sheet_name = 'Billing', engine='openpyxl')\n",
    "        rostered_hr_w1 = extract_rostered_hr(file, 'Week 1 Roster')\n",
    "        rostered_hr_w2 = extract_rostered_hr(file, 'Week 2 Roster')\n",
    "        additional_hr_w1 = extract_additional_hr(file, 'Week 1 Roster')\n",
    "        additional_hr_w2 = extract_additional_hr(file, 'Week 2 Roster')\n",
    "        employees = pd.read_excel(file, sheet_name = 'Employees')\n",
    "\n",
    "        timesheets = pd.concat([timesheets, timesheet], ignore_index=True)\n",
    "        billings = pd.concat([billings, billing], ignore_index=True)\n",
    "        rostered_hr = pd.concat([rostered_hr, rostered_hr_w1], ignore_index=True)\n",
    "        rostered_hr = pd.concat([rostered_hr, rostered_hr_w2], ignore_index=True)\n",
    "        additional_hr = pd.concat([additional_hr, additional_hr_w1], ignore_index=True)\n",
    "        additional_hr = pd.concat([additional_hr, additional_hr_w2], ignore_index=True)\n",
    "\n",
    "#Remov  e irrelevant rows\n",
    "timesheets.dropna(subset = ['Employee ID'], inplace=True)\n",
    "#Keep the needed columns\n",
    "timesheets_cols = [1,2,3,7,8,9,10,11,12,13,14,15,16,17,18,19,20]\n",
    "timesheets = timesheets[timesheets.columns[timesheets_cols]]\n",
    "timesheets['Update Wage'] = timesheets['Update Wage'].astype(bool)\n",
    "#Column Aggregations\n",
    "timesheets_agg_cols = {'First Name':'first','Last Name':'first','Update Wage':'first','Hour Threshold':'first','Company':'first','Ord':'sum','Sat':'sum','Sun':'sum','Pub':'sum','Eve 1':'sum','Eve 2':'sum','No. of Shifts':'sum','Personal Leave':'sum','Annual Leave':'sum','Unpaid Leave':'sum','Total':'sum'}\n",
    "timesheets = timesheets.groupby('Employee ID', as_index = False).agg(timesheets_agg_cols)\n",
    "#Calculate Over Threshold\n",
    "timesheets['Over Threshold'] = timesheets['Total'] - timesheets['Hour Threshold']\n",
    "timesheets.loc[timesheets[\"Over Threshold\"] <=0, \"Over Threshold\"] = 0\n",
    "#Keep Over Thresholds to a new df\n",
    "over_threshold = timesheets[timesheets['Over Threshold']>0]\n",
    "#Reduce Ord & Total with the excess\n",
    "timesheets['Ord'] = timesheets['Ord'] - timesheets['Over Threshold']\n",
    "timesheets['Total'] = timesheets['Total'] - timesheets['Over Threshold']\n",
    "#Convert 80 & 100 hours to 76 hours\n",
    "hours_col = ['Ord', 'Sat','Sun','Eve 1','Eve 2','Pub','Personal Leave', 'Annual Leave', 'Unpaid Leave', 'Total']\n",
    "if(100 in timesheets[\"Hour Threshold\"].values):\n",
    "    timesheets.loc[timesheets[\"Hour Threshold\"] == 100, hours_col] = timesheets[hours_col]/100*76\n",
    "if(80 in timesheets[\"Hour Threshold\"].values):\n",
    "    timesheets.loc[timesheets[\"Hour Threshold\"] == 80, hours_col] = timesheets[hours_col]/80*76\n",
    "if any(timesheets[\"Hour Threshold\"] > 1000):\n",
    "# Find rows where \"Hour Threshold\" is greater than 1000\n",
    "    rows_to_update = timesheets.loc[timesheets[\"Hour Threshold\"] > 1000]\n",
    "    # Perform actions on the rows\n",
    "    for index, row in rows_to_update.iterrows():\n",
    "        threshold = int(row[\"Hour Threshold\"])\n",
    "        base = int(str(threshold)[:2])\n",
    "        conversion = int(str(threshold)[-2:])\n",
    "        # Update multiple columns using .loc\n",
    "        timesheets.loc[index, hours_col] = timesheets.loc[index, hours_col] / conversion * base\n",
    "\n",
    "#drop Hour Threshold & Over Threshold\n",
    "timesheets = timesheets.drop(['Hour Threshold','Over Threshold'],axis = 1)\n",
    "\n",
    "#Remove irrelevant rows\n",
    "billings.dropna(subset=['Store'],inplace = True)\n",
    "billings = billings[billings['Total'] > 0]\n",
    "\n",
    "#Keep the needed columns\n",
    "billings_cols = [0,1,2,3,4,5,6,7,8,9,10,11]\n",
    "billings = billings[billings.columns[billings_cols]]\n",
    "#Column Aggregations\n",
    "billings_agg_cols = {'Ord':'sum','Sat':'sum','Sun':'sum','Pub':'sum','Eve 1':'sum','Eve 2':'sum','No. of Shifts':'sum','Personal Leave':'sum','Annual Leave':'sum','Unpaid Leave':'sum','Total':'sum'}\n",
    "billings = billings.groupby('Store', as_index = False).agg(billings_agg_cols)\n",
    "\n",
    "rostered_hr = pd.merge(rostered_hr, employees[['Employee ID', 'First Name', 'Last Name', 'Company']], how='left', on=['Employee ID'])\n",
    "rostered_hr_col = [\n",
    "'Employee ID',\n",
    "'First Name',\n",
    "'Last Name',\n",
    "'Preferred Name',\n",
    "'Company',\n",
    "'Store',\n",
    "'Date',\n",
    "'Hours'\n",
    "]\n",
    "rostered_hr = rostered_hr[rostered_hr_col]\n",
    "rostered_hr['Date'] = pd.to_datetime(rostered_hr['Date'])\n",
    "\n",
    "bonus = rostered_hr.copy()\n",
    "\n",
    "# Stitch Store ID and drop rows which Store ID are not found\n",
    "sheet_id = '1rqOeBjA9drmTnjlENvr57RqL5-oxSqe_KGdbdL2MKhM'\n",
    "sheet_name = 'StoreReference'\n",
    "url = f'https://docs.google.com/spreadsheets/d/{sheet_id}/gviz/tq?tqx=out:csv&sheet={sheet_name}'\n",
    "store_ref = pd.read_csv(url)\n",
    "\n",
    "bonus = pd.merge(bonus, store_ref, on=['Store'], how = 'left')\n",
    "\n",
    "bonus.dropna(subset=['Store ID'], inplace = True)\n",
    "\n",
    "# Stitch recid_plo\n",
    "sheet_id = '1ezyBlKquUhYnFwmIKTR4fghI59ZvGaKL35mKbcdeRy4'\n",
    "sheet_name = 'Stores'\n",
    "url = f'https://docs.google.com/spreadsheets/d/{sheet_id}/gviz/tq?tqx=out:csv&sheet={sheet_name}'\n",
    "store_df_gs = pd.read_csv(url)\n",
    "\n",
    "bonus = pd.merge(bonus, store_df_gs[['Store ID', 'recid_plo']], on=['Store ID'], how = 'left')\n",
    "bonus['recid_plo'] = bonus['recid_plo'].astype(int)\n",
    "\n",
    "# Stich sales based on recid_plo & dates, skip if there is no Date\n",
    "start = bonus['Date'].min()\n",
    "end = bonus['Date'].max()\n",
    "\n",
    "start_str = start.strftime('%Y-%m-%d')\n",
    "end_str = end.strftime('%Y-%m-%d')\n",
    "\n",
    "recid_plo_list = bonus['recid_plo'].unique().tolist()\n",
    "recid_plo_list_str = ', '.join(str(id) for id in recid_plo_list)\n",
    "\n",
    "tumbler_recid_plu_list = [1059,1060,1061,1062]\n",
    "gingerbread_recid_plu_list = [485,559,572,573,574,575,1036,1085,1086]\n",
    "stock_exclusions_list = tumbler_recid_plu_list + gingerbread_recid_plu_list\n",
    "stock_exclusions_list_str = ', '.join(str(s) for s in stock_exclusions_list)\n",
    "\n",
    "query = '''\n",
    "SELECT ts2.recid_plo, ts.itemdate as Date, sum(ts.qty*ts.price) as Sales\n",
    "FROM tbl_salesitems ts \n",
    "JOIN tbl_salesheaders ts2 on ts.recid_mixh = ts2.recid\n",
    "WHERE ts.itemdate >= '{start}' and ts.itemdate <= '{end}' and ts2.recid_plo in ({recid_plo_list}) and ts.recid_plu not in ({stock_exclusions_list})\n",
    "GROUP BY ts2.recid_plo, ts.itemdate\n",
    "ORDER BY ts.itemdate ASC, recid_plo ASC\n",
    "'''.format(start=start_str, end = end_str, recid_plo_list = recid_plo_list_str, stock_exclusions_list = stock_exclusions_list_str)\n",
    "\n",
    "sales_df = pd.read_sql(query, mysql_engine)\n",
    "sales_df['Date'] = pd.to_datetime(sales_df['Date'])\n",
    "\n",
    "bonus = pd.merge(bonus, sales_df[['recid_plo', 'Date', 'Sales']], on=['recid_plo', 'Date'], how = 'left')\n",
    "\n",
    "# Stitch Target Sales & Bonus Rates\n",
    "sheet_id = '1rqOeBjA9drmTnjlENvr57RqL5-oxSqe_KGdbdL2MKhM'\n",
    "sheet_name = 'Targets'\n",
    "url = f'https://docs.google.com/spreadsheets/d/{sheet_id}/gviz/tq?tqx=out:csv&sheet={sheet_name}'\n",
    "targets = pd.read_csv(url)\n",
    "targets['Date'] = pd.to_datetime(targets['Date'])\n",
    "\n",
    "# Change Bonus Rates to 0, if Target Sales is not met\n",
    "bonus = pd.merge(bonus, targets[['Store ID', 'Date', 'Target Sales', 'Bonus Rate']], on=['Store ID', 'Date'], how = 'left')\n",
    "bonus['Bonus Rate'] = bonus['Bonus Rate'].where(bonus['Sales'] >= bonus['Target Sales'], 0)\n",
    "bonus['Bonus'] = bonus['Bonus Rate']  * bonus['Hours']\n",
    "\n",
    "# Work out additional_hr\n",
    "additional_hr = additional_hr.dropna(subset=['Employee ID'])\n",
    "additional_hr = pd.merge(additional_hr, employees[['Employee ID', 'First Name', 'Last Name', 'Company']], how='left', on=['Employee ID'])\n",
    "additional_hr_col = [\n",
    "'Employee ID',\n",
    "'First Name',\n",
    "'Last Name',\n",
    "'Preferred Name',\n",
    "'Company',\n",
    "'Store',\n",
    "'Date',\n",
    "'Hours'\n",
    "]\n",
    "additional_hr = additional_hr[additional_hr_col]\n",
    "additional_hr['Date'] = pd.to_datetime(additional_hr['Date'])\n",
    "\n",
    "# Concat rostered_hr and additional_hr\n",
    "analysis = pd.concat([rostered_hr, additional_hr])\n",
    "\n",
    "# Concat Bouns on to Timesheets\n",
    "bonus_summary = bonus.groupby('Employee ID', as_index = False).agg({'Bonus':'sum'})\n",
    "timesheets = pd.merge(timesheets, bonus_summary, on=['Employee ID'], how = 'left')\n",
    "timesheets.fillna({'Bonus':0}, inplace = True)\n",
    "timesheets.rename(columns={'Bonus':'Bonus $'}, inplace = True)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Employee ID</th>\n",
       "      <th>First Name</th>\n",
       "      <th>Last Name</th>\n",
       "      <th>Update Wage</th>\n",
       "      <th>Company</th>\n",
       "      <th>Ord</th>\n",
       "      <th>Sat</th>\n",
       "      <th>Sun</th>\n",
       "      <th>Pub</th>\n",
       "      <th>Eve 1</th>\n",
       "      <th>Eve 2</th>\n",
       "      <th>No. of Shifts</th>\n",
       "      <th>Personal Leave</th>\n",
       "      <th>Annual Leave</th>\n",
       "      <th>Unpaid Leave</th>\n",
       "      <th>Total</th>\n",
       "      <th>Bonus $</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10008.0</td>\n",
       "      <td>Elsie</td>\n",
       "      <td>Chan</td>\n",
       "      <td>False</td>\n",
       "      <td>GCM</td>\n",
       "      <td>15.250000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0</td>\n",
       "      <td>8.00</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>42.366667</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10010.0</td>\n",
       "      <td>Erica Fong-de</td>\n",
       "      <td>Jong</td>\n",
       "      <td>False</td>\n",
       "      <td>GCM</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>19.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10013.0</td>\n",
       "      <td>Hanbo</td>\n",
       "      <td>Zhang</td>\n",
       "      <td>False</td>\n",
       "      <td>GCM</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1.50</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10032.0</td>\n",
       "      <td>Reynardo</td>\n",
       "      <td>Tjhin</td>\n",
       "      <td>False</td>\n",
       "      <td>GCM</td>\n",
       "      <td>28.500000</td>\n",
       "      <td>17.083333</td>\n",
       "      <td>0.183333</td>\n",
       "      <td>0</td>\n",
       "      <td>7.00</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>52.850000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10054.0</td>\n",
       "      <td>Yiran</td>\n",
       "      <td>Zhang</td>\n",
       "      <td>False</td>\n",
       "      <td>SS</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10058.0</td>\n",
       "      <td>Han-Chun</td>\n",
       "      <td>Lin</td>\n",
       "      <td>False</td>\n",
       "      <td>GCM</td>\n",
       "      <td>34.130000</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>31.37</td>\n",
       "      <td>0</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10061.0</td>\n",
       "      <td>Adrian</td>\n",
       "      <td>Lim</td>\n",
       "      <td>False</td>\n",
       "      <td>HL</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1.50</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>18.500000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10081.0</td>\n",
       "      <td>Emmanuel</td>\n",
       "      <td>Quebec</td>\n",
       "      <td>False</td>\n",
       "      <td>HL</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10114.0</td>\n",
       "      <td>Mari</td>\n",
       "      <td>Cuasay</td>\n",
       "      <td>False</td>\n",
       "      <td>HL</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10120.0</td>\n",
       "      <td>Namrata</td>\n",
       "      <td>Gurung</td>\n",
       "      <td>False</td>\n",
       "      <td>HL</td>\n",
       "      <td>70.110000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>4.56</td>\n",
       "      <td>0.215333</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>74.885333</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10160.0</td>\n",
       "      <td>Pulin</td>\n",
       "      <td>Pan</td>\n",
       "      <td>False</td>\n",
       "      <td>GCM</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>76.00</td>\n",
       "      <td>0</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10161.0</td>\n",
       "      <td>Zihan</td>\n",
       "      <td>Wang</td>\n",
       "      <td>False</td>\n",
       "      <td>GCM</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10185.0</td>\n",
       "      <td>Lihour</td>\n",
       "      <td>Chhit</td>\n",
       "      <td>False</td>\n",
       "      <td>HL</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>10249.0</td>\n",
       "      <td>Yonglin</td>\n",
       "      <td>Zhu</td>\n",
       "      <td>False</td>\n",
       "      <td>GCM</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>2.50</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>10270.0</td>\n",
       "      <td>Zalfa</td>\n",
       "      <td>Buana</td>\n",
       "      <td>False</td>\n",
       "      <td>GCM</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>10276.0</td>\n",
       "      <td>Cana</td>\n",
       "      <td>Fukuda</td>\n",
       "      <td>False</td>\n",
       "      <td>GCM</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>10285.0</td>\n",
       "      <td>Manisha</td>\n",
       "      <td>Thapa Magar</td>\n",
       "      <td>False</td>\n",
       "      <td>HL</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>21.083333</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>10289.0</td>\n",
       "      <td>Jethro</td>\n",
       "      <td>Soewandito</td>\n",
       "      <td>False</td>\n",
       "      <td>GCM</td>\n",
       "      <td>46.500000</td>\n",
       "      <td>14.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>3.50</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>64.583333</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>10310.0</td>\n",
       "      <td>Marlene</td>\n",
       "      <td>Schütte</td>\n",
       "      <td>False</td>\n",
       "      <td>GCM</td>\n",
       "      <td>44.116667</td>\n",
       "      <td>15.833333</td>\n",
       "      <td>10.633333</td>\n",
       "      <td>0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>10335.0</td>\n",
       "      <td>Chansethea</td>\n",
       "      <td>Sunly</td>\n",
       "      <td>False</td>\n",
       "      <td>SS</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>10337.0</td>\n",
       "      <td>Ngoc My</td>\n",
       "      <td>Nguyen</td>\n",
       "      <td>True</td>\n",
       "      <td>SS</td>\n",
       "      <td>13.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>23.500000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>10341.0</td>\n",
       "      <td>Truc Thanh</td>\n",
       "      <td>Nguyen</td>\n",
       "      <td>False</td>\n",
       "      <td>SS</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>48.00</td>\n",
       "      <td>0</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>10343.0</td>\n",
       "      <td>Theresa</td>\n",
       "      <td>Chow</td>\n",
       "      <td>False</td>\n",
       "      <td>SS</td>\n",
       "      <td>41.550000</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>9.50</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>10345.0</td>\n",
       "      <td>Julia</td>\n",
       "      <td>Esteve</td>\n",
       "      <td>False</td>\n",
       "      <td>SS</td>\n",
       "      <td>49.883333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>60.883333</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>10346.0</td>\n",
       "      <td>Leslie</td>\n",
       "      <td>Andrade</td>\n",
       "      <td>False</td>\n",
       "      <td>SS</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>10349.0</td>\n",
       "      <td>XI</td>\n",
       "      <td>ZENG</td>\n",
       "      <td>False</td>\n",
       "      <td>SS</td>\n",
       "      <td>41.500000</td>\n",
       "      <td>13.500000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>6.25</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>66.250000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>10350.0</td>\n",
       "      <td>Axel</td>\n",
       "      <td>Purnomo</td>\n",
       "      <td>False</td>\n",
       "      <td>SS</td>\n",
       "      <td>22.500000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>3.50</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Employee ID     First Name    Last Name  Update Wage Company        Ord  \\\n",
       "0       10008.0          Elsie         Chan        False     GCM  15.250000   \n",
       "1       10010.0  Erica Fong-de         Jong        False     GCM  29.000000   \n",
       "2       10013.0          Hanbo        Zhang        False     GCM   3.500000   \n",
       "3       10032.0       Reynardo        Tjhin        False     GCM  28.500000   \n",
       "4       10054.0          Yiran        Zhang        False      SS   4.000000   \n",
       "5       10058.0       Han-Chun          Lin        False     GCM  34.130000   \n",
       "6       10061.0         Adrian          Lim        False      HL  17.000000   \n",
       "7       10081.0       Emmanuel       Quebec        False      HL   0.000000   \n",
       "8       10114.0           Mari       Cuasay        False      HL   0.000000   \n",
       "9       10120.0        Namrata       Gurung        False      HL  70.110000   \n",
       "10      10160.0          Pulin          Pan        False     GCM   0.000000   \n",
       "11      10161.0          Zihan         Wang        False     GCM  11.000000   \n",
       "12      10185.0         Lihour        Chhit        False      HL   0.000000   \n",
       "13      10249.0        Yonglin          Zhu        False     GCM   6.500000   \n",
       "14      10270.0          Zalfa        Buana        False     GCM   0.000000   \n",
       "15      10276.0           Cana       Fukuda        False     GCM  13.000000   \n",
       "16      10285.0        Manisha  Thapa Magar        False      HL   8.000000   \n",
       "17      10289.0         Jethro   Soewandito        False     GCM  46.500000   \n",
       "18      10310.0        Marlene      Schütte        False     GCM  44.116667   \n",
       "19      10335.0     Chansethea        Sunly        False      SS  10.000000   \n",
       "20      10337.0        Ngoc My       Nguyen         True      SS  13.500000   \n",
       "21      10341.0     Truc Thanh       Nguyen        False      SS   0.000000   \n",
       "22      10343.0        Theresa         Chow        False      SS  41.550000   \n",
       "23      10345.0          Julia       Esteve        False      SS  49.883333   \n",
       "24      10346.0         Leslie      Andrade        False      SS  11.000000   \n",
       "25      10349.0             XI         ZENG        False      SS  41.500000   \n",
       "26      10350.0           Axel      Purnomo        False      SS  22.500000   \n",
       "\n",
       "          Sat        Sun  Pub  Eve 1     Eve 2  No. of Shifts  Personal Leave  \\\n",
       "0   19.000000   0.066667    0   8.00  0.050000              6               0   \n",
       "1    6.500000  19.500000    0   0.00  0.000000              6               0   \n",
       "2    0.000000   0.000000    0   1.50  0.000000              1               0   \n",
       "3   17.083333   0.183333    0   7.00  0.083333              6               0   \n",
       "4    0.000000   0.000000    0   1.00  0.000000              1               0   \n",
       "5    6.500000   0.000000    0   4.00  0.000000              4               0   \n",
       "6    0.000000   0.000000    0   1.50  0.000000              2               0   \n",
       "7    0.000000   8.500000    0   0.00  0.000000              1               0   \n",
       "8    0.000000  11.000000    0   0.00  0.000000              1               0   \n",
       "9    0.000000   0.000000    0   4.56  0.215333              9               0   \n",
       "10   0.000000   0.000000    0   0.00  0.000000              0               0   \n",
       "11   0.000000   0.000000    0   0.00  0.000000              1               0   \n",
       "12   9.000000   0.000000    0   0.00  0.000000              1               0   \n",
       "13   0.000000   0.000000    0   2.50  0.000000              2               0   \n",
       "14   0.000000   8.500000    0   0.00  0.000000              1               0   \n",
       "15   7.500000   5.500000    0   0.00  0.000000              4               0   \n",
       "16   0.000000  11.000000    0   2.00  0.083333              2               0   \n",
       "17  14.500000   0.000000    0   3.50  0.083333              8               0   \n",
       "18  15.833333  10.633333    0   5.00  0.416667             10               0   \n",
       "19   0.000000   0.000000    0   0.00  0.000000              1               0   \n",
       "20   0.000000  10.000000    0   0.00  0.000000              3               0   \n",
       "21   0.000000   0.000000    0   0.00  0.000000              0               0   \n",
       "22   6.500000  18.000000    0   9.50  0.450000              9               0   \n",
       "23   0.000000   6.000000    0   5.00  0.000000              8               0   \n",
       "24   0.000000   0.000000    0   0.00  0.000000              2               0   \n",
       "25  13.500000   5.000000    0   6.25  0.000000             10               0   \n",
       "26   5.000000   0.000000    0   3.50  0.000000              6               0   \n",
       "\n",
       "    Annual Leave  Unpaid Leave      Total  Bonus $  \n",
       "0           0.00             0  42.366667      0.0  \n",
       "1           0.00             0  55.000000      0.0  \n",
       "2           0.00             0   5.000000      0.0  \n",
       "3           0.00             0  52.850000      0.0  \n",
       "4           0.00             0   5.000000      0.0  \n",
       "5          31.37             0  76.000000      0.0  \n",
       "6           0.00             0  18.500000      0.0  \n",
       "7           0.00             0   8.500000      0.0  \n",
       "8           0.00             0  11.000000      0.0  \n",
       "9           0.00             0  74.885333      0.0  \n",
       "10         76.00             0  76.000000      0.0  \n",
       "11          0.00             0  11.000000      0.0  \n",
       "12          0.00             0   9.000000      0.0  \n",
       "13          0.00             0   9.000000      0.0  \n",
       "14          0.00             0   8.500000      0.0  \n",
       "15          0.00             0  26.000000      0.0  \n",
       "16          0.00             0  21.083333      0.0  \n",
       "17          0.00             0  64.583333      0.0  \n",
       "18          0.00             0  76.000000      0.0  \n",
       "19          0.00             0  10.000000      0.0  \n",
       "20          0.00             0  23.500000      0.0  \n",
       "21         48.00             0  48.000000      0.0  \n",
       "22          0.00             0  76.000000      0.0  \n",
       "23          0.00             0  60.883333      0.0  \n",
       "24          0.00             0  11.000000      0.0  \n",
       "25          0.00             0  66.250000      0.0  \n",
       "26          0.00             0  31.000000      0.0  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timesheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Employee ID</th>\n",
       "      <th>First Name</th>\n",
       "      <th>Last Name</th>\n",
       "      <th>Preferred Name</th>\n",
       "      <th>Company</th>\n",
       "      <th>Store</th>\n",
       "      <th>Date</th>\n",
       "      <th>Hours</th>\n",
       "      <th>Store ID</th>\n",
       "      <th>recid_plo</th>\n",
       "      <th>Sales</th>\n",
       "      <th>Target Sales</th>\n",
       "      <th>Bonus Rate</th>\n",
       "      <th>Bonus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10035</td>\n",
       "      <td>Shanzhi</td>\n",
       "      <td>Chen</td>\n",
       "      <td>CHLOE CHEN</td>\n",
       "      <td>GCM</td>\n",
       "      <td>Waterloo</td>\n",
       "      <td>2024-01-22</td>\n",
       "      <td>8.5</td>\n",
       "      <td>S164</td>\n",
       "      <td>154</td>\n",
       "      <td>NaN</td>\n",
       "      <td>724.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10035</td>\n",
       "      <td>Shanzhi</td>\n",
       "      <td>Chen</td>\n",
       "      <td>CHLOE CHEN</td>\n",
       "      <td>GCM</td>\n",
       "      <td>Waterloo</td>\n",
       "      <td>2024-01-22</td>\n",
       "      <td>8.5</td>\n",
       "      <td>S164</td>\n",
       "      <td>154</td>\n",
       "      <td>NaN</td>\n",
       "      <td>784.39</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10052</td>\n",
       "      <td>Yeyu</td>\n",
       "      <td>Deng</td>\n",
       "      <td>DEREK DENG</td>\n",
       "      <td>GCM</td>\n",
       "      <td>Waterloo</td>\n",
       "      <td>2024-01-22</td>\n",
       "      <td>6.0</td>\n",
       "      <td>S164</td>\n",
       "      <td>154</td>\n",
       "      <td>NaN</td>\n",
       "      <td>724.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10052</td>\n",
       "      <td>Yeyu</td>\n",
       "      <td>Deng</td>\n",
       "      <td>DEREK DENG</td>\n",
       "      <td>GCM</td>\n",
       "      <td>Waterloo</td>\n",
       "      <td>2024-01-22</td>\n",
       "      <td>6.0</td>\n",
       "      <td>S164</td>\n",
       "      <td>154</td>\n",
       "      <td>NaN</td>\n",
       "      <td>784.39</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10299</td>\n",
       "      <td>YUTANG</td>\n",
       "      <td>HUANG</td>\n",
       "      <td>RYAN HUANG</td>\n",
       "      <td>GCM</td>\n",
       "      <td>Waterloo</td>\n",
       "      <td>2024-01-23</td>\n",
       "      <td>7.5</td>\n",
       "      <td>S164</td>\n",
       "      <td>154</td>\n",
       "      <td>NaN</td>\n",
       "      <td>978.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1803</th>\n",
       "      <td>10343</td>\n",
       "      <td>Theresa</td>\n",
       "      <td>Chow</td>\n",
       "      <td>Theresa chow</td>\n",
       "      <td>SS</td>\n",
       "      <td>501</td>\n",
       "      <td>2024-02-04</td>\n",
       "      <td>6.5</td>\n",
       "      <td>S001</td>\n",
       "      <td>124</td>\n",
       "      <td>5592.42</td>\n",
       "      <td>8213.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1804</th>\n",
       "      <td>10054</td>\n",
       "      <td>Yiran</td>\n",
       "      <td>Zhang</td>\n",
       "      <td>Eos zhang</td>\n",
       "      <td>SS</td>\n",
       "      <td>501</td>\n",
       "      <td>2024-02-04</td>\n",
       "      <td>7.5</td>\n",
       "      <td>S001</td>\n",
       "      <td>124</td>\n",
       "      <td>5592.42</td>\n",
       "      <td>7581.97</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1805</th>\n",
       "      <td>10054</td>\n",
       "      <td>Yiran</td>\n",
       "      <td>Zhang</td>\n",
       "      <td>Eos zhang</td>\n",
       "      <td>SS</td>\n",
       "      <td>501</td>\n",
       "      <td>2024-02-04</td>\n",
       "      <td>7.5</td>\n",
       "      <td>S001</td>\n",
       "      <td>124</td>\n",
       "      <td>5592.42</td>\n",
       "      <td>8213.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1806</th>\n",
       "      <td>10334</td>\n",
       "      <td>Huy Tien</td>\n",
       "      <td>Phan</td>\n",
       "      <td>Pat phan</td>\n",
       "      <td>SS</td>\n",
       "      <td>501</td>\n",
       "      <td>2024-02-04</td>\n",
       "      <td>7.5</td>\n",
       "      <td>S001</td>\n",
       "      <td>124</td>\n",
       "      <td>5592.42</td>\n",
       "      <td>7581.97</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1807</th>\n",
       "      <td>10334</td>\n",
       "      <td>Huy Tien</td>\n",
       "      <td>Phan</td>\n",
       "      <td>Pat phan</td>\n",
       "      <td>SS</td>\n",
       "      <td>501</td>\n",
       "      <td>2024-02-04</td>\n",
       "      <td>7.5</td>\n",
       "      <td>S001</td>\n",
       "      <td>124</td>\n",
       "      <td>5592.42</td>\n",
       "      <td>8213.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1808 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Employee ID First Name Last Name Preferred Name Company     Store  \\\n",
       "0           10035    Shanzhi      Chen     CHLOE CHEN     GCM  Waterloo   \n",
       "1           10035    Shanzhi      Chen     CHLOE CHEN     GCM  Waterloo   \n",
       "2           10052       Yeyu      Deng     DEREK DENG     GCM  Waterloo   \n",
       "3           10052       Yeyu      Deng     DEREK DENG     GCM  Waterloo   \n",
       "4           10299     YUTANG     HUANG     RYAN HUANG     GCM  Waterloo   \n",
       "...           ...        ...       ...            ...     ...       ...   \n",
       "1803        10343    Theresa      Chow   Theresa chow      SS       501   \n",
       "1804        10054      Yiran     Zhang      Eos zhang      SS       501   \n",
       "1805        10054      Yiran     Zhang      Eos zhang      SS       501   \n",
       "1806        10334   Huy Tien      Phan       Pat phan      SS       501   \n",
       "1807        10334   Huy Tien      Phan       Pat phan      SS       501   \n",
       "\n",
       "           Date  Hours Store ID  recid_plo    Sales  Target Sales  Bonus Rate  \\\n",
       "0    2024-01-22    8.5     S164        154      NaN        724.06         0.0   \n",
       "1    2024-01-22    8.5     S164        154      NaN        784.39         0.0   \n",
       "2    2024-01-22    6.0     S164        154      NaN        724.06         0.0   \n",
       "3    2024-01-22    6.0     S164        154      NaN        784.39         0.0   \n",
       "4    2024-01-23    7.5     S164        154      NaN        978.01         0.0   \n",
       "...         ...    ...      ...        ...      ...           ...         ...   \n",
       "1803 2024-02-04    6.5     S001        124  5592.42       8213.80         0.0   \n",
       "1804 2024-02-04    7.5     S001        124  5592.42       7581.97         0.0   \n",
       "1805 2024-02-04    7.5     S001        124  5592.42       8213.80         0.0   \n",
       "1806 2024-02-04    7.5     S001        124  5592.42       7581.97         0.0   \n",
       "1807 2024-02-04    7.5     S001        124  5592.42       8213.80         0.0   \n",
       "\n",
       "      Bonus  \n",
       "0       0.0  \n",
       "1       0.0  \n",
       "2       0.0  \n",
       "3       0.0  \n",
       "4       0.0  \n",
       "...     ...  \n",
       "1803    0.0  \n",
       "1804    0.0  \n",
       "1805    0.0  \n",
       "1806    0.0  \n",
       "1807    0.0  \n",
       "\n",
       "[1808 rows x 14 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bonus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Employee ID</th>\n",
       "      <th>First Name</th>\n",
       "      <th>Last Name</th>\n",
       "      <th>Preferred Name</th>\n",
       "      <th>Company</th>\n",
       "      <th>Store</th>\n",
       "      <th>Date</th>\n",
       "      <th>Hours</th>\n",
       "      <th>Store ID</th>\n",
       "      <th>recid_plo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10035</td>\n",
       "      <td>Shanzhi</td>\n",
       "      <td>Chen</td>\n",
       "      <td>CHLOE CHEN</td>\n",
       "      <td>GCM</td>\n",
       "      <td>Waterloo</td>\n",
       "      <td>2024-01-22</td>\n",
       "      <td>8.5</td>\n",
       "      <td>S164</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10052</td>\n",
       "      <td>Yeyu</td>\n",
       "      <td>Deng</td>\n",
       "      <td>DEREK DENG</td>\n",
       "      <td>GCM</td>\n",
       "      <td>Waterloo</td>\n",
       "      <td>2024-01-22</td>\n",
       "      <td>6.0</td>\n",
       "      <td>S164</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10299</td>\n",
       "      <td>YUTANG</td>\n",
       "      <td>HUANG</td>\n",
       "      <td>RYAN HUANG</td>\n",
       "      <td>GCM</td>\n",
       "      <td>Waterloo</td>\n",
       "      <td>2024-01-23</td>\n",
       "      <td>7.5</td>\n",
       "      <td>S164</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10052</td>\n",
       "      <td>Yeyu</td>\n",
       "      <td>Deng</td>\n",
       "      <td>DEREK DENG</td>\n",
       "      <td>GCM</td>\n",
       "      <td>Waterloo</td>\n",
       "      <td>2024-01-23</td>\n",
       "      <td>7.0</td>\n",
       "      <td>S164</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10052</td>\n",
       "      <td>Yeyu</td>\n",
       "      <td>Deng</td>\n",
       "      <td>DEREK DENG</td>\n",
       "      <td>GCM</td>\n",
       "      <td>Waterloo</td>\n",
       "      <td>2024-01-24</td>\n",
       "      <td>14.5</td>\n",
       "      <td>S164</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>917</th>\n",
       "      <td>10276</td>\n",
       "      <td>Cana</td>\n",
       "      <td>Fukuda</td>\n",
       "      <td>Cana fukuda</td>\n",
       "      <td>GCM</td>\n",
       "      <td>501</td>\n",
       "      <td>2024-02-04</td>\n",
       "      <td>9.0</td>\n",
       "      <td>S001</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>918</th>\n",
       "      <td>10303</td>\n",
       "      <td>Trong Van</td>\n",
       "      <td>Le</td>\n",
       "      <td>Van le</td>\n",
       "      <td>HL</td>\n",
       "      <td>501</td>\n",
       "      <td>2024-02-04</td>\n",
       "      <td>5.0</td>\n",
       "      <td>S001</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>919</th>\n",
       "      <td>10343</td>\n",
       "      <td>Theresa</td>\n",
       "      <td>Chow</td>\n",
       "      <td>Theresa chow</td>\n",
       "      <td>SS</td>\n",
       "      <td>501</td>\n",
       "      <td>2024-02-04</td>\n",
       "      <td>6.5</td>\n",
       "      <td>S001</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>920</th>\n",
       "      <td>10054</td>\n",
       "      <td>Yiran</td>\n",
       "      <td>Zhang</td>\n",
       "      <td>Eos zhang</td>\n",
       "      <td>SS</td>\n",
       "      <td>501</td>\n",
       "      <td>2024-02-04</td>\n",
       "      <td>7.5</td>\n",
       "      <td>S001</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>921</th>\n",
       "      <td>10334</td>\n",
       "      <td>Huy Tien</td>\n",
       "      <td>Phan</td>\n",
       "      <td>Pat phan</td>\n",
       "      <td>SS</td>\n",
       "      <td>501</td>\n",
       "      <td>2024-02-04</td>\n",
       "      <td>7.5</td>\n",
       "      <td>S001</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>922 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Employee ID First Name Last Name Preferred Name Company     Store  \\\n",
       "0          10035    Shanzhi      Chen     CHLOE CHEN     GCM  Waterloo   \n",
       "1          10052       Yeyu      Deng     DEREK DENG     GCM  Waterloo   \n",
       "2          10299     YUTANG     HUANG     RYAN HUANG     GCM  Waterloo   \n",
       "3          10052       Yeyu      Deng     DEREK DENG     GCM  Waterloo   \n",
       "4          10052       Yeyu      Deng     DEREK DENG     GCM  Waterloo   \n",
       "..           ...        ...       ...            ...     ...       ...   \n",
       "917        10276       Cana    Fukuda    Cana fukuda     GCM       501   \n",
       "918        10303  Trong Van        Le         Van le      HL       501   \n",
       "919        10343    Theresa      Chow   Theresa chow      SS       501   \n",
       "920        10054      Yiran     Zhang      Eos zhang      SS       501   \n",
       "921        10334   Huy Tien      Phan       Pat phan      SS       501   \n",
       "\n",
       "          Date  Hours Store ID  recid_plo  \n",
       "0   2024-01-22    8.5     S164        154  \n",
       "1   2024-01-22    6.0     S164        154  \n",
       "2   2024-01-23    7.5     S164        154  \n",
       "3   2024-01-23    7.0     S164        154  \n",
       "4   2024-01-24   14.5     S164        154  \n",
       "..         ...    ...      ...        ...  \n",
       "917 2024-02-04    9.0     S001        124  \n",
       "918 2024-02-04    5.0     S001        124  \n",
       "919 2024-02-04    6.5     S001        124  \n",
       "920 2024-02-04    7.5     S001        124  \n",
       "921 2024-02-04    7.5     S001        124  \n",
       "\n",
       "[922 rows x 10 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Employee ID</th>\n",
       "      <th>First Name</th>\n",
       "      <th>Last Name</th>\n",
       "      <th>Preferred Name</th>\n",
       "      <th>Company</th>\n",
       "      <th>Store</th>\n",
       "      <th>Date</th>\n",
       "      <th>Hours</th>\n",
       "      <th>Store ID</th>\n",
       "      <th>recid_plo</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10035</td>\n",
       "      <td>Shanzhi</td>\n",
       "      <td>Chen</td>\n",
       "      <td>CHLOE CHEN</td>\n",
       "      <td>GCM</td>\n",
       "      <td>Waterloo</td>\n",
       "      <td>2024-01-22</td>\n",
       "      <td>8.5</td>\n",
       "      <td>S164</td>\n",
       "      <td>154</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10052</td>\n",
       "      <td>Yeyu</td>\n",
       "      <td>Deng</td>\n",
       "      <td>DEREK DENG</td>\n",
       "      <td>GCM</td>\n",
       "      <td>Waterloo</td>\n",
       "      <td>2024-01-22</td>\n",
       "      <td>6.0</td>\n",
       "      <td>S164</td>\n",
       "      <td>154</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10299</td>\n",
       "      <td>YUTANG</td>\n",
       "      <td>HUANG</td>\n",
       "      <td>RYAN HUANG</td>\n",
       "      <td>GCM</td>\n",
       "      <td>Waterloo</td>\n",
       "      <td>2024-01-23</td>\n",
       "      <td>7.5</td>\n",
       "      <td>S164</td>\n",
       "      <td>154</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10052</td>\n",
       "      <td>Yeyu</td>\n",
       "      <td>Deng</td>\n",
       "      <td>DEREK DENG</td>\n",
       "      <td>GCM</td>\n",
       "      <td>Waterloo</td>\n",
       "      <td>2024-01-23</td>\n",
       "      <td>7.0</td>\n",
       "      <td>S164</td>\n",
       "      <td>154</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10052</td>\n",
       "      <td>Yeyu</td>\n",
       "      <td>Deng</td>\n",
       "      <td>DEREK DENG</td>\n",
       "      <td>GCM</td>\n",
       "      <td>Waterloo</td>\n",
       "      <td>2024-01-24</td>\n",
       "      <td>14.5</td>\n",
       "      <td>S164</td>\n",
       "      <td>154</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>917</th>\n",
       "      <td>10276</td>\n",
       "      <td>Cana</td>\n",
       "      <td>Fukuda</td>\n",
       "      <td>Cana fukuda</td>\n",
       "      <td>GCM</td>\n",
       "      <td>501</td>\n",
       "      <td>2024-02-04</td>\n",
       "      <td>9.0</td>\n",
       "      <td>S001</td>\n",
       "      <td>124</td>\n",
       "      <td>5592.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>918</th>\n",
       "      <td>10303</td>\n",
       "      <td>Trong Van</td>\n",
       "      <td>Le</td>\n",
       "      <td>Van le</td>\n",
       "      <td>HL</td>\n",
       "      <td>501</td>\n",
       "      <td>2024-02-04</td>\n",
       "      <td>5.0</td>\n",
       "      <td>S001</td>\n",
       "      <td>124</td>\n",
       "      <td>5592.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>919</th>\n",
       "      <td>10343</td>\n",
       "      <td>Theresa</td>\n",
       "      <td>Chow</td>\n",
       "      <td>Theresa chow</td>\n",
       "      <td>SS</td>\n",
       "      <td>501</td>\n",
       "      <td>2024-02-04</td>\n",
       "      <td>6.5</td>\n",
       "      <td>S001</td>\n",
       "      <td>124</td>\n",
       "      <td>5592.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>920</th>\n",
       "      <td>10054</td>\n",
       "      <td>Yiran</td>\n",
       "      <td>Zhang</td>\n",
       "      <td>Eos zhang</td>\n",
       "      <td>SS</td>\n",
       "      <td>501</td>\n",
       "      <td>2024-02-04</td>\n",
       "      <td>7.5</td>\n",
       "      <td>S001</td>\n",
       "      <td>124</td>\n",
       "      <td>5592.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>921</th>\n",
       "      <td>10334</td>\n",
       "      <td>Huy Tien</td>\n",
       "      <td>Phan</td>\n",
       "      <td>Pat phan</td>\n",
       "      <td>SS</td>\n",
       "      <td>501</td>\n",
       "      <td>2024-02-04</td>\n",
       "      <td>7.5</td>\n",
       "      <td>S001</td>\n",
       "      <td>124</td>\n",
       "      <td>5592.42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>922 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Employee ID First Name Last Name Preferred Name Company     Store  \\\n",
       "0          10035    Shanzhi      Chen     CHLOE CHEN     GCM  Waterloo   \n",
       "1          10052       Yeyu      Deng     DEREK DENG     GCM  Waterloo   \n",
       "2          10299     YUTANG     HUANG     RYAN HUANG     GCM  Waterloo   \n",
       "3          10052       Yeyu      Deng     DEREK DENG     GCM  Waterloo   \n",
       "4          10052       Yeyu      Deng     DEREK DENG     GCM  Waterloo   \n",
       "..           ...        ...       ...            ...     ...       ...   \n",
       "917        10276       Cana    Fukuda    Cana fukuda     GCM       501   \n",
       "918        10303  Trong Van        Le         Van le      HL       501   \n",
       "919        10343    Theresa      Chow   Theresa chow      SS       501   \n",
       "920        10054      Yiran     Zhang      Eos zhang      SS       501   \n",
       "921        10334   Huy Tien      Phan       Pat phan      SS       501   \n",
       "\n",
       "          Date  Hours Store ID  recid_plo    Sales  \n",
       "0   2024-01-22    8.5     S164        154      NaN  \n",
       "1   2024-01-22    6.0     S164        154      NaN  \n",
       "2   2024-01-23    7.5     S164        154      NaN  \n",
       "3   2024-01-23    7.0     S164        154      NaN  \n",
       "4   2024-01-24   14.5     S164        154      NaN  \n",
       "..         ...    ...      ...        ...      ...  \n",
       "917 2024-02-04    9.0     S001        124  5592.42  \n",
       "918 2024-02-04    5.0     S001        124  5592.42  \n",
       "919 2024-02-04    6.5     S001        124  5592.42  \n",
       "920 2024-02-04    7.5     S001        124  5592.42  \n",
       "921 2024-02-04    7.5     S001        124  5592.42  \n",
       "\n",
       "[922 rows x 11 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bonus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calc_timesheets_n_billings(files):\n",
    "  print('calc')\n",
    "  timesheets = pd.DataFrame()\n",
    "  billings = pd.DataFrame()\n",
    "  rostered_hr = pd.DataFrame()\n",
    "  additional_hr = pd.DataFrame()\n",
    "\n",
    "  for file in files:\n",
    "    # time.sleep(1)\n",
    "    timesheet = pd.read_excel(file, sheet_name = 'Timesheet')\n",
    "    billing = pd.read_excel(file, sheet_name = 'Billing')\n",
    "    rostered_hr_w1 = extract_rostered_hr(file, 'Week 1 Roster')\n",
    "    rostered_hr_w2 = extract_rostered_hr(file, 'Week 2 Roster')\n",
    "    additional_hr_w1 = extract_additional_hr(file, 'Week 1 Roster')\n",
    "    additional_hr_w2 = extract_additional_hr(file, 'Week 2 Roster')\n",
    "    employees = pd.read_excel(file, sheet_name = 'Employees')\n",
    "\n",
    "    timesheets = pd.concat([timesheets, timesheet], ignore_index=True)\n",
    "    billings = pd.concat([billings, billing], ignore_index=True)\n",
    "    rostered_hr = pd.concat([rostered_hr, rostered_hr_w1], ignore_index=True)\n",
    "    rostered_hr = pd.concat([rostered_hr, rostered_hr_w2], ignore_index=True)\n",
    "    additional_hr = pd.concat([additional_hr, additional_hr_w1], ignore_index=True)\n",
    "    additional_hr = pd.concat([additional_hr, additional_hr_w2], ignore_index=True)\n",
    "\n",
    "  #Remove irrelevant rows\n",
    "  timesheets.dropna(subset = ['Employee ID'], inplace=True)\n",
    "  #Keep the needed columns\n",
    "  timesheets_cols = [1,2,3,7,8,9,10,11,12,13,14,15,16,17,18,19,20]\n",
    "  timesheets = timesheets[timesheets.columns[timesheets_cols]]\n",
    "  timesheets['Update Wage'] = timesheets['Update Wage'].astype(bool)\n",
    "  #Column Aggregations\n",
    "  timesheets_agg_cols = {'First Name':'first','Last Name':'first','Update Wage':'first','Hour Threshold':'first','Company':'first','Ord':'sum','Sat':'sum','Sun':'sum','Pub':'sum','Eve 1':'sum','Eve 2':'sum','No. of Shifts':'sum','Personal Leave':'sum','Annual Leave':'sum','Unpaid Leave':'sum','Total':'sum'}\n",
    "  timesheets = timesheets.groupby('Employee ID', as_index = False).agg(timesheets_agg_cols)\n",
    "  #Calculate Over Threshold\n",
    "  timesheets['Over Threshold'] = timesheets['Total'] - timesheets['Hour Threshold']\n",
    "  timesheets.loc[timesheets[\"Over Threshold\"] <=0, \"Over Threshold\"] = 0\n",
    "  #Keep Over Thresholds to a new df\n",
    "  over_threshold = timesheets[timesheets['Over Threshold']>0]\n",
    "  #Reduce Ord & Total with the excess\n",
    "  timesheets['Ord'] = timesheets['Ord'] - timesheets['Over Threshold']\n",
    "  timesheets['Total'] = timesheets['Total'] - timesheets['Over Threshold']\n",
    "  #Convert 80 & 100 hours to 76 hours\n",
    "  hours_col = ['Ord', 'Sat','Sun','Eve 1','Eve 2','Pub','Personal Leave', 'Annual Leave', 'Unpaid Leave', 'Total']\n",
    "  if(100 in timesheets[\"Hour Threshold\"].values):\n",
    "    timesheets.loc[timesheets[\"Hour Threshold\"] == 100, hours_col] = timesheets[hours_col]/100*76\n",
    "  if(80 in timesheets[\"Hour Threshold\"].values):\n",
    "    timesheets.loc[timesheets[\"Hour Threshold\"] == 80, hours_col] = timesheets[hours_col]/80*76\n",
    "  if any(timesheets[\"Hour Threshold\"] > 1000):\n",
    "    # Find rows where \"Hour Threshold\" is greater than 1000\n",
    "    rows_to_update = timesheets.loc[timesheets[\"Hour Threshold\"] > 1000]\n",
    "    # Perform actions on the rows\n",
    "    for index, row in rows_to_update.iterrows():\n",
    "      threshold = int(row[\"Hour Threshold\"])\n",
    "      base = int(str(threshold)[:2])\n",
    "      # print('before conversion')\n",
    "      conversion = int(str(threshold)[-2:])\n",
    "      # print('after conversion')\n",
    "      # Update multiple columns using .loc\n",
    "      timesheets.loc[index, hours_col] = timesheets.loc[index, hours_col] / conversion * base\n",
    "\n",
    "  #drop Hour Threshold & Over Threshold\n",
    "  timesheets = timesheets.drop(['Hour Threshold','Over Threshold'],axis = 1)\n",
    "\n",
    "  #Remove irrelevant rows\n",
    "  billings.dropna(subset=['Store'],inplace = True)\n",
    "  billings = billings[billings['Total'] > 0]\n",
    "\n",
    "  #Keep the needed columns\n",
    "  billings_cols = [0,1,2,3,4,5,6,7,8,9,10,11]\n",
    "  billings = billings[billings.columns[billings_cols]]\n",
    "  #Column Aggregations\n",
    "  billings_agg_cols = {'Ord':'sum','Sat':'sum','Sun':'sum','Pub':'sum','Eve 1':'sum','Eve 2':'sum','No. of Shifts':'sum','Personal Leave':'sum','Annual Leave':'sum','Unpaid Leave':'sum','Total':'sum'}\n",
    "  billings = billings.groupby('Store', as_index = False).agg(billings_agg_cols)\n",
    "\n",
    "  rostered_hr = pd.merge(rostered_hr, employees[['Employee ID', 'First Name', 'Last Name', 'Company']], how='left', on=['Employee ID'])\n",
    "  rostered_hr_col = [\n",
    "    'Employee ID',\n",
    "    'First Name',\n",
    "    'Last Name',\n",
    "    'Preferred Name',\n",
    "    'Company',\n",
    "    'Store',\n",
    "    'Date',\n",
    "    'Hours'\n",
    "    ]\n",
    "  rostered_hr = rostered_hr[rostered_hr_col]\n",
    "  rostered_hr['Date'] = pd.to_datetime(rostered_hr['Date'])\n",
    "\n",
    "  bonus = rostered_hr.copy()\n",
    "\n",
    "  # Stitch Store ID and drop rows which Store ID are not found\n",
    "  sheet_id = '1rqOeBjA9drmTnjlENvr57RqL5-oxSqe_KGdbdL2MKhM'\n",
    "  sheet_name = 'StoreReference'\n",
    "  url = f'https://docs.google.com/spreadsheets/d/{sheet_id}/gviz/tq?tqx=out:csv&sheet={sheet_name}'\n",
    "  store_ref = pd.read_csv(url)\n",
    "\n",
    "  bonus = pd.merge(bonus, store_ref, on=['Store'], how = 'left')\n",
    "\n",
    "  bonus.dropna(subset=['Store ID'], inplace = True)\n",
    "\n",
    "  # Stitch shop_id\n",
    "  sheet_id = '1ezyBlKquUhYnFwmIKTR4fghI59ZvGaKL35mKbcdeRy4'\n",
    "  sheet_name = 'Stores'\n",
    "  url = f'https://docs.google.com/spreadsheets/d/{sheet_id}/gviz/tq?tqx=out:csv&sheet={sheet_name}'\n",
    "  store_df_gs = pd.read_csv(url)\n",
    "\n",
    "  bonus = pd.merge(bonus, store_df_gs[['Store ID', 'shop_id']], on=['Store ID'], how = 'left')\n",
    "  bonus['shop_id'] = bonus['shop_id'].astype(int)\n",
    "\n",
    "\n",
    "  # Stich sales based on shop_id & dates, skip if there is no Date\n",
    "  start = bonus['Date'].min()\n",
    "  end = bonus['Date'].max()\n",
    "\n",
    "  start_str = start.strftime('%Y-%m-%d')\n",
    "  end_str = (end+timedelta(days=1)).strftime('%Y-%m-%d')\n",
    "  shop_id_list = bonus['shop_id'].unique().tolist()\n",
    "  shop_id_list_str = ', '.join(str(id) for id in shop_id_list)\n",
    "  stock_exclusions_list = [266,267,268,269,270,272,256,255,254]\n",
    "  stock_exclusions_list_str = ', '.join(str(s) for s in stock_exclusions_list)\n",
    "\n",
    "  query = '''\n",
    "  SELECT\n",
    "    d.shop_id, Date(d.docket_date) AS Date, SUM(dl.quantity * dl.sell_inc) as Sales\n",
    "  FROM\n",
    "    DocketLine dl\n",
    "  JOIN\n",
    "    Docket d on dl.docket_id  = d.docket_id \n",
    "  WHERE \n",
    "    d.docket_date >='{start}' and d.docket_date < '{end}' and d.shop_id in ({shop_id_list}) and d.`transaction`  = 'SA' and dl.stock_id not in ({stock_exclusions_list})\n",
    "  GROUP BY \n",
    "    d.shop_id, Date(d.docket_date)\n",
    "  '''.format(start=start_str, end = end_str, shop_id_list = shop_id_list_str, stock_exclusions_list = stock_exclusions_list_str)\n",
    "  sales_df = pd.read_sql(con=Gong_cha_MySQL_engine.connect(), sql=sql_text(query))\n",
    "  sales_df['Date'] = pd.to_datetime(sales_df['Date'])\n",
    "\n",
    "  bonus = pd.merge(bonus, sales_df[['shop_id', 'Date', 'Sales']], on=['shop_id', 'Date'], how = 'left')\n",
    "\n",
    "  # Stitch Target Sales & Bonus Rates\n",
    "  sheet_id = '1rqOeBjA9drmTnjlENvr57RqL5-oxSqe_KGdbdL2MKhM'\n",
    "  sheet_name = 'Targets'\n",
    "  url = f'https://docs.google.com/spreadsheets/d/{sheet_id}/gviz/tq?tqx=out:csv&sheet={sheet_name}'\n",
    "  targets = pd.read_csv(url)\n",
    "  targets['Date'] = pd.to_datetime(targets['Date'])\n",
    "\n",
    "  # Change Bonus Rates to 0, if Target Sales is not met\n",
    "  bonus = pd.merge(bonus, targets[['Store ID', 'Date', 'Target Sales', 'Bonus Rate']], on=['Store ID', 'Date'], how = 'left')\n",
    "  bonus['Bonus Rate'] = bonus['Bonus Rate'].where(bonus['Sales'] >= bonus['Target Sales'], 0)\n",
    "  bonus['Bonus'] = bonus['Bonus Rate']  * bonus['Hours']\n",
    "\n",
    "  # Work out additional_hr\n",
    "  additional_hr = additional_hr.dropna(subset=['Employee ID'])\n",
    "  additional_hr = pd.merge(additional_hr, employees[['Employee ID', 'First Name', 'Last Name', 'Company']], how='left', on=['Employee ID'])\n",
    "  additional_hr_col = [\n",
    "    'Employee ID',\n",
    "    'First Name',\n",
    "    'Last Name',\n",
    "    'Preferred Name',\n",
    "    'Company',\n",
    "    'Store',\n",
    "    'Date',\n",
    "    'Hours'\n",
    "  ]\n",
    "  additional_hr = additional_hr[additional_hr_col]\n",
    "  additional_hr['Date'] = pd.to_datetime(additional_hr['Date'])\n",
    "\n",
    "  # Concat rostered_hr and additional_hr\n",
    "  analysis = pd.concat([rostered_hr, additional_hr])\n",
    "\n",
    "  # Concat Bouns on to Timesheets\n",
    "  bonus_summary = bonus.groupby('Employee ID', as_index = False).agg({'Bonus':'sum'})\n",
    "  timesheets = pd.merge(timesheets, bonus_summary, on=['Employee ID'], how = 'left')\n",
    "  timesheets.fillna({'Bonus':0}, inplace = True)\n",
    "  timesheets.rename(columns={'Bonus':'Bonus $'}, inplace = True)\n",
    "\n",
    "  return timesheets, billings, over_threshold, analysis, bonus\n",
    "\n",
    "# # # END OF FUNCTIONS\n",
    "\n",
    "\n",
    "import io\n",
    "import streamlit as st\n",
    "\n",
    "st.title('Timesheet & Billing')\n",
    "\n",
    "uploaded_files = st.file_uploader(\"Choose Files\", accept_multiple_files = True)\n",
    "\n",
    "# Create an empty container\n",
    "output = st.empty()\n",
    "\n",
    "# if uploaded_files is not None:\n",
    "if len(uploaded_files) > 0:\n",
    "    ts, bl, ot, an, bo = calc_timesheets_n_billings(uploaded_files)\n",
    "\n",
    "    buffer = io.BytesIO()\n",
    "\n",
    "    with pd.ExcelWriter(buffer, engine='xlsxwriter') as writer:\n",
    "    # Write each dataframe to a different worksheet.\n",
    "        ts.to_excel(writer, sheet_name='Timesheet', index = False)\n",
    "        bl.to_excel(writer, sheet_name='Billing', index = False)\n",
    "        ot.to_excel(writer, sheet_name='Over Threshold', index = False)\n",
    "        an.to_excel(writer, sheet_name='Analysis',index = False)\n",
    "        bo.to_excel(writer, sheet_name='Bonus',index = False)\n",
    "\n",
    "    # Close the Pandas Excel writer and output the Excel file to the buffer\n",
    "    writer.close()\n",
    "\n",
    "    st.download_button(\n",
    "        label=\"Download\",\n",
    "        data=buffer,\n",
    "        file_name=\"Timesheet & Billing.xlsx\",\n",
    "        mime=\"application/vnd.ms-excel\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
