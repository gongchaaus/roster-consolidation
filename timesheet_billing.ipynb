{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from database_utils import *\n",
    "clickhouse_client = gong_cha_redcat_db_clickhouse_client\n",
    "\n",
    "# # # START OF FUNCTIONS\n",
    "def extract_additional_hr(file, sheet_name):\n",
    "  df = pd.read_excel(file, sheet_name = sheet_name)\n",
    "  df = df.dropna(subset=['Employee ID'])\n",
    "\n",
    "  if df['Employee ID'].dtypes == 'object':\n",
    "    df['Employee ID'] = df['Employee ID'].str[:6]\n",
    "  df['Employee ID'] = df['Employee ID'].astype(int)\n",
    "\n",
    "  if df['Store'].dtypes == float:\n",
    "    df['Store'] = df['Store'].astype(int).astype(str)\n",
    "\n",
    "  df = df.fillna({'Add': 0, 'Add.1': 0,'Add.2': 0,'Add.3': 0,'Add.4': 0,'Add.5': 0,'Personal Leave': 0,'Annual Leave': 0,})\n",
    "  df['2012-11-01'] = df['Add'] + df['Add.1'] + df['Add.2'] + df['Add.3'] + df['Add.4'] + df['Add.5']\n",
    "  df['2013-01-01'] = df['Personal Leave'] + df['Annual Leave']\n",
    "  cols =[0,1,2, df.columns.tolist().index('2012-11-01'),df.columns.tolist().index('2013-01-01')]\n",
    "\n",
    "  df = df.iloc[:, cols]\n",
    "  df = df.dropna(subset=df.columns[:3], how='all')\n",
    "  df = df.melt(id_vars=['Employee ID', 'Store', 'Preferred Name'], value_vars=df.columns[3:], var_name='Date', value_name='Hours')\n",
    "  df = df[df['Hours'] != 0]\n",
    "  return df\n",
    "\n",
    "def extract_rostered_hr(file, sheet_name):\n",
    "  df = pd.read_excel(file, sheet_name = sheet_name)\n",
    "\n",
    "  df = df.dropna(subset=['Employee ID'])\n",
    "\n",
    "  if df['Employee ID'].dtypes == 'object':\n",
    "    df['Employee ID'] = df['Employee ID'].str[:6]\n",
    "  df['Employee ID'] = df['Employee ID'].astype(int)\n",
    "\n",
    "  if df['Store'].dtypes == float:\n",
    "    df['Store'] = df['Store'].astype(int).astype(str)\n",
    "\n",
    "  df = df.iloc[:, :24]\n",
    "  cols = [0,1,2]\n",
    "  for col in range(3, 24, 3):\n",
    "      df[df.columns[col]] = df[df.columns[col+2]]\n",
    "      cols.append(col)\n",
    "  df = df.iloc[:,cols]\n",
    "  df = df.dropna(subset=df.columns[:3], how='all')\n",
    "  df = df.melt(id_vars=['Employee ID', 'Store', 'Preferred Name'], value_vars=df.columns[3:], var_name='Date', value_name='Hours')\n",
    "  df = df[df['Hours'] != 0]\n",
    "  return df\n",
    "\n",
    "# Function to count digits before the decimal point in a float number\n",
    "def count_digits_before_decimal(number):\n",
    "  # Convert to string, split at the decimal point, and count digits in the integer part\n",
    "  integer_part = str(number).split('.')[0]\n",
    "  return len(integer_part.replace('-', '').replace('nan', ''))\n",
    "\n",
    "def calc_timesheets_n_billings(files):\n",
    "  print('calc')\n",
    "  timesheets = pd.DataFrame()\n",
    "  # billings = pd.DataFrame()\n",
    "  rostered_hr = pd.DataFrame()\n",
    "  additional_hr = pd.DataFrame()\n",
    "\n",
    "  for file in files:\n",
    "    timesheet = pd.read_excel(file, sheet_name = 'Timesheet')\n",
    "    # billing = pd.read_excel(file, sheet_name = 'Billing')\n",
    "    rostered_hr_w1 = extract_rostered_hr(file, 'Week 1 Roster')\n",
    "    rostered_hr_w2 = extract_rostered_hr(file, 'Week 2 Roster')\n",
    "    additional_hr_w1 = extract_additional_hr(file, 'Week 1 Roster')\n",
    "    additional_hr_w2 = extract_additional_hr(file, 'Week 2 Roster')\n",
    "    employees = pd.read_excel(file, sheet_name = 'Employees')\n",
    "\n",
    "    timesheets = pd.concat([timesheets, timesheet], ignore_index=True)\n",
    "    # billings = pd.concat([billings, billing], ignore_index=True)\n",
    "    rostered_hr = pd.concat([rostered_hr, rostered_hr_w1], ignore_index=True)\n",
    "    rostered_hr = pd.concat([rostered_hr, rostered_hr_w2], ignore_index=True)\n",
    "    additional_hr = pd.concat([additional_hr, additional_hr_w1], ignore_index=True)\n",
    "    additional_hr = pd.concat([additional_hr, additional_hr_w2], ignore_index=True)\n",
    "\n",
    "  roster_start_date = rostered_hr['Date'].min()\n",
    "  #Remove irrelevant rows\n",
    "  timesheets = timesheets.dropna(subset = ['Employee ID'])\n",
    "\n",
    "  #Keep the needed columns\n",
    "  timesheets_cols = [1,2,3,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22]\n",
    "  timesheets = timesheets[timesheets.columns[timesheets_cols]]\n",
    "  timesheets['Update Wage'] = timesheets['Update Wage'].astype(bool)\n",
    "  #Column Aggregations\n",
    "  over_threshold_agg_cols = {'Ord':'sum','Sat':'sum','Sun':'sum','Pub':'sum','Eve 1':'sum','Eve 2':'sum','No. of Shifts':'sum','Personal Leave':'sum','Annual Leave':'sum','Unpaid Leave':'sum','Total':'sum'}\n",
    "  # timesheets = timesheets.groupby(['Employee ID', 'First Name','Last Name', 'Update Wage', 'Hour Threshold', 'Labour Hire', 'Store', 'Operator'], as_index = False).agg(timesheets_agg_cols)\n",
    "  over_threshold = timesheets.groupby(['Employee ID', 'First Name','Last Name', 'Update Wage', 'Hour Threshold'], as_index = False).agg(over_threshold_agg_cols)\n",
    "\n",
    "  #Calculate Over Threshold\n",
    "  over_threshold['Over Threshold'] = over_threshold['Total'] - over_threshold['Hour Threshold']\n",
    "  over_threshold.loc[over_threshold[\"Over Threshold\"] <=0, \"Over Threshold\"] = 0\n",
    "\n",
    "  #Reduce Ord & Total with the excess\n",
    "  over_threshold['Ord OT Ratio'] = (over_threshold['Ord'] - over_threshold['Over Threshold']) / over_threshold['Ord']\n",
    "  # over_threshold['Ord'] = over_threshold['Ord'] - over_threshold['Over Threshold']\n",
    "  # over_threshold['Total'] = over_threshold['Total'] - over_threshold['Over Threshold']\n",
    "\n",
    "  time_sheets_agg_cols = {'Ord':'sum','Sat':'sum','Sun':'sum','Pub':'sum','Eve 1':'sum','Eve 2':'sum','No. of Shifts':'sum','Personal Leave':'sum','Annual Leave':'sum','Unpaid Leave':'sum','Total':'sum'}\n",
    "  timesheets = timesheets.groupby(['Employee ID', 'First Name','Last Name', 'Update Wage', 'Hour Threshold', 'Labour Hire', 'Store', 'Operator'], as_index = False).agg(time_sheets_agg_cols)\n",
    "\n",
    "  # Add Ord OT Ratio and Over Threshold columns from over_threshold dataframe\n",
    "  timesheets = pd.merge(timesheets, over_threshold[['Employee ID', 'Ord OT Ratio', 'Over Threshold']], on=['Employee ID'], how='left')\n",
    "  timesheets.fillna({'Ord OT Ratio': 1, 'Over Threshold': 0}, inplace=True)\n",
    "\n",
    "\n",
    "  # Apply Ord OT Ratio to Ord hours when Over Threshold > 0\n",
    "  timesheets.loc[timesheets['Over Threshold'] > 0, 'Ord'] = timesheets['Ord'] * timesheets['Ord OT Ratio']\n",
    "  timesheets.loc[timesheets['Over Threshold'] > 0, 'Total'] = timesheets['Total'] - timesheets['Over Threshold']\n",
    "\n",
    "  #Convert 80 & 100 hours to 76 hours\n",
    "  hours_col = ['Ord', 'Sat','Sun','Eve 1','Eve 2','Pub','Personal Leave', 'Annual Leave', 'Unpaid Leave', 'Total']\n",
    "  if(100 in timesheets[\"Hour Threshold\"].values):\n",
    "      timesheets.loc[timesheets[\"Hour Threshold\"] == 100, hours_col] = timesheets[hours_col]/100*76\n",
    "  if(80 in timesheets[\"Hour Threshold\"].values):\n",
    "      timesheets.loc[timesheets[\"Hour Threshold\"] == 80, hours_col] = timesheets[hours_col]/80*76\n",
    "  if any(timesheets[\"Hour Threshold\"] > 1000):\n",
    "  # Find rows where \"Hour Threshold\" is greater than 1000\n",
    "      rows_to_update = timesheets.loc[timesheets[\"Hour Threshold\"] > 1000]\n",
    "      # Perform actions on the rows\n",
    "      for index, row in rows_to_update.iterrows():\n",
    "          threshold = int(row[\"Hour Threshold\"])\n",
    "          base = int(str(threshold)[:2])\n",
    "          conversion = int(str(threshold)[-2:])\n",
    "          # Update multiple columns using .loc\n",
    "          timesheets.loc[index, hours_col] = timesheets.loc[index, hours_col] / conversion * base\n",
    "  \n",
    "  \n",
    "  #Keep Over Thresholds to a new df\n",
    "  over_threshold = over_threshold[over_threshold['Over Threshold']>0]\n",
    "  \n",
    "  #drop Hour Threshold & Over Threshold\n",
    "\n",
    "  timesheets = timesheets.drop(['Hour Threshold','Over Threshold', 'Ord OT Ratio'],axis = 1)\n",
    "\n",
    "  #Column Aggregations\n",
    "  billings_agg_cols = {'Ord':'sum','Sat':'sum','Sun':'sum','Pub':'sum','Eve 1':'sum','Eve 2':'sum','No. of Shifts':'sum','Personal Leave':'sum','Annual Leave':'sum','Unpaid Leave':'sum','Total':'sum'}\n",
    "  billings = timesheets.groupby(['Labour Hire', 'Store', 'Operator'], as_index = False).agg(billings_agg_cols)\n",
    "\n",
    "  rostered_hr = pd.merge(rostered_hr, employees[['Employee ID', 'First Name', 'Last Name', 'Company']], how='left', on=['Employee ID'])\n",
    "  rostered_hr_col = [\n",
    "  'Employee ID',\n",
    "  'First Name',\n",
    "  'Last Name',\n",
    "  'Preferred Name',\n",
    "  'Company',\n",
    "  'Store',\n",
    "  'Date',\n",
    "  'Hours'\n",
    "  ]\n",
    "  rostered_hr = rostered_hr[rostered_hr_col]\n",
    "  rostered_hr['Date'] = pd.to_datetime(rostered_hr['Date']).dt.date\n",
    "\n",
    "  bonus = rostered_hr.copy()\n",
    "\n",
    "  # Stitch Store ID and drop rows which Store ID are not found\n",
    "  sheet_id = '1rqOeBjA9drmTnjlENvr57RqL5-oxSqe_KGdbdL2MKhM'\n",
    "  sheet_name = 'StoreReference'\n",
    "  url = f'https://docs.google.com/spreadsheets/d/{sheet_id}/gviz/tq?tqx=out:csv&sheet={sheet_name}'\n",
    "  store_ref = pd.read_csv(url)\n",
    "\n",
    "  bonus = pd.merge(bonus, store_ref, on=['Store'], how = 'left')\n",
    "\n",
    "  bonus.dropna(subset=['Store ID'], inplace = True)\n",
    "\n",
    "  if bonus.shape[0] == 0:\n",
    "     print('No bonus to process')\n",
    "  \n",
    "  else:\n",
    "    store_crm_config = {\n",
    "      'sheet_id': '1aVcnah9Cp_PUvFiXgd2XRmBpLhumCqHUaqROaLcpYfc',\n",
    "      'sheet_name': 'store'\n",
    "    }\n",
    "    store_crm = read_csv_from_config(store_crm_config)\n",
    "    store_crm['opened_on'] = pd.to_datetime(store_crm['opened_on'])\n",
    "    store_crm['closed_on'] = pd.to_datetime(store_crm['closed_on'])\n",
    "    store_crm_col = ['store_id', 'recid_plo']\n",
    "    store_crm = store_crm[store_crm_col]\n",
    "    store_crm = store_crm[~store_crm['recid_plo'].isna()]\n",
    "    store_crm = store_crm.rename(columns={'store_id': 'Store ID'})\n",
    "    \n",
    "    bonus = pd.merge(bonus, store_crm[['Store ID', 'recid_plo']], on=['Store ID'], how = 'left')\n",
    "    bonus['recid_plo'] = bonus['recid_plo'].astype(int)\n",
    "\n",
    "    # Stich sales based on recid_plo & dates, skip if there is no Date\n",
    "    start = bonus['Date'].min()\n",
    "    end = bonus['Date'].max()\n",
    "\n",
    "    start_str = start.strftime('%Y-%m-%d')\n",
    "    end_str = end.strftime('%Y-%m-%d')\n",
    "\n",
    "    recid_plo_list = bonus['recid_plo'].unique().tolist()\n",
    "    recid_plo_list_str = ', '.join(str(id) for id in recid_plo_list)\n",
    "\n",
    "    query = '''\n",
    "    SELECT *\n",
    "    FROM r_opsbonusexclusion\n",
    "    '''\n",
    "    exclusion_df = get_DataFrame_from_clickhouse(query, clickhouse_client)\n",
    "    excluded_recid_plu = exclusion_df['recid_plu'].drop_duplicates()\n",
    "    excluded_recid_plu_str = ', '.join(str(s) for s in excluded_recid_plu)\n",
    "\n",
    "    query = '''\n",
    "    SELECT recid_plo, itemdate as Date, sum(net_amount + gst_amount) as Sales\n",
    "    FROM d_txnlines\n",
    "    WHERE itemdate >='{start}' and itemdate <= '{end}' and recid_plo in ({recid_plo_list}) and recid_plu not in ({excluded_recid_plu})\n",
    "    GROUP BY recid_plo, itemdate\n",
    "    ORDER BY itemdate ASC, recid_plo ASC\n",
    "    '''.format(start=start_str, end = end_str, recid_plo_list = recid_plo_list_str, excluded_recid_plu = excluded_recid_plu_str)\n",
    "    sales_df = get_DataFrame_from_clickhouse(query, clickhouse_client)\n",
    "\n",
    "    sales_df['Date'] = pd.to_datetime(sales_df['Date']).dt.date\n",
    "\n",
    "    bonus = pd.merge(bonus, sales_df[['recid_plo', 'Date', 'Sales']], on=['recid_plo', 'Date'], how = 'left')\n",
    "\n",
    "    # Stitch Target Sales & Bonus Rates\n",
    "    sheet_id = '1rqOeBjA9drmTnjlENvr57RqL5-oxSqe_KGdbdL2MKhM'\n",
    "    sheet_name = 'Targets'\n",
    "    url = f'https://docs.google.com/spreadsheets/d/{sheet_id}/gviz/tq?tqx=out:csv&sheet={sheet_name}'\n",
    "    targets = pd.read_csv(url)\n",
    "    targets['Date'] = pd.to_datetime(targets['Date']).dt.date\n",
    "\n",
    "    # Change Bonus Rates to 0, if Target Sales is not met\n",
    "    bonus = pd.merge(bonus, targets[['Store ID', 'Date', 'Target Sales', 'Bonus Rate']], on=['Store ID', 'Date'], how = 'left')\n",
    "    bonus['Bonus Rate'] = bonus['Bonus Rate'].where(bonus['Sales'] >= bonus['Target Sales'], 0)\n",
    "    bonus['Bonus'] = bonus['Bonus Rate']  * bonus['Hours']\n",
    "\n",
    "  # Work out additional_hr\n",
    "  additional_hr = additional_hr.dropna(subset=['Employee ID'])\n",
    "  additional_hr = pd.merge(additional_hr, employees[['Employee ID', 'First Name', 'Last Name', 'Company']], how='left', on=['Employee ID'])\n",
    "  additional_hr_col = [\n",
    "  'Employee ID',\n",
    "  'First Name',\n",
    "  'Last Name',\n",
    "  'Preferred Name',\n",
    "  'Company',\n",
    "  'Store',\n",
    "  'Date',\n",
    "  'Hours'\n",
    "  ]\n",
    "  additional_hr = additional_hr[additional_hr_col]\n",
    "  additional_hr['Date'] = pd.to_datetime(additional_hr['Date'])\n",
    "\n",
    "  # Concat rostered_hr and additional_hr\n",
    "  analysis = pd.concat([rostered_hr, additional_hr])\n",
    "\n",
    "  # Concat Bouns on to Timesheets\n",
    "  if bonus.shape[0]==0:\n",
    "     print('No Bonus Summary to calculate')\n",
    "     timesheets['Bonus']=0\n",
    "  else:\n",
    "\n",
    "    bonus_summary = bonus.groupby(['Employee ID', 'Store'], as_index = False).agg({'Bonus':'sum'})\n",
    "    # print(bonus)\n",
    "    # print(bonus_summary)\n",
    "    timesheets['Store'] = timesheets['Store'].astype(str)\n",
    "    bonus_summary['Store'] = bonus_summary['Store'].astype(str)\n",
    "    timesheets = pd.merge(timesheets, bonus_summary, on=['Employee ID', 'Store'], how = 'left')\n",
    "\n",
    "    timesheets.fillna({'Bonus':0}, inplace = True)\n",
    "\n",
    "  upsheets = pd.melt(\n",
    "    timesheets, \n",
    "    id_vars=['Employee ID', 'First Name', 'Last Name', 'Labour Hire'],  # Columns to keep\n",
    "    value_vars=['Ord', 'Sat', 'Sun', 'Pub', 'Eve 1', 'Eve 2', 'No. of Shifts', 'Personal Leave', 'Annual Leave', 'Unpaid Leave', 'Bonus'],  # Columns to unpivot\n",
    "    var_name='type',\n",
    "    value_name='hours'\n",
    "  )\n",
    "\n",
    "  lvl3_eid = employees[employees['Level'] == 'Level 3']['Employee ID']\n",
    "  upsheets['type'] = upsheets.apply(lambda row: 'Sun Lvl3' if row['Employee ID'] in lvl3_eid.values and row['type'] == 'Sun' else row['type'], axis=1)\n",
    "\n",
    "  type_replacement = {\n",
    "    'Ord': 'Ordinary Hours',\n",
    "    'Sat': 'Saturday',\n",
    "    'Sun': 'Sunday',\n",
    "    'Sun Lvl3': 'Sunday Level 3',\n",
    "    'Pub': 'Public Holiday Hours',\n",
    "    'Eve 1': 'Late Evening Hours 10pm to Midnight',\n",
    "    'Eve 2': 'Late Evening Hours Midnight - 6AM',\n",
    "    'No. of Shifts': 'Laundry Allowance',\n",
    "    'Personal Leave': \"Personal/Carer's Leave\",\n",
    "    'Annual Leave': 'Annual Leave',\n",
    "    'Unpaid Leave': 'Other Unpaid Leave',\n",
    "    'Bonus': 'Bonus',\n",
    "  }\n",
    "  upsheets['type'] = upsheets['type'].replace(type_replacement)\n",
    "  \n",
    "  upsheets = upsheets[upsheets['hours'] != 0]\n",
    "  upsheets['date']=roster_start_date\n",
    "  upsheets = upsheets.rename(columns={'First Name': 'first_name', 'Last Name':'last_name'})\n",
    "\n",
    "\n",
    "  upsheets['rate'] = ''\n",
    "  upsheets['calculation_type'] = ''\n",
    "\n",
    "  fixed_hours_calc_types = [\"Personal/Carer's Leave\", 'Annual Leave', 'Other Unpaid Leave']\n",
    "  upsheets.loc[upsheets['type'].isin(fixed_hours_calc_types), 'calculation_type'] = 'FIXEDHOURS'\n",
    "\n",
    "  fixed_amount_calc_types = ['Bonus']\n",
    "  upsheets.loc[upsheets['type'].isin(fixed_amount_calc_types), 'calculation_type'] = 'FIXEDAMOUNT'\n",
    "  upsheets.loc[upsheets['type'].isin(fixed_amount_calc_types), 'rate'] = upsheets['hours']\n",
    "  upsheets.loc[upsheets['type'].isin(fixed_amount_calc_types), 'hours'] = ''\n",
    "\n",
    "  upsheets['digit'] = upsheets['Employee ID'].apply(count_digits_before_decimal)\n",
    "# Define a mapping of existing types to new types\n",
    "  casual_mapping = {\n",
    "      'Ordinary Hours': 'Casual Ordinary Hours',\n",
    "      'Saturday': 'Casual Saturday',\n",
    "      'Sunday': 'Casual Sunday',\n",
    "      'Public Holiday Hours': 'Casual Public Holiday Hours',\n",
    "      'Late Evening Hours 10pm to Midnight' : 'Casual Late Evening Hours 10pm to Midnight',\n",
    "      'Late Evening Hours Midnight - 6AM' : 'Casual Late Evening Hours Midnight - 6AM',\n",
    "  }\n",
    "# Use map with fillna to keep original values if no match in casual_mapping\n",
    "  upsheets.loc[upsheets['digit'] == 6, 'type'] = (\n",
    "      upsheets.loc[upsheets['digit'] == 6, 'type']\n",
    "      .map(casual_mapping)\n",
    "      .fillna(upsheets.loc[upsheets['digit'] == 6, 'type'])\n",
    "  )\n",
    "  GCM = upsheets[upsheets['Labour Hire']=='GCM']\n",
    "  HL = upsheets[upsheets['Labour Hire']=='HL']\n",
    "  SS = upsheets[upsheets['Labour Hire']=='SS']\n",
    "  MSC = upsheets[upsheets['Labour Hire']=='MSC']\n",
    "  WLD = upsheets[upsheets['Labour Hire']=='WLD']\n",
    "  upsheets_cols = ['Labour Hire','first_name', 'last_name', 'type', 'date','hours', 'rate', 'calculation_type']\n",
    "  upsheets = upsheets[upsheets_cols]\n",
    "\n",
    "  company_cols = ['first_name', 'last_name', 'type', 'date','hours', 'rate', 'calculation_type']\n",
    "  GCM = GCM[company_cols]\n",
    "  HL = HL[company_cols]\n",
    "  SS = SS[company_cols]\n",
    "  MSC = MSC[company_cols]\n",
    "  WLD = WLD[company_cols]\n",
    "\n",
    "  return timesheets, billings, over_threshold, analysis, bonus, upsheets, GCM, HL, SS, MSC, WLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # # END OF FUNCTIONS\n",
    "\n",
    "import io\n",
    "import streamlit as st\n",
    "\n",
    "st.title('Timesheet & Billing')\n",
    "\n",
    "uploaded_files = st.file_uploader(\"Choose Files\", accept_multiple_files = True)\n",
    "\n",
    "# Create an empty container\n",
    "output = st.empty()\n",
    "\n",
    "# if uploaded_files is not None:\n",
    "if len(uploaded_files) > 0:\n",
    "    ts, bl, ot, an, bo, up, gcm, hl, ss, msc, wld = calc_timesheets_n_billings(uploaded_files)\n",
    "\n",
    "    buffer = io.BytesIO()\n",
    "\n",
    "    with pd.ExcelWriter(buffer, engine='xlsxwriter') as writer:\n",
    "    # Write each dataframe to a different worksheet.\n",
    "        ts.to_excel(writer, sheet_name='Timesheet', index = False)\n",
    "        bl.to_excel(writer, sheet_name='Billing', index = False)\n",
    "        ot.to_excel(writer, sheet_name='Over Threshold', index = False)\n",
    "        an.to_excel(writer, sheet_name='Analysis',index = False)\n",
    "        bo.to_excel(writer, sheet_name='Bonus',index = False)\n",
    "        up.to_excel(writer, sheet_name='Upsheets',index = False)\n",
    "        gcm.to_excel(writer, sheet_name='Upsheets GCM',index = False)\n",
    "        hl.to_excel(writer, sheet_name='Upsheets HL',index = False)\n",
    "        ss.to_excel(writer, sheet_name='Upsheets SS',index = False)\n",
    "        msc.to_excel(writer, sheet_name='Upsheets MSC',index = False)\n",
    "        wld.to_excel(writer, sheet_name='Upsheets WLD',index = False)\n",
    "\n",
    "    # Close the Pandas Excel writer and output the Excel file to the buffer\n",
    "    writer.close()\n",
    "\n",
    "    st.download_button(\n",
    "        label=\"Download\",\n",
    "        data=buffer,\n",
    "        file_name=\"Timesheet & Billing.xlsx\",\n",
    "        mime=\"application/vnd.ms-excel\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/eddy/Developer/Python/roster-consolidation/files/Roster v20251024.xlsx']\n",
      "calc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eddy/.pyenv/versions/default/lib/python3.13/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "/Users/eddy/.pyenv/versions/default/lib/python3.13/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "/Users/eddy/.pyenv/versions/default/lib/python3.13/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "/Users/eddy/.pyenv/versions/default/lib/python3.13/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "/var/folders/3y/sylb4fpd4y19tc1y_nfdd_jw0000gn/T/ipykernel_58963/3720842677.py:305: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  upsheets.loc[upsheets['type'].isin(fixed_amount_calc_types), 'hours'] = ''\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "directory = '/Users/eddy/Developer/Python/roster-consolidation/files/'\n",
    "files = [os.path.join(directory, f) for f in os.listdir(directory) if os.path.isfile(os.path.join(directory, f)) and f.endswith('.xlsx')]\n",
    "print(files)\n",
    "ts, bl, ot, an, bo, up, gcm, hl, ss, msc, wld = calc_timesheets_n_billings(files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Employee ID</th>\n",
       "      <th>First Name</th>\n",
       "      <th>Last Name</th>\n",
       "      <th>Preferred Name</th>\n",
       "      <th>Company</th>\n",
       "      <th>Store</th>\n",
       "      <th>Date</th>\n",
       "      <th>Hours</th>\n",
       "      <th>Store ID</th>\n",
       "      <th>recid_plo</th>\n",
       "      <th>Sales</th>\n",
       "      <th>Target Sales</th>\n",
       "      <th>Bonus Rate</th>\n",
       "      <th>Bonus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10156</td>\n",
       "      <td>Chau Kim</td>\n",
       "      <td>Quach</td>\n",
       "      <td>Chau</td>\n",
       "      <td>HL</td>\n",
       "      <td>MC</td>\n",
       "      <td>2025-09-29</td>\n",
       "      <td>5.183333</td>\n",
       "      <td>S002</td>\n",
       "      <td>91</td>\n",
       "      <td>2624.3500</td>\n",
       "      <td>2549.71</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.183333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10156</td>\n",
       "      <td>Chau Kim</td>\n",
       "      <td>Quach</td>\n",
       "      <td>Chau</td>\n",
       "      <td>HL</td>\n",
       "      <td>MC</td>\n",
       "      <td>2025-09-29</td>\n",
       "      <td>5.183333</td>\n",
       "      <td>S002</td>\n",
       "      <td>91</td>\n",
       "      <td>2624.3500</td>\n",
       "      <td>2762.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10243</td>\n",
       "      <td>Shi Wei</td>\n",
       "      <td>Wong</td>\n",
       "      <td>Norman Wong</td>\n",
       "      <td>GCM</td>\n",
       "      <td>MC</td>\n",
       "      <td>2025-09-29</td>\n",
       "      <td>5.816667</td>\n",
       "      <td>S002</td>\n",
       "      <td>91</td>\n",
       "      <td>2624.3500</td>\n",
       "      <td>2549.71</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.816667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10243</td>\n",
       "      <td>Shi Wei</td>\n",
       "      <td>Wong</td>\n",
       "      <td>Norman Wong</td>\n",
       "      <td>GCM</td>\n",
       "      <td>MC</td>\n",
       "      <td>2025-09-29</td>\n",
       "      <td>5.816667</td>\n",
       "      <td>S002</td>\n",
       "      <td>91</td>\n",
       "      <td>2624.3500</td>\n",
       "      <td>2762.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>210419</td>\n",
       "      <td>Yu Yin Jennifer</td>\n",
       "      <td>Wong</td>\n",
       "      <td>Jennifer Wong</td>\n",
       "      <td>SS</td>\n",
       "      <td>MC</td>\n",
       "      <td>2025-09-29</td>\n",
       "      <td>6.733333</td>\n",
       "      <td>S002</td>\n",
       "      <td>91</td>\n",
       "      <td>2624.3500</td>\n",
       "      <td>2549.71</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.733333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>10378</td>\n",
       "      <td>Harshit</td>\n",
       "      <td>Setia</td>\n",
       "      <td>Harshit Setia</td>\n",
       "      <td>SS</td>\n",
       "      <td>MC</td>\n",
       "      <td>2025-10-12</td>\n",
       "      <td>5.066667</td>\n",
       "      <td>S002</td>\n",
       "      <td>91</td>\n",
       "      <td>2850.9500</td>\n",
       "      <td>4002.54</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>10037</td>\n",
       "      <td>Siew Wei</td>\n",
       "      <td>Liew</td>\n",
       "      <td>Sylvia Liew</td>\n",
       "      <td>GCM</td>\n",
       "      <td>MC</td>\n",
       "      <td>2025-10-12</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>S002</td>\n",
       "      <td>91</td>\n",
       "      <td>2850.9500</td>\n",
       "      <td>3694.66</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>10037</td>\n",
       "      <td>Siew Wei</td>\n",
       "      <td>Liew</td>\n",
       "      <td>Sylvia Liew</td>\n",
       "      <td>GCM</td>\n",
       "      <td>MC</td>\n",
       "      <td>2025-10-12</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>S002</td>\n",
       "      <td>91</td>\n",
       "      <td>2850.9500</td>\n",
       "      <td>4002.54</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>10090</td>\n",
       "      <td>Hsin-Yi</td>\n",
       "      <td>CHIANG</td>\n",
       "      <td>Ava Chiang</td>\n",
       "      <td>HL</td>\n",
       "      <td>MC</td>\n",
       "      <td>2025-10-12</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>S002</td>\n",
       "      <td>91</td>\n",
       "      <td>2850.9500</td>\n",
       "      <td>3694.66</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>10090</td>\n",
       "      <td>Hsin-Yi</td>\n",
       "      <td>CHIANG</td>\n",
       "      <td>Ava Chiang</td>\n",
       "      <td>HL</td>\n",
       "      <td>MC</td>\n",
       "      <td>2025-10-12</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>S002</td>\n",
       "      <td>91</td>\n",
       "      <td>2850.9500</td>\n",
       "      <td>4002.54</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>126 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Employee ID       First Name Last Name Preferred Name Company Store  \\\n",
       "0          10156         Chau Kim     Quach           Chau      HL    MC   \n",
       "1          10156         Chau Kim     Quach           Chau      HL    MC   \n",
       "2          10243          Shi Wei      Wong    Norman Wong     GCM    MC   \n",
       "3          10243          Shi Wei      Wong    Norman Wong     GCM    MC   \n",
       "4         210419  Yu Yin Jennifer      Wong  Jennifer Wong      SS    MC   \n",
       "..           ...              ...       ...            ...     ...   ...   \n",
       "121        10378          Harshit     Setia  Harshit Setia      SS    MC   \n",
       "122        10037         Siew Wei      Liew    Sylvia Liew     GCM    MC   \n",
       "123        10037         Siew Wei      Liew    Sylvia Liew     GCM    MC   \n",
       "124        10090          Hsin-Yi    CHIANG     Ava Chiang      HL    MC   \n",
       "125        10090          Hsin-Yi    CHIANG     Ava Chiang      HL    MC   \n",
       "\n",
       "           Date     Hours Store ID  recid_plo      Sales  Target Sales  \\\n",
       "0    2025-09-29  5.183333     S002         91  2624.3500       2549.71   \n",
       "1    2025-09-29  5.183333     S002         91  2624.3500       2762.18   \n",
       "2    2025-09-29  5.816667     S002         91  2624.3500       2549.71   \n",
       "3    2025-09-29  5.816667     S002         91  2624.3500       2762.18   \n",
       "4    2025-09-29  6.733333     S002         91  2624.3500       2549.71   \n",
       "..          ...       ...      ...        ...        ...           ...   \n",
       "121  2025-10-12  5.066667     S002         91  2850.9500       4002.54   \n",
       "122  2025-10-12  5.000000     S002         91  2850.9500       3694.66   \n",
       "123  2025-10-12  5.000000     S002         91  2850.9500       4002.54   \n",
       "124  2025-10-12  6.500000     S002         91  2850.9500       3694.66   \n",
       "125  2025-10-12  6.500000     S002         91  2850.9500       4002.54   \n",
       "\n",
       "     Bonus Rate     Bonus  \n",
       "0           1.0  5.183333  \n",
       "1           0.0  0.000000  \n",
       "2           1.0  5.816667  \n",
       "3           0.0  0.000000  \n",
       "4           1.0  6.733333  \n",
       "..          ...       ...  \n",
       "121         0.0  0.000000  \n",
       "122         0.0  0.000000  \n",
       "123         0.0  0.000000  \n",
       "124         0.0  0.000000  \n",
       "125         0.0  0.000000  \n",
       "\n",
       "[126 rows x 14 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bo\n",
    "\n",
    "# TODO: fix upsheets, as bonus calc twice, and double check Laundry Allowance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
