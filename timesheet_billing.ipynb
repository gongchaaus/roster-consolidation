{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from database_utils import *\n",
    "clickhouse_client = gong_cha_redcat_db_clickhouse_client\n",
    "\n",
    "# # # START OF FUNCTIONS\n",
    "def extract_additional_hr(file, sheet_name):\n",
    "  df = pd.read_excel(file, sheet_name = sheet_name)\n",
    "  df = df.dropna(subset=['Employee ID'])\n",
    "\n",
    "  if df['Employee ID'].dtypes == 'object':\n",
    "    df['Employee ID'] = df['Employee ID'].str[:6]\n",
    "  df['Employee ID'] = df['Employee ID'].astype(int)\n",
    "\n",
    "  if df['Store'].dtypes == float:\n",
    "    df['Store'] = df['Store'].astype(int).astype(str)\n",
    "\n",
    "  df = df.fillna({'Add': 0, 'Add.1': 0,'Add.2': 0,'Add.3': 0,'Add.4': 0,'Add.5': 0,'Personal Leave': 0,'Annual Leave': 0,})\n",
    "  df['2012-11-01'] = df['Add'] + df['Add.1'] + df['Add.2'] + df['Add.3'] + df['Add.4'] + df['Add.5']\n",
    "  df['2013-01-01'] = df['Personal Leave'] + df['Annual Leave']\n",
    "  cols =[0,1,2, df.columns.tolist().index('2012-11-01'),df.columns.tolist().index('2013-01-01')]\n",
    "\n",
    "  df = df.iloc[:, cols]\n",
    "  df = df.dropna(subset=df.columns[:3], how='all')\n",
    "  df = df.melt(id_vars=['Employee ID', 'Store', 'Preferred Name'], value_vars=df.columns[3:], var_name='Date', value_name='Hours')\n",
    "  df = df[df['Hours'] != 0]\n",
    "  return df\n",
    "\n",
    "def extract_rostered_hr(file, sheet_name):\n",
    "  df = pd.read_excel(file, sheet_name = sheet_name)\n",
    "\n",
    "  df = df.dropna(subset=['Employee ID'])\n",
    "\n",
    "  if df['Employee ID'].dtypes == 'object':\n",
    "    df['Employee ID'] = df['Employee ID'].str[:6]\n",
    "  df['Employee ID'] = df['Employee ID'].astype(int)\n",
    "\n",
    "  if df['Store'].dtypes == float:\n",
    "    df['Store'] = df['Store'].astype(int).astype(str)\n",
    "\n",
    "  df = df.iloc[:, :24]\n",
    "  cols = [0,1,2]\n",
    "  for col in range(3, 24, 3):\n",
    "      df[df.columns[col]] = df[df.columns[col+2]]\n",
    "      cols.append(col)\n",
    "  df = df.iloc[:,cols]\n",
    "  df = df.dropna(subset=df.columns[:3], how='all')\n",
    "  df = df.melt(id_vars=['Employee ID', 'Store', 'Preferred Name'], value_vars=df.columns[3:], var_name='Date', value_name='Hours')\n",
    "  df = df[df['Hours'] != 0]\n",
    "  return df\n",
    "\n",
    "# Function to count digits before the decimal point in a float number\n",
    "def count_digits_before_decimal(number):\n",
    "  # Convert to string, split at the decimal point, and count digits in the integer part\n",
    "  integer_part = str(number).split('.')[0]\n",
    "  return len(integer_part.replace('-', '').replace('nan', ''))\n",
    "\n",
    "def calc_timesheets_n_billings(files):\n",
    "  print('calc')\n",
    "  timesheets = pd.DataFrame()\n",
    "  # billings = pd.DataFrame()\n",
    "  rostered_hr = pd.DataFrame()\n",
    "  additional_hr = pd.DataFrame()\n",
    "\n",
    "  for file in files:\n",
    "    timesheet = pd.read_excel(file, sheet_name = 'Timesheet')\n",
    "    # billing = pd.read_excel(file, sheet_name = 'Billing')\n",
    "    rostered_hr_w1 = extract_rostered_hr(file, 'Week 1 Roster')\n",
    "    rostered_hr_w2 = extract_rostered_hr(file, 'Week 2 Roster')\n",
    "    additional_hr_w1 = extract_additional_hr(file, 'Week 1 Roster')\n",
    "    additional_hr_w2 = extract_additional_hr(file, 'Week 2 Roster')\n",
    "    employees = pd.read_excel(file, sheet_name = 'Employees')\n",
    "\n",
    "    timesheets = pd.concat([timesheets, timesheet], ignore_index=True)\n",
    "    # billings = pd.concat([billings, billing], ignore_index=True)\n",
    "    rostered_hr = pd.concat([rostered_hr, rostered_hr_w1], ignore_index=True)\n",
    "    rostered_hr = pd.concat([rostered_hr, rostered_hr_w2], ignore_index=True)\n",
    "    additional_hr = pd.concat([additional_hr, additional_hr_w1], ignore_index=True)\n",
    "    additional_hr = pd.concat([additional_hr, additional_hr_w2], ignore_index=True)\n",
    "\n",
    "  roster_start_date = rostered_hr['Date'].min()\n",
    "  #Remove irrelevant rows\n",
    "  timesheets = timesheets.dropna(subset = ['Employee ID'])\n",
    "\n",
    "  #Keep the needed columns\n",
    "  timesheets_cols = [1,2,3,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22]\n",
    "  timesheets = timesheets[timesheets.columns[timesheets_cols]]\n",
    "  timesheets['Update Wage'] = timesheets['Update Wage'].astype(bool)\n",
    "  timesheets['Store'] = timesheets['Store'].astype(str)\n",
    "  # If the original values were floats in say another column, you might first check that\n",
    "  mask = (timesheets['Store'] == '501.0')\n",
    "  timesheets.loc[mask, 'Store'] = '501'\n",
    "\n",
    "  #Column Aggregations\n",
    "  over_threshold_agg_cols = {'Ord':'sum','Sat':'sum','Sun':'sum','Pub':'sum','Eve 1':'sum','Eve 2':'sum','No. of Shifts':'sum','Personal Leave':'sum','Annual Leave':'sum','Unpaid Leave':'sum','Total':'sum'}\n",
    "  # timesheets = timesheets.groupby(['Employee ID', 'First Name','Last Name', 'Update Wage', 'Hour Threshold', 'Labour Hire', 'Store', 'Operator'], as_index = False).agg(timesheets_agg_cols)\n",
    "  over_threshold = timesheets.groupby(['Employee ID', 'First Name','Last Name', 'Update Wage', 'Hour Threshold'], as_index = False).agg(over_threshold_agg_cols)\n",
    "\n",
    "  #Calculate Over Threshold\n",
    "  over_threshold['Over Threshold'] = over_threshold['Total'] - over_threshold['Hour Threshold']\n",
    "  over_threshold.loc[over_threshold[\"Over Threshold\"] <=0, \"Over Threshold\"] = 0\n",
    "\n",
    "  #Reduce Ord & Total with the excess\n",
    "  over_threshold['Ord OT Ratio'] = (over_threshold['Ord'] - over_threshold['Over Threshold']) / over_threshold['Ord']\n",
    "  # over_threshold['Ord'] = over_threshold['Ord'] - over_threshold['Over Threshold']\n",
    "  # over_threshold['Total'] = over_threshold['Total'] - over_threshold['Over Threshold']\n",
    "\n",
    "  time_sheets_agg_cols = {'Ord':'sum','Sat':'sum','Sun':'sum','Pub':'sum','Eve 1':'sum','Eve 2':'sum','No. of Shifts':'sum','Personal Leave':'sum','Annual Leave':'sum','Unpaid Leave':'sum','Total':'sum'}\n",
    "  timesheets = timesheets.groupby(['Employee ID', 'First Name','Last Name', 'Update Wage', 'Hour Threshold', 'Labour Hire', 'Store', 'Operator'], as_index = False).agg(time_sheets_agg_cols)\n",
    "\n",
    "  # Add Ord OT Ratio and Over Threshold columns from over_threshold dataframe\n",
    "  timesheets = pd.merge(timesheets, over_threshold[['Employee ID', 'Ord OT Ratio', 'Over Threshold']], on=['Employee ID'], how='left')\n",
    "  timesheets.fillna({'Ord OT Ratio': 1, 'Over Threshold': 0}, inplace=True)\n",
    "\n",
    "\n",
    "  # Apply Ord OT Ratio to Ord hours when Over Threshold > 0\n",
    "  timesheets.loc[timesheets['Over Threshold'] > 0, 'Ord'] = timesheets['Ord'] * timesheets['Ord OT Ratio']\n",
    "  timesheets.loc[timesheets['Over Threshold'] > 0, 'Total'] = timesheets['Total'] - timesheets['Over Threshold']\n",
    "\n",
    "  #Convert 80 & 100 hours to 76 hours\n",
    "  hours_col = ['Ord', 'Sat','Sun','Eve 1','Eve 2','Pub','Personal Leave', 'Annual Leave', 'Unpaid Leave', 'Total']\n",
    "  if(100 in timesheets[\"Hour Threshold\"].values):\n",
    "      timesheets.loc[timesheets[\"Hour Threshold\"] == 100, hours_col] = timesheets[hours_col]/100*76\n",
    "  if(80 in timesheets[\"Hour Threshold\"].values):\n",
    "      timesheets.loc[timesheets[\"Hour Threshold\"] == 80, hours_col] = timesheets[hours_col]/80*76\n",
    "  if any(timesheets[\"Hour Threshold\"] > 1000):\n",
    "  # Find rows where \"Hour Threshold\" is greater than 1000\n",
    "      rows_to_update = timesheets.loc[timesheets[\"Hour Threshold\"] > 1000]\n",
    "      # Perform actions on the rows\n",
    "      for index, row in rows_to_update.iterrows():\n",
    "          threshold = int(row[\"Hour Threshold\"])\n",
    "          base = int(str(threshold)[:2])\n",
    "          conversion = int(str(threshold)[-2:])\n",
    "          # Update multiple columns using .loc\n",
    "          timesheets.loc[index, hours_col] = timesheets.loc[index, hours_col] / conversion * base\n",
    "  \n",
    "  \n",
    "  #Keep Over Thresholds to a new df\n",
    "  over_threshold = over_threshold[over_threshold['Over Threshold']>0]\n",
    "  \n",
    "  #drop Hour Threshold & Over Threshold\n",
    "\n",
    "  timesheets = timesheets.drop(['Hour Threshold','Over Threshold', 'Ord OT Ratio'],axis = 1)\n",
    "\n",
    "  #Column Aggregations\n",
    "  billings_agg_cols = {'Ord':'sum','Sat':'sum','Sun':'sum','Pub':'sum','Eve 1':'sum','Eve 2':'sum','No. of Shifts':'sum','Personal Leave':'sum','Annual Leave':'sum','Unpaid Leave':'sum','Total':'sum'}\n",
    "  billings = timesheets.groupby(['Labour Hire', 'Store', 'Operator'], as_index = False).agg(billings_agg_cols)\n",
    "\n",
    "  rostered_hr = pd.merge(rostered_hr, employees[['Employee ID', 'First Name', 'Last Name', 'Company']], how='left', on=['Employee ID'])\n",
    "  rostered_hr_col = [\n",
    "  'Employee ID',\n",
    "  'First Name',\n",
    "  'Last Name',\n",
    "  'Preferred Name',\n",
    "  'Company',\n",
    "  'Store',\n",
    "  'Date',\n",
    "  'Hours'\n",
    "  ]\n",
    "  rostered_hr = rostered_hr[rostered_hr_col]\n",
    "  rostered_hr['Date'] = pd.to_datetime(rostered_hr['Date']).dt.date\n",
    "\n",
    "  bonus = rostered_hr.copy()\n",
    "\n",
    "  # Stitch Store ID and drop rows which Store ID are not found\n",
    "  sheet_id = '1rqOeBjA9drmTnjlENvr57RqL5-oxSqe_KGdbdL2MKhM'\n",
    "  sheet_name = 'StoreReference'\n",
    "  url = f'https://docs.google.com/spreadsheets/d/{sheet_id}/gviz/tq?tqx=out:csv&sheet={sheet_name}'\n",
    "  store_ref = pd.read_csv(url)\n",
    "\n",
    "  bonus = pd.merge(bonus, store_ref, on=['Store'], how = 'left')\n",
    "\n",
    "  bonus.dropna(subset=['Store ID'], inplace = True)\n",
    "\n",
    "  if bonus.shape[0] == 0:\n",
    "     print('No bonus to process')\n",
    "  \n",
    "  else:\n",
    "    store_crm_config = {\n",
    "      'sheet_id': '1aVcnah9Cp_PUvFiXgd2XRmBpLhumCqHUaqROaLcpYfc',\n",
    "      'sheet_name': 'store'\n",
    "    }\n",
    "    store_crm = read_csv_from_config(store_crm_config)\n",
    "    store_crm['opened_on'] = pd.to_datetime(store_crm['opened_on'])\n",
    "    store_crm['closed_on'] = pd.to_datetime(store_crm['closed_on'])\n",
    "    store_crm_col = ['store_id', 'recid_plo']\n",
    "    store_crm = store_crm[store_crm_col]\n",
    "    store_crm = store_crm[~store_crm['recid_plo'].isna()]\n",
    "    store_crm = store_crm.rename(columns={'store_id': 'Store ID'})\n",
    "    \n",
    "    bonus = pd.merge(bonus, store_crm[['Store ID', 'recid_plo']], on=['Store ID'], how = 'left')\n",
    "    bonus['recid_plo'] = bonus['recid_plo'].astype(int)\n",
    "\n",
    "    # Stich sales based on recid_plo & dates, skip if there is no Date\n",
    "    start = bonus['Date'].min()\n",
    "    end = bonus['Date'].max()\n",
    "\n",
    "    start_str = start.strftime('%Y-%m-%d')\n",
    "    end_str = end.strftime('%Y-%m-%d')\n",
    "\n",
    "    recid_plo_list = bonus['recid_plo'].unique().tolist()\n",
    "    recid_plo_list_str = ', '.join(str(id) for id in recid_plo_list)\n",
    "\n",
    "    query = '''\n",
    "    SELECT *\n",
    "    FROM r_opsbonusexclusion\n",
    "    '''\n",
    "    exclusion_df = get_DataFrame_from_clickhouse(query, clickhouse_client)\n",
    "    excluded_recid_plu = exclusion_df['recid_plu'].drop_duplicates()\n",
    "    excluded_recid_plu_str = ', '.join(str(s) for s in excluded_recid_plu)\n",
    "\n",
    "    query = '''\n",
    "    SELECT recid_plo, itemdate as Date, sum(net_amount + gst_amount) as Sales\n",
    "    FROM d_txnlines\n",
    "    WHERE itemdate >='{start}' and itemdate <= '{end}' and recid_plo in ({recid_plo_list}) and recid_plu not in ({excluded_recid_plu})\n",
    "    GROUP BY recid_plo, itemdate\n",
    "    ORDER BY itemdate ASC, recid_plo ASC\n",
    "    '''.format(start=start_str, end = end_str, recid_plo_list = recid_plo_list_str, excluded_recid_plu = excluded_recid_plu_str)\n",
    "    sales_df = get_DataFrame_from_clickhouse(query, clickhouse_client)\n",
    "\n",
    "    sales_df['Date'] = pd.to_datetime(sales_df['Date']).dt.date\n",
    "\n",
    "    bonus = pd.merge(bonus, sales_df[['recid_plo', 'Date', 'Sales']], on=['recid_plo', 'Date'], how = 'left')\n",
    "\n",
    "    # Stitch Target Sales & Bonus Rates\n",
    "    sheet_id = '1rqOeBjA9drmTnjlENvr57RqL5-oxSqe_KGdbdL2MKhM'\n",
    "    sheet_name = 'Targets'\n",
    "    url = f'https://docs.google.com/spreadsheets/d/{sheet_id}/gviz/tq?tqx=out:csv&sheet={sheet_name}'\n",
    "    targets = pd.read_csv(url)\n",
    "    targets['Date'] = pd.to_datetime(targets['Date']).dt.date\n",
    "\n",
    "    # Change Bonus Rates to 0, if Target Sales is not met\n",
    "    bonus = pd.merge(bonus, targets[['Store ID', 'Date', 'Target Sales', 'Bonus Rate']], on=['Store ID', 'Date'], how = 'left')\n",
    "    bonus['Bonus Rate'] = bonus['Bonus Rate'].where(bonus['Sales'] >= bonus['Target Sales'], 0)\n",
    "    bonus['Bonus'] = bonus['Bonus Rate']  * bonus['Hours']\n",
    "\n",
    "  # Work out additional_hr\n",
    "  additional_hr = additional_hr.dropna(subset=['Employee ID'])\n",
    "  additional_hr = pd.merge(additional_hr, employees[['Employee ID', 'First Name', 'Last Name', 'Company']], how='left', on=['Employee ID'])\n",
    "  additional_hr_col = [\n",
    "  'Employee ID',\n",
    "  'First Name',\n",
    "  'Last Name',\n",
    "  'Preferred Name',\n",
    "  'Company',\n",
    "  'Store',\n",
    "  'Date',\n",
    "  'Hours'\n",
    "  ]\n",
    "  additional_hr = additional_hr[additional_hr_col]\n",
    "  additional_hr['Date'] = pd.to_datetime(additional_hr['Date'])\n",
    "\n",
    "  # Concat rostered_hr and additional_hr\n",
    "  analysis = pd.concat([rostered_hr, additional_hr])\n",
    "\n",
    "  # Concat Bouns on to Timesheets\n",
    "  if bonus.shape[0]==0:\n",
    "     print('No Bonus Summary to calculate')\n",
    "     timesheets['Bonus']=0\n",
    "  else:\n",
    "    bonus_summary = bonus.groupby(['Employee ID', 'Store'], as_index = False).agg({'Bonus':'sum'})\n",
    "    # print(bonus)\n",
    "    # print(bonus_summary)\n",
    "    bonus_summary['Store'] = bonus_summary['Store'].astype(str)\n",
    "    timesheets = pd.merge(timesheets, bonus_summary, on=['Employee ID', 'Store'], how = 'left')\n",
    "\n",
    "    timesheets.fillna({'Bonus':0}, inplace = True)\n",
    "\n",
    "  upsheets = pd.melt(\n",
    "    timesheets, \n",
    "    id_vars=['Employee ID', 'First Name', 'Last Name', 'Labour Hire'],  # Columns to keep\n",
    "    value_vars=['Ord', 'Sat', 'Sun', 'Pub', 'Eve 1', 'Eve 2', 'No. of Shifts', 'Personal Leave', 'Annual Leave', 'Unpaid Leave', 'Bonus'],  # Columns to unpivot\n",
    "    var_name='type',\n",
    "    value_name='hours'\n",
    "  )\n",
    "\n",
    "  lvl3_eid = employees[employees['Level'] == 'Level 3']['Employee ID']\n",
    "  upsheets['type'] = upsheets.apply(lambda row: 'Sun Lvl3' if row['Employee ID'] in lvl3_eid.values and row['type'] == 'Sun' else row['type'], axis=1)\n",
    "\n",
    "  type_replacement = {\n",
    "    'Ord': 'Ordinary Hours',\n",
    "    'Sat': 'Saturday',\n",
    "    'Sun': 'Sunday',\n",
    "    'Sun Lvl3': 'Sunday Level 3',\n",
    "    'Pub': 'Public Holiday Hours',\n",
    "    'Eve 1': 'Late Evening Hours 10pm to Midnight',\n",
    "    'Eve 2': 'Late Evening Hours Midnight - 6AM',\n",
    "    'No. of Shifts': 'Laundry Allowance',\n",
    "    'Personal Leave': \"Personal/Carer's Leave\",\n",
    "    'Annual Leave': 'Annual Leave',\n",
    "    'Unpaid Leave': 'Other Unpaid Leave',\n",
    "    'Bonus': 'Bonus',\n",
    "  }\n",
    "  upsheets['type'] = upsheets['type'].replace(type_replacement)\n",
    "  \n",
    "  upsheets = upsheets[upsheets['hours'] != 0]\n",
    "  upsheets['date']=roster_start_date\n",
    "  upsheets = upsheets.rename(columns={'First Name': 'first_name', 'Last Name':'last_name'})\n",
    "\n",
    "\n",
    "  upsheets['rate'] = ''\n",
    "  upsheets['calculation_type'] = ''\n",
    "\n",
    "  fixed_hours_calc_types = [\"Personal/Carer's Leave\", 'Annual Leave', 'Other Unpaid Leave']\n",
    "  upsheets.loc[upsheets['type'].isin(fixed_hours_calc_types), 'calculation_type'] = 'FIXEDHOURS'\n",
    "\n",
    "  fixed_amount_calc_types = ['Bonus']\n",
    "  upsheets.loc[upsheets['type'].isin(fixed_amount_calc_types), 'calculation_type'] = 'FIXEDAMOUNT'\n",
    "  upsheets.loc[upsheets['type'].isin(fixed_amount_calc_types), 'rate'] = upsheets['hours']\n",
    "  upsheets.loc[upsheets['type'].isin(fixed_amount_calc_types), 'hours'] = ''\n",
    "\n",
    "  upsheets['digit'] = upsheets['Employee ID'].apply(count_digits_before_decimal)\n",
    "# Define a mapping of existing types to new types\n",
    "  casual_mapping = {\n",
    "      'Ordinary Hours': 'Casual Ordinary Hours',\n",
    "      'Saturday': 'Casual Saturday',\n",
    "      'Sunday': 'Casual Sunday',\n",
    "      'Public Holiday Hours': 'Casual Public Holiday Hours',\n",
    "      'Late Evening Hours 10pm to Midnight' : 'Casual Late Evening Hours 10pm to Midnight',\n",
    "      'Late Evening Hours Midnight - 6AM' : 'Casual Late Evening Hours Midnight - 6AM',\n",
    "  }\n",
    "# Use map with fillna to keep original values if no match in casual_mapping\n",
    "  upsheets.loc[upsheets['digit'] == 6, 'type'] = (\n",
    "      upsheets.loc[upsheets['digit'] == 6, 'type']\n",
    "      .map(casual_mapping)\n",
    "      .fillna(upsheets.loc[upsheets['digit'] == 6, 'type'])\n",
    "  )\n",
    "  GCM = upsheets[upsheets['Labour Hire']=='GCM']\n",
    "  HL = upsheets[upsheets['Labour Hire']=='HL']\n",
    "  SS = upsheets[upsheets['Labour Hire']=='SS']\n",
    "  MSC = upsheets[upsheets['Labour Hire']=='MSC']\n",
    "  WLD = upsheets[upsheets['Labour Hire']=='WLD']\n",
    "  upsheets_cols = ['Labour Hire','first_name', 'last_name', 'type', 'date','hours', 'rate', 'calculation_type']\n",
    "  upsheets = upsheets[upsheets_cols]\n",
    "\n",
    "  company_cols = ['first_name', 'last_name', 'type', 'date','hours', 'rate', 'calculation_type']\n",
    "  GCM = GCM[company_cols]\n",
    "  HL = HL[company_cols]\n",
    "  SS = SS[company_cols]\n",
    "  MSC = MSC[company_cols]\n",
    "  WLD = WLD[company_cols]\n",
    "\n",
    "  return timesheets, billings, over_threshold, analysis, bonus, upsheets, GCM, HL, SS, MSC, WLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # # END OF FUNCTIONS\n",
    "\n",
    "import io\n",
    "import streamlit as st\n",
    "\n",
    "st.title('Timesheet & Billing')\n",
    "\n",
    "uploaded_files = st.file_uploader(\"Choose Files\", accept_multiple_files = True)\n",
    "\n",
    "# Create an empty container\n",
    "output = st.empty()\n",
    "\n",
    "# if uploaded_files is not None:\n",
    "if len(uploaded_files) > 0:\n",
    "    ts, bl, ot, an, bo, up, gcm, hl, ss, msc, wld = calc_timesheets_n_billings(uploaded_files)\n",
    "\n",
    "    buffer = io.BytesIO()\n",
    "\n",
    "    with pd.ExcelWriter(buffer, engine='xlsxwriter') as writer:\n",
    "    # Write each dataframe to a different worksheet.\n",
    "        ts.to_excel(writer, sheet_name='Timesheet', index = False)\n",
    "        bl.to_excel(writer, sheet_name='Billing', index = False)\n",
    "        ot.to_excel(writer, sheet_name='Over Threshold', index = False)\n",
    "        an.to_excel(writer, sheet_name='Analysis',index = False)\n",
    "        bo.to_excel(writer, sheet_name='Bonus',index = False)\n",
    "        up.to_excel(writer, sheet_name='Upsheets',index = False)\n",
    "        gcm.to_excel(writer, sheet_name='Upsheets GCM',index = False)\n",
    "        hl.to_excel(writer, sheet_name='Upsheets HL',index = False)\n",
    "        ss.to_excel(writer, sheet_name='Upsheets SS',index = False)\n",
    "        msc.to_excel(writer, sheet_name='Upsheets MSC',index = False)\n",
    "        wld.to_excel(writer, sheet_name='Upsheets WLD',index = False)\n",
    "\n",
    "    # Close the Pandas Excel writer and output the Excel file to the buffer\n",
    "    writer.close()\n",
    "\n",
    "    st.download_button(\n",
    "        label=\"Download\",\n",
    "        data=buffer,\n",
    "        file_name=\"Timesheet & Billing.xlsx\",\n",
    "        mime=\"application/vnd.ms-excel\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/eddy/Developer/Python/roster-consolidation/files/All store roster template 2710-0911.xlsx']\n",
      "calc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eddy/.pyenv/versions/default/lib/python3.13/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "/Users/eddy/.pyenv/versions/default/lib/python3.13/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "/Users/eddy/.pyenv/versions/default/lib/python3.13/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "/Users/eddy/.pyenv/versions/default/lib/python3.13/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "/var/folders/3y/sylb4fpd4y19tc1y_nfdd_jw0000gn/T/ipykernel_58963/2165183216.py:304: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  upsheets.loc[upsheets['type'].isin(fixed_amount_calc_types), 'hours'] = ''\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "directory = '/Users/eddy/Developer/Python/roster-consolidation/files/'\n",
    "files = [os.path.join(directory, f) for f in os.listdir(directory) if os.path.isfile(os.path.join(directory, f)) and f.endswith('.xlsx')]\n",
    "print(files)\n",
    "ts, bl, ot, an, bo, up, gcm, hl, ss, msc, wld = calc_timesheets_n_billings(files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Employee ID</th>\n",
       "      <th>First Name</th>\n",
       "      <th>Last Name</th>\n",
       "      <th>Update Wage</th>\n",
       "      <th>Labour Hire</th>\n",
       "      <th>Store</th>\n",
       "      <th>Operator</th>\n",
       "      <th>Ord</th>\n",
       "      <th>Sat</th>\n",
       "      <th>Sun</th>\n",
       "      <th>Pub</th>\n",
       "      <th>Eve 1</th>\n",
       "      <th>Eve 2</th>\n",
       "      <th>No. of Shifts</th>\n",
       "      <th>Personal Leave</th>\n",
       "      <th>Annual Leave</th>\n",
       "      <th>Unpaid Leave</th>\n",
       "      <th>Total</th>\n",
       "      <th>Bonus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10008.0</td>\n",
       "      <td>Elsie</td>\n",
       "      <td>Chan</td>\n",
       "      <td>False</td>\n",
       "      <td>GCM</td>\n",
       "      <td>501</td>\n",
       "      <td>Superb</td>\n",
       "      <td>42.500000</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>59.650000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10032.0</td>\n",
       "      <td>Reynardo</td>\n",
       "      <td>Tjhin</td>\n",
       "      <td>False</td>\n",
       "      <td>GCM</td>\n",
       "      <td>501</td>\n",
       "      <td>Superb</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>5.833333</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11.683333</td>\n",
       "      <td>5.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10160.0</td>\n",
       "      <td>Pulin</td>\n",
       "      <td>Pan</td>\n",
       "      <td>False</td>\n",
       "      <td>GCM</td>\n",
       "      <td>501</td>\n",
       "      <td>Superb</td>\n",
       "      <td>13.416667</td>\n",
       "      <td>10.316667</td>\n",
       "      <td>8.933333</td>\n",
       "      <td>0</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36.466667</td>\n",
       "      <td>7.816667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10289.0</td>\n",
       "      <td>Jethro</td>\n",
       "      <td>Soewandito</td>\n",
       "      <td>False</td>\n",
       "      <td>GCM</td>\n",
       "      <td>501</td>\n",
       "      <td>Superb</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10324.0</td>\n",
       "      <td>Yu-Ju</td>\n",
       "      <td>Wu</td>\n",
       "      <td>False</td>\n",
       "      <td>SS</td>\n",
       "      <td>501</td>\n",
       "      <td>Superb</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>8.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10341.0</td>\n",
       "      <td>Truc Thanh</td>\n",
       "      <td>Nguyen</td>\n",
       "      <td>False</td>\n",
       "      <td>SS</td>\n",
       "      <td>501</td>\n",
       "      <td>Superb</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10343.0</td>\n",
       "      <td>Theresa</td>\n",
       "      <td>Chow</td>\n",
       "      <td>False</td>\n",
       "      <td>SS</td>\n",
       "      <td>501</td>\n",
       "      <td>Superb</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>3.783333</td>\n",
       "      <td>0.216667</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10385.0</td>\n",
       "      <td>Hui Qi</td>\n",
       "      <td>Lau</td>\n",
       "      <td>False</td>\n",
       "      <td>SS</td>\n",
       "      <td>501</td>\n",
       "      <td>Superb</td>\n",
       "      <td>16.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28.250000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10387.0</td>\n",
       "      <td>Tran</td>\n",
       "      <td>Le</td>\n",
       "      <td>False</td>\n",
       "      <td>SS</td>\n",
       "      <td>501</td>\n",
       "      <td>Superb</td>\n",
       "      <td>17.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27.500000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>210413.0</td>\n",
       "      <td>Minh Huy</td>\n",
       "      <td>Loi</td>\n",
       "      <td>False</td>\n",
       "      <td>SS</td>\n",
       "      <td>501</td>\n",
       "      <td>Superb</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>8.316667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24.316667</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>210423.0</td>\n",
       "      <td>Priska Nathasa</td>\n",
       "      <td>Salim</td>\n",
       "      <td>False</td>\n",
       "      <td>SS</td>\n",
       "      <td>501</td>\n",
       "      <td>Superb</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>2.850000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.850000</td>\n",
       "      <td>8.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>210434.0</td>\n",
       "      <td>Yu</td>\n",
       "      <td>Hsiao</td>\n",
       "      <td>False</td>\n",
       "      <td>SS</td>\n",
       "      <td>501</td>\n",
       "      <td>Superb</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>210457.0</td>\n",
       "      <td>Ryan</td>\n",
       "      <td>Tristandi</td>\n",
       "      <td>False</td>\n",
       "      <td>SS</td>\n",
       "      <td>501</td>\n",
       "      <td>Superb</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>6.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>210485.0</td>\n",
       "      <td>MUTSUMI</td>\n",
       "      <td>KANEDA</td>\n",
       "      <td>False</td>\n",
       "      <td>SS</td>\n",
       "      <td>501</td>\n",
       "      <td>Superb</td>\n",
       "      <td>24.500000</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>3.833333</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>45.983333</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Employee ID      First Name   Last Name  Update Wage Labour Hire Store  \\\n",
       "0       10008.0           Elsie        Chan        False         GCM   501   \n",
       "1       10032.0        Reynardo       Tjhin        False         GCM   501   \n",
       "2       10160.0           Pulin         Pan        False         GCM   501   \n",
       "3       10289.0          Jethro  Soewandito        False         GCM   501   \n",
       "4       10324.0           Yu-Ju          Wu        False          SS   501   \n",
       "5       10341.0      Truc Thanh      Nguyen        False          SS   501   \n",
       "6       10343.0         Theresa        Chow        False          SS   501   \n",
       "7       10385.0          Hui Qi         Lau        False          SS   501   \n",
       "8       10387.0            Tran          Le        False          SS   501   \n",
       "9      210413.0        Minh Huy         Loi        False          SS   501   \n",
       "10     210423.0  Priska Nathasa       Salim        False          SS   501   \n",
       "11     210434.0              Yu       Hsiao        False          SS   501   \n",
       "12     210457.0            Ryan   Tristandi        False          SS   501   \n",
       "13     210485.0         MUTSUMI      KANEDA        False          SS   501   \n",
       "\n",
       "   Operator        Ord        Sat        Sun  Pub     Eve 1     Eve 2  \\\n",
       "0    Superb  42.500000   7.500000   5.500000    0  4.000000  0.150000   \n",
       "1    Superb   3.500000   5.833333   0.350000    0  2.000000  0.000000   \n",
       "2    Superb  13.416667  10.316667   8.933333    0  3.800000  0.000000   \n",
       "3    Superb   7.500000   0.000000   0.000000    0  0.000000  0.000000   \n",
       "4    Superb  48.000000   0.000000   0.000000    0  0.000000  0.000000   \n",
       "5    Superb   0.000000   0.000000   9.000000    0  0.000000  0.000000   \n",
       "6    Superb  12.500000   9.000000   0.000000    0  3.783333  0.216667   \n",
       "7    Superb  16.500000   0.000000   7.500000    0  4.000000  0.250000   \n",
       "8    Superb  17.500000   0.000000  10.000000    0  0.000000  0.000000   \n",
       "9    Superb  14.000000   8.316667   0.000000    0  2.000000  0.000000   \n",
       "10   Superb  17.000000   4.000000   0.000000    0  2.850000  0.000000   \n",
       "11   Superb   9.500000   8.500000   0.000000    0  2.000000  0.000000   \n",
       "12   Superb  26.000000   0.000000   0.000000    0  0.000000  0.000000   \n",
       "13   Superb  24.500000   7.500000  10.000000    0  3.833333  0.150000   \n",
       "\n",
       "    No. of Shifts  Personal Leave  Annual Leave  Unpaid Leave      Total  \\\n",
       "0               5               0             0             0  59.650000   \n",
       "1               2               0             0             0  11.683333   \n",
       "2               4               0             0             0  36.466667   \n",
       "3               1               0             0             0   7.500000   \n",
       "4               5               0             0             0  48.000000   \n",
       "5               1               0             0             0   9.000000   \n",
       "6               3               0             0             0  25.500000   \n",
       "7               4               0             0             0  28.250000   \n",
       "8               3               0             0             0  27.500000   \n",
       "9               3               0             0             0  24.316667   \n",
       "10              4               0             0             0  23.850000   \n",
       "11              3               0             0             0  20.000000   \n",
       "12              3               0             0             0  26.000000   \n",
       "13              6               0             0             0  45.983333   \n",
       "\n",
       "        Bonus  \n",
       "0    0.000000  \n",
       "1    5.833333  \n",
       "2    7.816667  \n",
       "3    0.000000  \n",
       "4    8.500000  \n",
       "5    0.000000  \n",
       "6    0.000000  \n",
       "7    0.000000  \n",
       "8   10.000000  \n",
       "9    0.000000  \n",
       "10   8.500000  \n",
       "11   0.000000  \n",
       "12   6.500000  \n",
       "13   0.000000  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts[ts['Store']==\"501\"]\n",
    "\n",
    "# TODO: fix upsheets, as bonus calc twice, and double check Laundry Allowance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
